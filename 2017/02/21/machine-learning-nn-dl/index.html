<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="https://galaxias-sapphi-ren.github.io">
  <title>Machine Learning | 扬帆起航神经网络与深度学习 | Ren&#39;s Time Overflow Skyline ^_^</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="睡眼惺忪，阳光入帘，起床深呼吸，要不然，开始有智能的机器就要淘汰你了。">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning | 扬帆起航神经网络与深度学习">
<meta property="og:url" content="https://galaxias-sapphi-ren.github.io/2017/02/21/machine-learning-nn-dl/index.html">
<meta property="og:site_name" content="Ren's Time Overflow Skyline ^_^">
<meta property="og:description" content="睡眼惺忪，阳光入帘，起床深呼吸，要不然，开始有智能的机器就要淘汰你了。">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/高科技.jpg">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/智能导图.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/人工智能.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/学习.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/3层机器学习.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/机器学习.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/机器学习map.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/机器学习地铁图.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/机器学习分类.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/机器学习算法图解.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/机器学习算法边界预测.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/神经元.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/神经元行为.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/神经元模型.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/MP模型对比.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/激活函数.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/感知机.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/sigmoid函数.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/tanh函数.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/ReLU函数.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/损失函数.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/学习率与损失曲线.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/神经网络历史.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/神经网络.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/前馈神经网络.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/神经网络导图.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/BP.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/神经网络类别.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/深度学习.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/循环神经网络例子.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/CNN学习路线.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/积卷神经网络.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/卷积例子.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/卷积池化.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/LSTM.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/LSTMstep1.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/LSTMstep2.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/LSTMstep3.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/LSTMstep4.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/playground.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/问题分类.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/寻找算法.png">
<meta property="og:image" content="https://galaxias-sapphi-ren.github.io/images/2017/spring/超参调整.png">
<meta property="og:updated_time" content="2017-03-02T02:17:23.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning | 扬帆起航神经网络与深度学习">
<meta name="twitter:description" content="睡眼惺忪，阳光入帘，起床深呼吸，要不然，开始有智能的机器就要淘汰你了。">
<meta name="twitter:image" content="https://galaxias-sapphi-ren.github.io/images/高科技.jpg">
  
    <link rel="alternative" href="/atom.xml" title="Ren&#39;s Time Overflow Skyline ^_^" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/favicon.ico">
  
  <link rel="stylesheet" type="text/css" href="/./main.2d7529.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  
<script>
var _hmt = _hmt || [];
(function() {
	var hm = document.createElement("script");
	hm.src = "https://hm.baidu.com/hm.js?e3f61da115e62fa64fec49698fb90170";
	var s = document.getElementsByTagName("script")[0]; 
	s.parentNode.insertBefore(hm, s);
})();
</script>


</head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/images/favicon.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">Galaxias-Sapphi-REN</a></h1>
		</hgroup>
		
		<p class="header-subtitle">Bla Bla</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">Time Overflow</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">博文</a>
    			
            
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">博主</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/Galaxias-Sapphi-REN" title="github"><i class="icon-github"></i></a>
		        
					<a class="weibo" target="_blank" href="http://www.cnblogs.com/Galaxias-Sapphi-REN/" title="weibo"><i class="icon-weibo"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:578556078@qq.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/images/favicon.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">Galaxias-Sapphi-REN</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>Bla Bla<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Galaxias-Sapphi-REN" title="github"><i class="icon-github"></i></a>
			        
						<a class="weibo" target="_blank" href="http://www.cnblogs.com/Galaxias-Sapphi-REN/" title="weibo"><i class="icon-weibo"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:578556078@qq.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 100%"><a href="/">Time Overflow</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            <article id="post-machine-learning-nn-dl" class="article article-type-post " itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Machine Learning | 扬帆起航神经网络与深度学习
    </h1>
  

        
        <a href="/2017/02/21/machine-learning-nn-dl/" class="archive-article-date">
  	<time datetime="2017-02-21T01:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-02-21</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/高科技.jpg" alt="cover"></p>
<p>睡眼惺忪，阳光入帘，起床深呼吸，要不然，开始有智能的机器就要淘汰你了。</p>
<a id="more"></a>
<p>2017年02月21日 - 任思飞 @Copyright Smart Home &amp; Roobo</p>
<hr>
<h1 id="神经网络与深度学习概述-机器学习预研"><a href="#神经网络与深度学习概述-机器学习预研" class="headerlink" title="神经网络与深度学习概述 - 机器学习预研"></a>神经网络与深度学习概述 - 机器学习预研</h1><hr>
<blockquote>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2></blockquote>
<pre><code>智能是根据环境变化而做出相应变化的能力，从信息论的观点看就是减熵的能力。而人工智能（Artificial Intelligence）的研究目标是使机器像人一样智能，主要应用于自然语言处理、知识表现、推理、规划、感知、模式识别等。
机器学习（Machine Learning）是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。
深度学习（Deep Learning）是深层的机器学习（Deep ML）。其“深层”（Deep）的真正含义是通过“抽象概念”学习，将多层表达的特征提取器和识别器合在一起，算法加“深”。
神经网络（Neural Networks）属于ML的一种。而深层神经网络（Deep NN）也只是深层学习的一种。
本文分别从自然学习与机器学习的概念类比、python最简代码（核心算法）学习、为什么要进行深度学习、谷歌开放机器学习框架tensorflow神经网络官方playground实例，四个方面概述人工智能、机器学习、深度学习的内容和结构，并层层递进的阐释感知器、神经网络、循环神经网络、卷积神经网络等的概念与常用算法。
本文试图在脱离线性代数、统计学相关公式的情况下，从不同角度聚焦在人工智能领域的神经网络和深度学习相关内容。并且最终给出一般性算法选择路径。
</code></pre><p><strong>关键字</strong><br>    神经网络 机器学习 深度学习</p>
<blockquote>
<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2></blockquote>
<p>吴军在《数学之美》中有一段描述，引做导读。</p>
<p>有不少专业术语乍一听很唬人，“人工神经网络”就属于这一类，至少我第一次听到这个词就被唬住了。你想啊，在大家的印象当中，人们对人脑的结构都还根本没有搞清楚，这就冒出来一个“人工的”神经网络，似乎是在用计算机来模拟人脑。想到人脑的结构那么复杂，大家的第一反应一定是人工神经网络肯定非常高深。如果我们有幸遇到一个好心同时又善于表达的科学家或教授，他愿意花一两个小时的时间，深入浅出地把人工神经网络的底细告诉你，你便会发现，“哦，原来是这么回事”。如果我们不幸遇到一个爱卖弄的人，他会很郑重地告诉你“我在使用人工神经网络”或者“我研究的课题是人工神经网络”，然后就没有下文了，如此，你除了对他肃然起敬外，不由得可能还会感到自卑。当然还有好心却不善于表达的人试图将这个概念给你讲清楚，但是他用了一些更难懂的名词，讲得云山雾罩，最后你发现听他讲了好几个小时，结果是更加糊涂了，你除了浪费时间外一无所获，于是你得出一个结论：反正我这辈子不需要搞懂它了。</p>
<p>大家可别以为我是在说笑话，这些都是我的亲身经历。首先，我没有遇到过一两小时给我讲懂的好心人，其次我遇到了一批在我前面卖弄的人，作为年轻人，总是希望把自己不明白的东西搞懂，于是我决定去旁听一门课。不过，我听了大约两三次便不再去了，因为除了浪费时间，似乎我并没得到什么收获。好在我自己做研究暂时用不到它，也就不再关心了。后来在美国读博士期间，我喜欢在睡觉前躺着看书，没事儿就捧着几本关于人工神经网络的教科书在床上看，居然也看懂了。然后再用它做了两三个项目，算是学会了。到这时回过头来再看“人工神经网络”，其实并不复杂，入门也不难，只是我走了弯路。</p>
<blockquote>
<h2 id="第一章：自然到机器的学习"><a href="#第一章：自然到机器的学习" class="headerlink" title="第一章：自然到机器的学习"></a>第一章：自然到机器的学习</h2></blockquote>
<p>本章对比自然学习和机器学习的相关概念，尝试类比机器学习的内容，并强化对机器学习中神经网络的理解。机器学习地铁图、算法决策图等概述机器学习概念。</p>
<p>知识比对表如下：</p>
<table>
<thead>
<tr>
<th>自然名词</th>
<th>机器名词</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>智能</td>
<td>人工智能</td>
<td>熵减，根据环境变化而做出相应变化，学习和预测</td>
</tr>
<tr>
<td>生物学习</td>
<td>机器学习</td>
<td>寻求从过去状态到未来状态的关联的过程</td>
</tr>
<tr>
<td>神经元</td>
<td>感知机</td>
<td>输入特征（向量），输出描述状态，用线性变换跟随着非线性变化，将输入空间投向另一个空间，是输出的决策单元</td>
</tr>
<tr>
<td>抽象层级</td>
<td>层</td>
<td>增加容纳变体的能力、鲁棒性</td>
</tr>
<tr>
<td>神经元的网状结构</td>
<td>神经网络（分类器）</td>
<td>学习和预测过去到未来的关联</td>
</tr>
</tbody>
</table>
<h3 id="1-1-从智能开始"><a href="#1-1-从智能开始" class="headerlink" title="1.1 从智能开始"></a>1.1 从智能开始</h3><blockquote>
<h4 id="1-1-2-智能"><a href="#1-1-2-智能" class="headerlink" title="1.1.2 智能"></a>1.1.2 智能</h4></blockquote>
<p>从信息论的观点看自然智能，从宇宙大爆炸开始，世界的状态向越不确定的状态转变，所蕴涵的信息越来越多。生命要在这个变化的世界中生存，它就需要知道如何根据环境变化做出相应的行动来避免毁灭。把不确定的环境转换成确定的行动。会将无序的事物重新整理到有序的状态。生物仅仅活着就需要减熵，否则就会被不确定性会消灭。</p>
<p>其中：</p>
<p><code>智能</code>是可以根据环境变化而做出相应变化的能力(熵减的能力)，通过智能，智能体学习和预测信息，减少信息状态的不确定性。</p>
<p><code>熵</code>是用来衡量我们对事物在跨时间后能产生不同状态的混乱度。越确定(deterministic)的事件的熵越低，越随机(probabilistic)的事件的熵越高。</p>
<p><img src="/images/2017/spring/智能导图.png" alt="智能导图"></p>
<p>自然的智能存储于遗传物质中，通过螺旋结构合成蛋白质，根据化学信号和电信号执行功能。生物通过繁殖和变异学习自然智能。</p>
<blockquote>
<h4 id="1-1-2-人工智能（Artificial-Intelligence）"><a href="#1-1-2-人工智能（Artificial-Intelligence）" class="headerlink" title="1.1.2 人工智能（Artificial Intelligence）"></a>1.1.2 人工智能（Artificial Intelligence）</h4></blockquote>
<p>随着信息量的增加，智能无法解决大信息量的问题，人类开始尝试使机器产生智能，人工智能是指由人工制造出来的系统所表现出来的智能。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基于仿生学、认知心理学，以及基于概率论和经济学的算法等等也在逐步探索当中。而机器学习是解决人工智能的主要途径，主要用于解决决策所需要的数据量超过我们有限大脑的处理能力的问题。</p>
<p><img src="/images/2017/spring/人工智能.png" alt="人工智能"></p>
<p>人工智能是多科学的交叉，但又不被任何一个学科完全包含。 从智能的定义直接扩展的话，人工智能是非自然选择形成的一种减熵的能力。</p>
<h3 id="1-2-什么是学习"><a href="#1-2-什么是学习" class="headerlink" title="1.2 什么是学习"></a>1.2 什么是学习</h3><blockquote>
<h4 id="1-2-1-生物学习"><a href="#1-2-1-生物学习" class="headerlink" title="1.2.1 生物学习"></a>1.2.1 生物学习</h4></blockquote>
<p>人可以通过经验学习，比方说“朝霞不出门，晚霞行千里”，就是通过经验得来的知识。所以学习的对象是‘经验’，准确说是<code>先验知识</code>，广义说是<code>数据</code>。</p>
<p><img src="/images/2017/spring/学习.png" alt="学习"></p>
<p>随着信息增加，不确定性增高。学习是从信息中找回物理关系，回卷信息，降低不确定性的过程。被找回的物理关系叫做知识。</p>
<blockquote>
<h4 id="1-2-2-机器学习"><a href="#1-2-2-机器学习" class="headerlink" title="1.2.2 机器学习"></a>1.2.2 机器学习</h4></blockquote>
<p><code>机器学习</code>主要是研究如何使计算机从给定的数据中学习规律，即从观测数据(样本)中寻找规律，并利用学习到的规律(模型)对未知或无法观测的数据进行预测。目前，主流的机器学习算法是基于统计的方法，也叫统计机器学习。</p>
<p>简单来讲，只要表现出智能的程序（将无序数据转换为有用知识），且程序的参数是从数据中进行学习，就是机器学习。</p>
<h5 id="1-2-2-1-概念"><a href="#1-2-2-1-概念" class="headerlink" title="1.2.2.1 概念"></a>1.2.2.1 概念</h5><p><code>维基百科</code> 机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。</p>
<p><code>机器学习</code>（1998 Tom Mitchell）对于一个程序，给它一个任务T和一个性能测量方法P，如果在经验E的影响下，P对T的测量结果得到了改进，那么就说该程序从E中学习。</p>
<h5 id="1-2-2-2-学习阶段"><a href="#1-2-2-2-学习阶段" class="headerlink" title="1.2.2.2 学习阶段"></a>1.2.2.2 学习阶段</h5><pre><code>LEARNING = REPRESENTATION + EVALUATION + OPTIMIZATION
</code></pre><ul>
<li>REPRESENTATION（表现）：表示信息的状态（假设空间）及特征（分类器）</li>
<li>EVALUATION（评价）：区分正确的信息状态和好的特征（评价函数或目标函数）</li>
<li>OPTIMIZATION（优化）：迭代快速的学习（算法优化）</li>
</ul>
<p><img src="/images/2017/spring/3层机器学习.png" alt="3层机器学习"></p>
<h5 id="1-2-2-3-数学解释"><a href="#1-2-2-3-数学解释" class="headerlink" title="1.2.2.3 数学解释"></a>1.2.2.3 数学解释</h5><p>学习一个映射函数f : x → y，将输入变量x映射为输出变量y。一般我们可以假设映射函数为y = f(x, θ)。其中θ 即为函数的参数。参数可以通过学习算法进行学习。</p>
<p><img src="/images/2017/spring/机器学习.png" alt="机器学习"></p>
<p>我们还要建立一些准则来衡量决策函数的好坏。在很多机器学习算法中， 一般是定义一个损失函数 </p>
<pre><code>L(y, f(x, a))
</code></pre><p>然后在所有的训练样本上来评价决策函数的风险。</p>
<p>用对参数求经验风险来逐渐逼近理想的期望风险的最小值，就是我们常说的经验风险最小化原则(Empirical Risk Minimization)。这样，我们的目标就是变成了找到一个参数a使得经验风险最小。 </p>
<h5 id="1-2-2-2-结构"><a href="#1-2-2-2-结构" class="headerlink" title="1.2.2.2 结构"></a>1.2.2.2 结构</h5><p><img src="/images/2017/spring/机器学习map.png" alt="机器学习map"></p>
<h5 id="1-2-2-3-学习地铁图"><a href="#1-2-2-3-学习地铁图" class="headerlink" title="1.2.2.3 学习地铁图"></a>1.2.2.3 学习地铁图</h5><p><img src="/images/2017/spring/机器学习地铁图.png" alt="地铁图 "></p>
<h5 id="1-2-2-3-分类及算法"><a href="#1-2-2-3-分类及算法" class="headerlink" title="1.2.2.3 分类及算法"></a>1.2.2.3 分类及算法</h5><p>机器学习分类包括：</p>
<ul>
<li>监督性学习（Supervised Learning），<ul>
<li>概念：有监督学习是利用一组已知输入 x 和输出 y 的数据来学习模型的参数，使 ]得模型预测的输出标记和真实标记尽可能的一致。</li>
<li>用途：根据函数的输出是连续的值还是离散的值可以分为回归（Recregression）和分类（Classication）。目前最广泛被使用的分类器有人工神经网络、支持向量机、最近邻居法、高斯混合模型、朴素贝叶斯方法、决策树和径向基函数分类。</li>
</ul>
</li>
<li>非监督学习（Unsupervised Learning）<ul>
<li>概念：无监督学习是用来学习的数据不包 含输出目标，需要学习算法自动学习到一些有价值的信息。</li>
<li>用途：主要用于数据聚类（Clustering），在人工神经网络中，自我组织映射（SOM）和适应性共振理论（ART）则是最常用的非监督式学习。</li>
</ul>
</li>
<li>强化学习（Reinforcement Learning）<ul>
<li>概念：强化学习强调如何基于环境做出一系列的动作，以取得最大化的累积收益。每做出一个动作，并不一定立刻得到收益。增强学习和有监督 学习的不同在于增强学习不需要显式地以输入/输出对的方式给出训练样本，是一种在线的学习机制。</li>
<li>用途：主要应用于机器人决策中的回报函数和连续决策。</li>
</ul>
</li>
<li>迁移学习（Transfer Learning）。<ul>
<li>概念：把已学训练好的模型参数迁移到新的模型来帮助新模型训练数据集。</li>
</ul>
</li>
</ul>
<p><img src="/images/2017/spring/机器学习分类.png" alt="机器学习分类"></p>
<p>机器学习常用算法有：</p>
<p><a href="https://static.coggle.it/diagram/WHeBqDIrJRk-kDDY" target="_blank" rel="external">算法一览</a></p>
<p>机器学习中算法决策图解</p>
<p><img src="/images/2017/spring/机器学习算法图解.png" alt="算法索引"></p>
<p>算法索引</p>
<ul>
<li>正则化算法（Regularization Algorithms）<ul>
<li>概念：它是另一种方法（通常是回归方法）的拓展，这种方法会基于模型复杂性对其进行惩罚，它喜欢相对简单能够更好的泛化的模型。</li>
<li>案例：岭回归（Ridge Regression）、最小绝对收缩与选择算子（LASSO）、GLASSO、弹性网络（Elastic Net）、最小角回归（Least-Angle Regression）</li>
<li>优点：其惩罚会减少过拟合，总会有解决方法</li>
<li>缺点：惩罚会造成欠拟合，很难校准</li>
</ul>
</li>
<li>集成算法（Ensemble Algorithms）<ul>
<li>概念：集成方法是由多个较弱的模型集成模型组，其中的模型可以单独进行训练，并且它们的预测能以某种方式结合起来去做出一个总体预测。</li>
<li>案例：Boosting、Bootstrapped Aggregation（Bagging）、AdaBoost、层叠泛化（Stacked Generalization）（blending）、梯度推进机（Gradient Boosting Machines，GBM）、梯度提升回归树（Gradient Boosted Regression Trees，GBRT）、随机森林（Random Forest）</li>
<li>优点：当先最先进的预测几乎都使用了算法集成。它比使用单个模型预测出来的结果要精确的多</li>
<li>缺点：需要大量的维护工作</li>
</ul>
</li>
<li>决策树算法（Decision Tree Algorithm）<ul>
<li>概念：决策树学习使用一个决策树作为一个预测模型，它将对一个 item（表征在分支上）观察所得映射成关于该 item 的目标值的结论（表征在叶子中）。树模型中的目标是可变的，可以采一组有限值，被称为分类树；在这些树结构中，叶子表示类标签，分支表示表征这些类标签的连接的特征。</li>
<li>案例：分类和回归树（Classification and Regression Tree，CART）、Iterative Dichotomiser 3（ID3）、C4.5 和 C5.0（一种强大方法的两个不同版本）</li>
<li>优点：计算量简单，可解释性强，比较适合处理有缺失属性值的样本，能够处理不相关的特征</li>
<li>缺点：容易过拟合（后续出现了随机森林，减小了过拟合现象），可能或陷于局部最小值中，没有在线学习，单颗决策树分类能力弱，并且对连续值变量难以处理。</li>
</ul>
</li>
<li>回归（Regression）<ul>
<li>概念：回归是用于估计两种变量之间关系的统计过程。当用于分析因变量和一个 多个自变量之间的关系时，该算法能提供很多建模和分析多个变量的技巧。具体一点说，回归分析可以帮助我们理解当任意一个自变量变化，另一个自变量不变时，因变量变化的典型值。最常见的是，回归分析能在给定自变量的条件下估计出因变量的条件期望。</li>
<li>案例：普通最小二乘回归（Ordinary Least Squares Regression，OLSR）、线性回归（Linear Regression）、逻辑回归（Logistic Regression）、逐步回归（Stepwise Regression）、多元自适应回归样条（Multivariate Adaptive Regression Splines，MARS）、本地散点平滑估计（Locally Estimated Scatterplot Smoothing，LOESS）</li>
<li>优点：直接、快速，知名度高</li>
<li>缺点：要求严格的假设，需要处理异常值</li>
</ul>
</li>
<li>人工神经网络（Artificial Neural Network）<ul>
<li>概念：人工神经网络是受生物神经网络启发而构建的算法模型。它是一种模式匹配，常被用于回归和分类问题，但拥有庞大的子域，由数百种算法和各类问题的变体组成。</li>
<li>案例：感知器、反向传播、Hopfield 网络、径向基函数网络（Radial Basis Function Network，RBFN）</li>
<li>优点：在语音、语义、视觉、各类游戏（如围棋）的任务中表现极好。算法可以快速调整，适应新的问题。</li>
<li>缺点：需要大量数据进行训练。训练要求很高的硬件配置。模型处于「黑箱状态」，难以理解内部机制。元参数（Metaparameter）与网络拓扑选择困难。</li>
</ul>
</li>
<li>深度学习（Deep Learning）<ul>
<li>概念：深度学习是人工神经网络的最新分支，它受益于当代硬件的快速发展。众多研究者目前的方向主要集中于构建更大、更复杂的神经网络，目前有许多方法正在聚焦半监督学习问题，其中用于训练的大数据集只包含很少的标记。</li>
<li>案例：深玻耳兹曼机（Deep Boltzmann Machine，DBM）、Deep Belief Networks（DBN）、卷积神经网络（CNN）、Stacked Auto-Encoders</li>
<li>优缺点：同神经网络</li>
</ul>
</li>
<li>支持向量机（Support Vector Machine）<ul>
<li>概念：给定一组训练事例，其中每个事例都属于两个类别中的一个，支持向量机（SVM）训练算法可以在被输入新的事例后将其分类到两个类别中的一个，使自身成为非概率二进制线性分类器。SVM 模型将训练事例表示为空间中的点，它们被映射到一幅图中，由一条明确的、尽可能宽的间隔分开以区分两个类别。随后，新的示例会被映射到同一空间中，并基于它们落在间隔的哪一侧来预测它属于的类别。</li>
<li>优点：在非线性可分问题上表现优秀。</li>
<li>缺点：非常难以训练。很难解释。</li>
</ul>
</li>
<li>降维算法（Dimensionality Reduction Algorithms）<ul>
<li>概念：和集簇方法类似，降维追求并利用数据的内在结构，目的在于使用较少的信息总结或描述数据。这一算法可用于可视化高维数据或简化接下来可用于监督学习中的数据。许多这样的方法可针对分类和回归的使用进行调整。</li>
<li>案例：主成分分析（Principal Component Analysis (PCA)）、主成分回归（Principal Component Regression (PCR)）、偏最小二乘回归（Partial Least Squares Regression (PLSR)）、Sammon 映射（Sammon Mapping）、多维尺度变换（Multidimensional Scaling (MDS)）、投影寻踪（Projection Pursuit）、线性判别分析（Linear Discriminant Analysis (LDA)）、混合判别分析（Mixture Discriminant Analysis (MDA)）、二次判别分析（Quadratic Discriminant Analysis (QDA)）、灵活判别分析（Flexible Discriminant Analysis (FDA)）</li>
<li>优点：可处理大规模数据集。无需在数据上进行假设。</li>
<li>缺点： 难以搞定非线性数据。难以理解结果的意义。</li>
</ul>
</li>
<li>聚类算法（Clustering Algorithms）<ul>
<li>概念：聚类算法是指对一组目标进行分类，属于同一组（亦即一个类，cluster）的目标被划分在一组中，与其他组目标相比，同一组目标更加彼此相似（在某种意义上）。</li>
<li>案例：K-均值（k-Means）、k-Medians 算法、Expectation Maximi 封层 ation (EM)、最大期望算法（EM）、分层集群（Hierarchical Clstering）</li>
<li>优点：让数据变得有意义</li>
<li>缺点：结果难以解读，针对不寻常的数据组，结果可能无用。</li>
</ul>
</li>
<li>基于实例的算法（Instance-based Algorithms）<ul>
<li>概念：基于实例的算法（有时也称为基于记忆的学习）是这样学习算法，不是明确归纳，而是将新的问题例子与训练过程中见过的例子进行对比，这些见过的例子就在存储器中。之所以叫基于实例的算法是因为它直接从训练实例中建构出假设。这意味这，假设的复杂度能随着数据的增长而变化：最糟的情况是，假设是一个训练项目列表，分类一个单独新实例计算复杂度为 O（n）</li>
<li>案例：K 最近邻（k-Nearest Neighbor (kNN)）、学习向量量化（Learning Vector Quantization (LVQ)）、自组织映射（Self-Organizing Map (SOM)）、局部加权学习（Locally Weighted Learning (LWL)）</li>
<li>优点：算法简单、结果易于解读</li>
<li>缺点：内存使用非常高。计算成本高。不可能用于高维特征空间。</li>
</ul>
</li>
<li>贝叶斯算法（Bayesian Algorithms）<ul>
<li>概念：贝叶斯方法是指明确应用了贝叶斯定理来解决如分类和回归等问题的方法。</li>
<li>案例：朴素贝叶斯（Naive Bayes）、高斯朴素贝叶斯（Gaussian Naive Bayes）、多项式朴素贝叶斯（Multinomial Naive Bayes）、平均一致依赖估计器（Averaged One-Dependence Estimators (AODE)）、贝叶斯信念网络（Bayesian Belief Network (BBN)）、贝叶斯网络（Bayesian Network (BN)）</li>
<li>优点：快速、易于训练、给出了它们所需的资源能带来良好的表现</li>
<li>缺点：如果输入变量是相关的，则会出现问题</li>
</ul>
</li>
<li>关联规则学习算法（Association Rule Learning Algorithms）0008–</li>
<li><ul>
<li>概念：关联规则学习方法能够提取出对数据中的变量之间的关系的最佳解释。比如说一家超市的销售数据中存在规则 {洋葱，土豆}=&gt; {汉堡}，那说明当一位客户同时购买了洋葱和土豆的时候，他很有可能还会购买汉堡肉。</li>
<li>案例：Apriori 算法（Apriori algorithm）、Eclat 算法（Eclat algorithm）、FP-growth </li>
</ul>
</li>
<li>图模型（Graphical Models）<ul>
<li>概念：图模型或概率图模型（PGM/probabilistic graphical model）是一种概率模型，一个图（graph）可以通过其表示随机变量之间的条件依赖结构（conditional dependence structure）。</li>
<li>案例：贝叶斯网络（Bayesian network）、马尔可夫随机域（Markov random field）、链图（Chain Graphs）、祖先图（Ancestral graph）</li>
<li>优点：模型清晰，能被直观地理解</li>
<li>缺点：确定其依赖的拓扑很困难，有时候也很模糊</li>
</ul>
</li>
</ul>
<p>常用算法边界预测对比</p>
<p><img src="/images/2017/spring/机器学习算法边界预测.png" alt="机器学习算法边界预测"></p>
<blockquote>
<h4 id="1-2-3-定理"><a href="#1-2-3-定理" class="headerlink" title="1.2.3 定理"></a>1.2.3 定理</h4></blockquote>
<h5 id="1-2-3-1-没有免费午餐定理"><a href="#1-2-3-1-没有免费午餐定理" class="headerlink" title="1.2.3.1 没有免费午餐定理"></a>1.2.3.1 没有免费午餐定理</h5><p>没有免费午餐定理(No Free Lunch Theorem，NFL) 是由Wolpert和Macerday在最优化理论中提出的。没有免费午餐定理证明：对于基于迭代的最优化算法，不存在某种算法对所有问题（有限的搜索空间内）都有效。如果一个算法对某些问题有效，那么它一定在另外一些问题上比纯随机搜索算法更差。也就是说，不能脱离具体问题来谈论算法的优劣，任何算法都有局限性。必须要“具体问题具体分析”。<br>没有免费午餐定理对于机器学习算法也同样适用。不存在一种机器学习算法适合于任何领域或任务。如果有人宣称自己的模型在所有问题上都好于其他模型，那么他肯定是在吹牛。</p>
<h5 id="1-2-3-2-丑小鸭定理"><a href="#1-2-3-2-丑小鸭定理" class="headerlink" title="1.2.3.2 丑小鸭定理"></a>1.2.3.2 丑小鸭定理</h5><p>丑小鸭定理（Ugly Duckling）1960年代，美籍日本学者渡边慧提出了丑的鼻祖之一。 小鸭定理：“丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大”。这个定理初看好像不符合常识，但是仔细思考后是非常有道理的。因为世界上不存在相似性的客观标准，一切相似性的标准都是主观的。如果以体型大小的角度来看，丑小鸭和白天鹅的区别大于两只白天鹅的区别；但是如果以基因的角度来看，丑小鸭与它父母的差别要小于他父母和其他白天鹅之间的差别。</p>
<blockquote>
<h4 id="1-2-4-学习网站"><a href="#1-2-4-学习网站" class="headerlink" title="1.2.4 学习网站"></a>1.2.4 学习网站</h4></blockquote>
<p>清晰的查询出相关算法的知识拓扑图。</p>
<p><a href="https://metacademy.org/roadmaps/cjrd/coursera_ml_supplement" target="_blank" rel="external">metacademy.org</a></p>
<h3 id="1-3-神经元与感知机"><a href="#1-3-神经元与感知机" class="headerlink" title="1.3 神经元与感知机"></a>1.3 神经元与感知机</h3><p>神经元是构成神经网络的基础单元，先归纳一下神经元模型。</p>
<blockquote>
<h4 id="1-3-1-神经元"><a href="#1-3-1-神经元" class="headerlink" title="1.3.1 神经元"></a>1.3.1 神经元</h4></blockquote>
<p><img src="/images/2017/spring/神经元.png" alt="神经元"></p>
<p>神经元通过电信号和化学信号传递兴奋或者抑制。</p>
<p>其行为可以解释为：<br><img src="/images/2017/spring/神经元行为.png" alt="神经元行为"></p>
<p>其中：x是输入电信号（向量），y是输出电信号（output），x，y的个数是突触的个数（维度），W是各个神经元连接强弱，a()是化学传递（激活函数，非线性能力）。大量神经元就可学习过去到未来的关联。</p>
<blockquote>
<h4 id="1-3-2-MP模型"><a href="#1-3-2-MP模型" class="headerlink" title="1.3.2 MP模型"></a>1.3.2 MP模型</h4></blockquote>
<p>总结神经元特点</p>
<ul>
<li>每个神经元都是一个多输入单输出的信息处理单元</li>
<li>神经元输入分兴奋性输入和抑制性输入两种类型</li>
<li>神经元具有空间整合特性和阈值特性</li>
<li>神经元输入与输出间有固定的时滞，主要取决于突触延搁</li>
</ul>
<p>心理学家Mcculloch和数理逻辑学家Pitts合作提出的M-P模型。<br>相比于神经元，MP模型忽略时间整合作用、不应期等复杂因素，并把神经元的突触时延和强度当成常数。</p>
<p><img src="/images/2017/spring/神经元模型.png" alt="神经元模型"></p>
<p><img src="/images/2017/spring/MP模型对比.png" alt="MP模型对比"></p>
<p>其中，<code>激活函数</code>（activation function）加入非线性因素的，因为线性模型的表达能力不够。例如，在实现分类器功能时，参数与权重的点积是线性的，在做分类运算时只能在数据轴上画一条直线，而在让该点积经过激活函数 y = f(a) 处理后，加入了非线性因素，使直线变成曲线，这时分类器的表达能力更好。</p>
<h5 id="1-3-2-1-激活函数"><a href="#1-3-2-1-激活函数" class="headerlink" title="1.3.2.1 激活函数"></a>1.3.2.1 激活函数</h5><p>如果没有激活函数，网络仅能够表达线性映射，即便有再多的隐藏层，整个网络跟单层神经网络也是等价的。因此也可以认为，只有加入了激活函数之后，深度神经网络才具备了分层的非线性映射的学习能力。</p>
<p>常用的神经元非线性激发函数有阈值型、分段线性型、Sigmoid函数型（简称S型）和双曲正切型</p>
<p><img src="/images/2017/spring/激活函数.png" alt="激活函数"></p>
<p>其中sigmoid函数曲线错误，详细神经网络激活函数见1.3.4.</p>
<blockquote>
<h4 id="1-3-3-感知机（Perceptron）"><a href="#1-3-3-感知机（Perceptron）" class="headerlink" title="1.3.3 感知机（Perceptron）"></a>1.3.3 感知机（Perceptron）</h4></blockquote>
<h5 id="1-3-3-1-概念"><a href="#1-3-3-1-概念" class="headerlink" title="1.3.3.1 概念"></a>1.3.3.1 概念</h5><p>感知机（perceptron）是二分类的线性分类模型，属于监督学习算法。输入为实例的特征向量，输出为实例的类别。感知机是神经网络和支持向量机的基础。</p>
<p>1957年美国学者Rosenblatt提出了一类具有自学习能力的感知器模型，它是一个具有单层计算单元的前向神经网络，其神经元为线性阈值单元，称为单层感知器。也就是说:</p>
<pre><code>神经元之间的连接权值wi是可变的，这种可变性就保证了感知器具有学习能力。
</code></pre><p>1959 年Rosenblatt提出了感知器模型中连接权值参数的学习算法。算法的思想是首先把连接权值和阈值初始化为较小的非零随机数，然后把有n个连接权值的输入送入网络，经加权运算处理，得到的输出如果与所期望的输出有较大的差别，就对连接权值参数按照某种算法进行自动调整，经过多次反复，直到所得到的输出与所期望的输出间的差别满足要求为止。</p>
<p><img src="/images/2017/spring/感知机.png" alt="感知机"></p>
<h5 id="1-3-3-2-分类"><a href="#1-3-3-2-分类" class="headerlink" title="1.3.3.2 分类"></a>1.3.3.2 分类</h5><p>已知存在感知机</p>
<pre><code>f(x) = sign ( w * x + b )
</code></pre><p>w是权重weight，b是偏置bias，sign是符号函数</p>
<pre><code>f(x)=    +1    if x &gt;= 0
        −1    else
</code></pre><p>目标：找到一个最佳的满足 w * x + b = 0 的 w 和 b 值，即分离超平面（separating hyperplane）将样本分为正样本和负样本。</p>
<p>问题转换为优化问题：<code>最小化损失函数</code></p>
<p>误分类点(x0, y0)到超平面 w * x + b = 0 的距离为 </p>
<pre><code>( w * x0 + b ) / ( w^2 + 1 )^1/2 
# 把( w^2 + 1 )^1/2 定义为 1/||w||，||w||为L2范式，满足高斯分布
</code></pre><p>且有</p>
<pre><code>−y0 * ( w * x0 + b) &gt; 0 
# 若(x0, y0)为正样本，y0为正，误分类后 w * x0 + b 为负，−y0 * ( w * x0 + b) 为正
# 若(x0, y0)为负样本，y0为负，误分类后 w * x0 + b 为正，−y0 * ( w * x0 + b) 为正
</code></pre><p>所有点到超平面的总距离为</p>
<pre><code>−1/||w|| * ∑ yi * | w * x0 + b |
</code></pre><p>定义损失函数 </p>
<pre><code>L(x, b) = −∑ yi * ( w * x0 + b )
</code></pre><p>则</p>
<pre><code>(1) 初始化w0,b0，权值可以初始化为0或一个很小的随机数
(2) 在训练数据集中选取（x_i, y_i）
(3) 如果 yi * (w * xi + b) ≤ 0 # η为学习率（0&lt;η&lt;1）
       w = w + η * y_i * x_i
       b = b + η * y_i
(4) 转至（2）,直至训练集中没有误分类点
</code></pre><p>其中，损失函数详见1.3.5。</p>
<blockquote>
<h4 id="1-3-4-激活函数"><a href="#1-3-4-激活函数" class="headerlink" title="1.3.4 激活函数"></a>1.3.4 激活函数</h4></blockquote>
<p>性质</p>
<ul>
<li>可微性： 当优化方法是基于梯度的时候，这个性质是必须的。 </li>
<li>单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数。 </li>
<li>输出值的范围： 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate。</li>
</ul>
<p>流行激活函数对比</p>
<ul>
<li><p>Sigmoid函数：曾经是最常用的激活函数, 但现在一般只用在输出层, 中间层很少使用。</p>
<ul>
<li><p>缺点1: 两头平坦。梯度小, 在后向传播 (BP) 中, 逐层梯度乘以整个网络最终输出的梯度之后, 达到输入层时, 导致反传回去的梯度被消减掉，最终导致没有梯度信号更新权重。权值的改动小, 学习速度慢。</p>
<ul>
<li>缺点2：输出值域不对称，不是以零为中心的。[0,1], 只有正数, 没有负数。在梯度下降过程中的动力学角度来讲，这会导致一个潜在问题：如果数据流经神经元的时数据总是正的，那么在反向传播时，权重的梯度也将全部变为正的，或者全部变为负的，对于权重的梯度更新来说，导致一个不好的锯齿状梯度。</li>
</ul>
<p><img src="/images/2017/spring/sigmoid函数.png" alt="sigmoid函数"></p>
</li>
</ul>
</li>
<li><p>tanh函数：曾经是最常用的激活函数, 中间层较少使用, 但比Sigmoid效果好。</p>
<ul>
<li>优点: 输出值域对称。[-1,1]</li>
<li>缺点: 两头依旧过于平坦<br><img src="/images/2017/spring/tanh函数.png" alt="tanh函数"></li>
</ul>
</li>
<li><p>ReLU (Rectified Linear Unit)</p>
<ul>
<li>优点1：不存在饱和(saturate)区域</li>
<li>优点2：收敛速度比sigmoid/tannh函数快</li>
<li>优点3：计算高效简单，没有引入计算复杂高的操作</li>
<li>缺点1：Dead Area: ReLU 函数单元在训练过程中比较脆弱，神经元死亡, 输出为0, 权重不更新</li>
</ul>
</li>
<li><p>Leaky ReLU </p>
<ul>
<li>优点：解决 ReLU 死亡问题，没有 Dead Area.<br><img src="/images/2017/spring/ReLU函数.png" alt="ReLU函数"></li>
</ul>
</li>
<li><p>Parametric ReLU：负数部分的斜率是从数据当中学习得到的，而不是预先定义的。</p>
</li>
<li>Randomized ReLU：负值部分的斜率值在给定范围内是随机选取的，而在测试时，参数值会被确定下来。</li>
<li>Maxout：maxout 是 ReLU 或 Leaky ReLU 的更一般形式<ul>
<li>优点：非线性但不具有饱和性，不会死掉</li>
<li>缺点：训练的参数是原本的两倍</li>
</ul>
</li>
</ul>
<blockquote>
<h4 id="1-3-5-损失函数"><a href="#1-3-5-损失函数" class="headerlink" title="1.3.5 损失函数"></a>1.3.5 损失函数</h4></blockquote>
<p>损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。</p>
<p><img src="/images/2017/spring/损失函数.png" alt="损失函数"></p>
<p>前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的ΦΦ是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是L1，也可以是L2，或者其他的正则函数。整个式子表示的意思是找到使目标函数最小时的θθ值。</p>
<ul>
<li><p>log对数损失函数（逻辑回归）</p>
<p>   有逻辑回归的损失函数不是平方损失。平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到，逻辑回归假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数，接着取对数求极值等等。逻辑回归没有求似然函数的极值，而把极大化当做是一种思想，进而推导出它的经验风险函数为：最小化负的似然函数（即max F(y, f(x)) —-&gt; min -F(y, f(x)))。从损失函数的视角来看，它就成了log损失函数了。</p>
<p>   利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说什么样的参数才能使我们观测到目前这组数据的概率最大</p>
</li>
<li><p>平方损失函数（最小二乘法, Ordinary Least Squares ）</p>
<p>  最小二乘法是线性回归的一种，OLS将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（中心极限定理）。最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。换言之，OLS是基于距离的，而这个距离就是我们用的最多的欧几里得距离。</p>
</li>
<li><p>指数损失函数（Adaboost）</p>
<p>  学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。</p>
</li>
<li><p>Hinge损失函数（SVM）</p>
</li>
<li>0-1损失函数</li>
<li>绝对值损失函数</li>
</ul>
<p><img src="/images/2017/spring/学习率与损失曲线.png" alt="学习率与损失曲线"></p>
<p>分类问题的损失函数，从信息论的角度看，等价于训练出来的模型（分布）与真实模型（分布）之间的交叉熵（两者相差一个只和样本数据量有关的倍数N），而这个交叉熵的大小，衡量了训练模型与真实模型之间的差距，交叉熵越小，两者越接近，从而说明模型越准确。</p>
<h3 id="1-4-抽象层级与层"><a href="#1-4-抽象层级与层" class="headerlink" title="1.4 抽象层级与层"></a>1.4 抽象层级与层</h3><p>把相同结构的神经单元组合在一起，构成神经网络的层:</p>
<ul>
<li>输入层 输入向量</li>
<li>中间层 (隐含层)</li>
<li>输出层 输出向量, 用于预测, 分类以及回归 </li>
</ul>
<p>抽象层级越高，层越多。</p>
<p>2012年多伦多大学的Krizhevsky等人构造了一个超大型卷积神经网络，有9层，共65万个神经元，6千万个参数。网络的输入是图片，输出是1000个类，比如小虫、美洲豹、救生船等等。这个模型的训练需要海量图片，它的分类准确率也完爆先前所有分类器。纽约大学的Zeiler和Fergusi把这个网络中某些神经元挑出来，把在其上响应特别大的那些输入图像放在一起，看它们有什么共同点。他们发现中间层的神经元响应了某些十分抽象的特征。</p>
<ul>
<li>第一层神经元主要负责识别颜色和简单纹理</li>
<li>第二层的一些神经元可以识别更加细化的纹理，比如布纹、刻度、叶纹。</li>
<li>第三层的一些神经元负责感受黑夜里的黄色烛光、鸡蛋黄、高光。</li>
<li>第四层的一些神经元负责识别萌狗的脸、七星瓢虫和一堆圆形物体的存在。</li>
<li>第五层的一些神经元可以识别出花、圆形屋顶、键盘、鸟、黑眼圈动物。</li>
</ul>
<blockquote>
<h4 id="1-4-1-层的基本变换"><a href="#1-4-1-层的基本变换" class="headerlink" title="1.4.1 层的基本变换"></a>1.4.1 层的基本变换</h4></blockquote>
<p>通过表达式：y⃗ =a(W⋅x⃗ +b)得知，x的输入空间转换为y的输出空间，其中W进行升维降维、放大缩小、旋转。b进行平移，a对空间进行弯曲。</p>
<h3 id="1-5-神经网络-ANN"><a href="#1-5-神经网络-ANN" class="headerlink" title="1.5 神经网络 ANN"></a>1.5 神经网络 ANN</h3><p><img src="/images/2017/spring/神经网络历史.png" alt="神经网络历史"></p>
<blockquote>
<h4 id="1-5-1-理解"><a href="#1-5-1-理解" class="headerlink" title="1.5.1 理解"></a>1.5.1 理解</h4><p>神经网络是最具代表性的机器学习的算法，同时也是深度学习的基础。</p>
</blockquote>
<p><img src="/images/2017/spring/神经网络.png" alt="神经网络"></p>
<p>这是最常见的多层前馈神经网络（multi-layer feedforward neural networks）。不难看出，神经网络的学习其实就是调整各神经元之间的连接权（connection weight）以及各神经元的阈值。</p>
<p>由图可知，我们可以拖通过</p>
<ul>
<li>增加节点数 : 增加维度，即增加线性转换能力。</li>
<li>增加层数 : 增加激活函数的次数，即增加非线性转换次数。</li>
</ul>
<p>将原始输入空间投向线性可分/稀疏的空间去分类/回归。</p>
<p><img src="/images/2017/spring/前馈神经网络.png" alt="前馈神经网络"></p>
<blockquote>
<h4 id="1-5-2-概念"><a href="#1-5-2-概念" class="headerlink" title="1.5.2 概念"></a>1.5.2 概念</h4></blockquote>
<p>维基百科：‘神经网络’（Neural Network）是一种模仿生物神经网络的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应系统。现代神经网络是一种非线性统计性数据建模工具。典型的神经网络具有以下三个部分:</p>
<ul>
<li>结构 （Architecture)</li>
<li>激励函数（Activity Rule)</li>
<li>学习规则（Learning Rule）</li>
</ul>
<p>人工神经网络模型主要考虑网络连接的拓扑结构、神经元的特征、学习规则等。目前，已有近 40 种神经网络模型。</p>
<ul>
<li>前馈神经网络:也经常称为多层感知器(Multilayer Perceptron， MLP)。</li>
<li>反馈神经网络:网络内神经元间有反馈，可以用一个无向的完备图表示。这种神经网络的信息处理是状态的变换，可以用动力学系统理论处理。</li>
</ul>
<p><img src="/images/2017/spring/神经网络导图.png" alt="神经网络导图"></p>
<p><a href="http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html" target="_blank" rel="external">神经网络 - demo</a></p>
<blockquote>
<h4 id="1-5-3-误差逆传播算法（BackPropagation-BP）"><a href="#1-5-3-误差逆传播算法（BackPropagation-BP）" class="headerlink" title="1.5.3 误差逆传播算法（BackPropagation BP）"></a>1.5.3 误差逆传播算法（BackPropagation BP）</h4></blockquote>
<p>感知机的学习过程在线性不可分时会发生振荡（fluctuation），难以稳定。对于多层感知器中的隐层，因为无法直接得到其输出值，不能直接使用损失。这时，就需要将损失从顶层反向传播（Back Propagate）到隐层，来完成参数估计的目标。BP是迄今最成功的神经网络学习算法，现实任务中使用神经网络大多是使用BP。一般而言，BP神经网络是指用BP算法训练的多层前馈神经网络，但BP算法也能训练其他类型的神经网络，如递归神经网络。</p>
<p><img src="/images/2017/spring/BP.png" alt="BP"></p>
<p>步骤</p>
<ol>
<li>先将输入实例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果</li>
<li>计算输出层误差，计算输出层神经元梯度项，再将误差逆向传播至隐层神经元</li>
<li>最后根据隐层神经元的误差对连接权和阈值进行调整</li>
<li>该迭代过程循环进行，直到达到某些同志条件为止。例如训练误差已经达到一个很小的值。</li>
</ol>
<p><code>思考</code><br>多层感知器存在的最大的问题就是，它是一个全连接的网络，因此在输入比较大的时候，权值会特别多。比如一个有1000个节点的隐层，连接到一个1000×1000的图像上，那么就需要 10^9 个权值参数（外加1000个偏置参数）！这个问题，一方面限制了每层能够容纳的最大神经元数目，另一方面也限制了多层感知器的层数即深度。多层感知器的另一个问题是梯度发散。一般情况下，我们需要把输入归一化，而每个神经元的输出在激活函数的作用下也是归一化的；另外，有效的参数其绝对值也一般是小于1的；这样，在BP过程中，多个小于1的数连乘，得到的会是更小的值。也就是说，在深度增加的情况下，从后传播到前边的残差会越来越小，甚至对更新权值起不到帮助，从而失去训练效果，使得前边层的参数趋于随机化（补充一下，其实随机参数也是能一定程度上捕捉到图像边缘的）。</p>
<blockquote>
<h4 id="1-5-4-其他神经网络"><a href="#1-5-4-其他神经网络" class="headerlink" title="1.5.4 其他神经网络"></a>1.5.4 其他神经网络</h4></blockquote>
<ul>
<li><p>RBF（Radial Basis Function）网络</p>
<p>  单隐层前馈神经网络，它使用径向基函数作为隐层神经元的激活函数。输出层则直接使用隐层神经元的线性组合。</p>
</li>
<li><p>ART（Adaptive Resonance Theory，自适应谐振理论）网络</p>
<p>  竞争型学习的重要代表。该网络由四部份组成：比较层、识别层、识别阈值、重置模块。比较层就是输入层，只负责把样本传递给识别层。识别层也即输出层，但识别层的每个神经元对应一个模式类，而且神经元的数目可以在训练过程中动态增加以增加新的模式类。ART能有效缓解竞争型学习中的可塑性-稳定性窘境（stability-plasticity dilemma），ART具备可塑性和稳定性，因此能进行增量学习（incremental learning）和在线学习（online learning）。</p>
</li>
<li><p>SOM（Self-Organizing Map，自组织映射）网络</p>
<p>  又称为自组织特征映射网络或Kohonen网络。同样是一种竞争学习型无监督神经网络，只有输入层和输出层两层，输出层以矩阵形式排列。与样本距离最近的输出层神经元获胜，称为最佳匹配单元（best matching unit）。最佳匹配单元和邻近神经元的权向量会被调整，使得下次遇到相似的样本时距离更小。如此迭代，直至收敛。</p>
</li>
<li><p>级联相关（Cascade-Correlation）网络</p>
<p>  典型的结构自适应网络，这类网络不仅通过训练来学习合适的连接权和阈值等参数，还会在训练过程中找到最符合数据特点的网络结构。</p>
</li>
<li><p>递归神经网络（recurrent neural networks，简称RNN）</p>
<p>  允许网络中出现环形结构，即一些神经元的输出可以反馈回来当输入信号，从而能够处理与时间有关的动态变化。Elman网络是最常用的递归神经网络之一，只有一个隐层，并且隐层神经元的输出会被反馈，在下一时刻与输入层神经元的输入信号一起作为隐层神经元的新输入。隐层神经元一般采用Sigmoid函数作为激活函数，并用BP算法训练整个网络。</p>
</li>
</ul>
<blockquote>
<h2 id="第二章：python实现最简神经网络"><a href="#第二章：python实现最简神经网络" class="headerlink" title="第二章：python实现最简神经网络"></a>第二章：python实现最简神经网络</h2></blockquote>
<p>用python实现，BP反向传播算法，单层神经网络，双重神经网络。</p>
<pre><code>X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])
y = np.array([[0,1,1,0]]).T
syn0 = 2*np.random.random((3,4)) - 1
syn1 = 2*np.random.random((4,1)) - 1
    for j in xrange(60000):
        l1 = 1/(1+np.exp(-(np.dot(X,syn0))))
    l2 = 1/(1+np.exp(-(np.dot(l1,syn1))))
    l2_delta = (y - l2)*(l2*(1-l2))
    l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))
    syn1 += l1.T.dot(l2_delta)
    syn0 += X.T.dot(l1_delta)
</code></pre><h3 id="2-1-一个简洁的神经网络"><a href="#2-1-一个简洁的神经网络" class="headerlink" title="2.1 一个简洁的神经网络"></a>2.1 一个简洁的神经网络</h3><p>给定三列输入，试着去预测对应的一列输出。我们可以通过简单测量输入与输出值的数据来解决这一问题。这样一来，我们可以发现最左边的一列输入值和输出值是完美匹配/完全相关的。直观意义上来讲，反向传播算法便是通过这种方式来衡量数据间统计关系进而得到模型的。</p>
<table>
<thead>
<tr>
<th>input</th>
<th></th>
<th></th>
<th>oytput</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<h3 id="2-2-两层神经网络"><a href="#2-2-两层神经网络" class="headerlink" title="2.2 两层神经网络"></a>2.2 两层神经网络</h3><pre><code>import numpy as np

# sigmoid function 非线性映射
def nonlin(x,deriv=False): # 用输出值便可以得到其导数值
    if(deriv==True):
        return x*(1-x)
    return 1/(1+np.exp(-x))

# input dataset
X = np.array([  [0,0,1],
                    [0,1,1],
                    [1,0,1],
                    [1,1,1] ])

# output dataset            
y = np.array([[0,0,1,1]]).T # “.T” 为转置函数

# seed random numbers to make calculation
# deterministic (just a good practice)
np.random.seed(1)

# initialize weights randomly with mean 0
syn0 = 2*np.random.random((3,1)) - 1 # 神经网络权重矩阵的初始化操作

for iter in xrange(10000): # 训练
    # forward propagation
    l0 = X
    l1 = nonlin(np.dot(l0,syn0)) # 前向预测阶段

    # how much did we miss? 误差
    l1_error = y - l1

        # multiply how much we missed by the 
    # slope of the sigmoid at the values in l1
    l1_delta = l1_error * nonlin(l1,True)

    # update weights
    syn0 += np.dot(l0.T,l1_delta)
print &quot;Output After Training:&quot;
print l1 
</code></pre><p>结果为</p>
<pre><code>Output After Training:
[[ 0.00966449]
[ 0.00786506]
[ 0.99358898]
[ 0.99211957]]
</code></pre><p>变量说明</p>
<table>
<thead>
<tr>
<th>变量</th>
<th>定义说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>X</td>
<td>输入数据集，形式为矩阵，每 1 行代表 1 个训练样本。</td>
</tr>
<tr>
<td>y</td>
<td>输出数据集，形式为矩阵，每 1 行代表 1 个训练样本。</td>
</tr>
<tr>
<td>l0</td>
<td>网络第 1 层，即网络输入层。</td>
</tr>
<tr>
<td>l1</td>
<td>网络第 2 层，常称作隐藏层。</td>
</tr>
<tr>
<td>syn0</td>
<td>第一层权值，突触 0 ，连接 l0 层与 l1 层。</td>
</tr>
</tbody>
</table>
<h3 id="2-3-复杂神经网络"><a href="#2-3-复杂神经网络" class="headerlink" title="2.3 复杂神经网络"></a>2.3 复杂神经网络</h3><p>给定前两列输入，尝试去预测输出列】，这两列与输出不存在任何关联，可以视为一种“非线性”模式，单个输入与输出间不存在一个一对一的关系。而输入的组合与输出间存在着一对一的关系，在这里也就是列 1 和列 2 的组合。我们需要额外增加一个网络层。第一层对输入进行组合，然后以第一层的输出作为输入，通过第二层的映射得到最终的输出结果。</p>
<table>
<thead>
<tr>
<th>input</th>
<th></th>
<th></th>
<th>Hidden Weight</th>
<th></th>
<th></th>
<th></th>
<th>output</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0.1</td>
<td>0.2</td>
<td>0.5</td>
<td>0.2</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0.2</td>
<td>0.6</td>
<td>0.7</td>
<td>0.1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0.3</td>
<td>0.2</td>
<td>0.3</td>
<td>0.9</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0.2</td>
<td>0.1</td>
<td>0.3</td>
<td>0.8</td>
<td>0 </td>
</tr>
</tbody>
</table>
<pre><code>import numpy as np

def nonlin(x,deriv=False):
    if(deriv==True):
        return x*(1-x)

    return 1/(1+np.exp(-x))

X = np.array([[0,0,1],
            [0,1,1],
            [1,0,1],
            [1,1,1]])

y = np.array([[0],
            [1],
            [1],
            [0]])

np.random.seed(1)

# randomly initialize our weights with mean 0
syn0 = 2*np.random.random((3,4)) - 1
syn1 = 2*np.random.random((4,1)) - 1

for j in xrange(60000):

    # Feed forward through layers 0, 1, and 2
    l0 = X
    l1 = nonlin(np.dot(l0,syn0))
    l2 = nonlin(np.dot(l1,syn1))

    # how much did we miss the target value?
    l2_error = y - l2

    if (j% 10000) == 0:
        print &quot;Error:&quot; + str(np.mean(np.abs(l2_error)))

    # in what direction is the target value?
    # were we really sure? if so, don&apos;t change too much.
    l2_delta = l2_error*nonlin(l2,deriv=True)

    # how much did each l1 value contribute to the l2 error (according to the weights)?
    l1_error = l2_delta.dot(syn1.T) # 置信度加权”，构建  l1  层相应的误差

    # in what direction is the target l1?
    # were we really sure? if so, don&apos;t change too much.
    l1_delta = l1_error * nonlin(l1,deriv=True)

    syn1 += l1.T.dot(l2_delta)
    syn0 += l0.T.dot(l1_delta)
</code></pre><p>变量说明</p>
<table>
<thead>
<tr>
<th>变量</th>
<th>定义说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>X</td>
<td>输入数据集，形式为矩阵，每 1 行代表 1 个训练样本。</td>
</tr>
<tr>
<td>y</td>
<td>输出数据集，形式为矩阵，每 1 行代表 1 个训练样本。</td>
</tr>
<tr>
<td>l0</td>
<td>网络第 1 层，即网络输入层。</td>
</tr>
<tr>
<td>l1</td>
<td>网络第 2 层，常称作隐藏层。</td>
</tr>
<tr>
<td>l2</td>
<td>假定为网络最后一层，随着训练进行，其输出应该逐渐接近正确结果</td>
</tr>
<tr>
<td>syn0</td>
<td>第一层权值，突触 0 ，连接 l0 层与 l1 层。</td>
</tr>
<tr>
<td>syn1</td>
<td>第二层权值，突触 1 ，连接 l1 层与 l2 层。</td>
</tr>
<tr>
<td>l2_error</td>
<td>该值说明了神经网络预测时“丢失”的数目。</td>
</tr>
<tr>
<td>l2_delta</td>
<td>该值为经确信度加权后的神经网络的误差，除了确信误差很小时，它近似等于预测误差。</td>
</tr>
<tr>
<td>l1_error</td>
<td>该值为 l2_delta 经 syn1 加权后的结果，从而能够计算得到中间层/隐层的误差。</td>
</tr>
<tr>
<td>l1_delta</td>
<td>该值为经确信度加权后的神经网络 l1 层的误差，除了确信误差很小时，它近似等于 l1_error 。</td>
</tr>
</tbody>
</table>
<blockquote>
<h2 id="第三章：深度学习"><a href="#第三章：深度学习" class="headerlink" title="第三章：深度学习"></a>第三章：深度学习</h2></blockquote>
<h3 id="3-1-理解"><a href="#3-1-理解" class="headerlink" title="3.1 理解"></a>3.1 理解</h3><p><img src="/images/2017/spring/神经网络类别.png" alt="神经网络类别"></p>
<ul>
<li>深度网络（DNN）: 学习的是函数</li>
<li>卷积神经网络（CNN）: 学习的是特征</li>
<li>循环神经网络（RNN）: 学习的是程序</li>
</ul>
<p>神经网络使用<code>并行</code>的先验知识使得模型可用线性回归，数据样本学习要求大。而深度学习比浅层神经网络更高效，因为<code>迭代</code>组成的先验知识使得样本可用于帮助训练其他共用同样底层结构的样本。</p>
<p>多层神经网络的限制</p>
<ul>
<li><p>面对大数据时，需要人为提取原始数据的特征作为输入，这个问题前面的知友提到过@杨延生。必须忽略不相关的变量，同时保留有用的信息。这个尺度很难掌握，多层神经网络会把蹲在屋顶的Kitty和骑在猫奴头上的Kitty识别为不同的猫咪，又会把二哈和狼归类为同一种动物。前者是对不相关变量过于敏感，后者则因无法提取有实际意义的特征。</p>
</li>
<li><p>想要更精确的近似复杂的函数，必须增加隐藏层的层数，这就产生了梯度扩散问题。所谓“强弩之末势不能穿鲁缟“。</p>
</li>
<li><p>无法处理时间序列数据（比如音频），因为多层神经网络不含时间参数。随着人工智能需求的提升，我们想要做复杂的图像识别，做自然语言处理，做语义分析翻译，等等。多层神经网络显然力不从心。</p>
</li>
</ul>
<p>那么深度模型是如何解决以上三个问题的。</p>
<ul>
<li><p>深度学习自动选择原始数据的特征。举一个图像的例子，将像素值矩阵输入深度网络，网络第一层表征物体的位置、边缘、亮度等初级视觉信息。第二层将边缘整合表征物体的轮廓……之后的层会表征更加抽象的信息，如猫或狗这样的抽象概念。所有特征完全在网络中自动呈现，并非出自人工设计。更重要的一点是这种随着层的深入，从具象到抽象的层级式表征跟大脑的工作原理吻合，视网膜接收图像从LGN到视皮层、颞叶皮层再到海马走的是同样的路数！</p>
</li>
<li><p>深度网络的学习算法。一种方法是改变网络的组织结构，比如用卷积神经网络代替全连接（full connectivity）网络，训练算法仍依据Backpropagating gradients的基本原理。另一种则是彻底改变训练算法，我尝试过的算法有Hessian-free optimization[3]，recursive least-squares(RLS)等。</p>
</li>
<li><p>使用带反馈和时间参数的Recurrent neural network处理时间序列数据。从某种意义上讲，Recurrent neural network可以在时间维度上展开成深度网络，可以有效处理音频信息，或者用来模拟动力系统。</p>
</li>
</ul>
<p><code>深度学习</code>是一种参数多，模型复杂度高，容量大的模型。，通过多个隐层，将低层特征转换为高层特征，用于完成更复杂的学习任务。</p>
<p><img src="/images/2017/spring/深度学习.png" alt="深度学习"></p>
<h3 id="3-2-概念"><a href="#3-2-概念" class="headerlink" title="3.2 概念"></a>3.2 概念</h3><p>多层神经网络与universal approximation theorem（泛逼近性原理）相伴而生。该理论指出，单隐藏层（hidden layer）非线性前馈神经网络，可以在实数空间近似任何连续函数</p>
<p>“深度学习”是为了让层数较多的多层神经网络可以训练，能够work而演化出来的一系列的新的结构和新的方法。新的网络结构中最著名的就是CNN，它解决了传统较深的网络参数太多，很难训练的问题，使用了“局部感受野”和“权植共享”的概念，大大减少了网络参数的数量。关键是这种结构确实很符合视觉类任务在人脑上的工作原理。新的结构还包括了：LSTM，ResNet等。新的方法就多了：新的激活函数：ReLU，新的权重初始化方法（逐层初始化，XAVIER等），新的损失函数，新的防止过拟合方法（Dropout, BN等）。这些方面主要都是为了解决传统的多层神经网络的一些不足：梯度消失，过拟合等。</p>
<h3 id="3-3-训练方式"><a href="#3-3-训练方式" class="headerlink" title="3.3 训练方式"></a>3.3 训练方式</h3><ul>
<li><p>无监督逐层训练（unsupervised layer-wise training）：每次训练一层隐结点，把上一层隐结点的输出当作输入来训练，本层隐结点训练好后，输出再作为下一层的输入来训练，这称为预训练（pre-training）。全部预训练完成后，再对整个网络进行微调（fine-tuning）训练。一个典型例子就是深度信念网络（deep belief network，简称DBN）。这种做法其实可以视为把大量的参数进行分组，先找出每组较好的设置，再基于这些局部最优的结果来训练全局最优。</p>
</li>
<li><p>权共享（weight sharing）：令同一层神经元使用完全相同的连接权，典型的例子是卷积神经网络（Convolutional Neural Network，简称CNN）。这样做可以大大减少需要训练的参数数目。</p>
</li>
</ul>
<h3 id="3-4-递归神经网络"><a href="#3-4-递归神经网络" class="headerlink" title="3.4 递归神经网络"></a>3.4 递归神经网络</h3><p>递归神经网络（RNN）是两种人工神经网络的总称。一种是时间递归神经网络（recurrent neural network），另一种是结构递归神经网络（recursive neural network）。主要处理序列数据（诸如文本、语言）。</p>
<p>一般而言，RNN指时间递归神经网络（recurrent neural network），也叫循环递归网络。</p>
<ul>
<li>RNN不仅仅能够处理序列输出, 也能得到序列输出, 这里序列指的是向量的序列</li>
<li>RNN学习出来的是程序, 不是函数</li>
</ul>
<p><img src="/images/2017/spring/循环神经网络例子.png" alt="循环神经网络例子"></p>
<p>每个正方形代表一个向量，箭头代表函数（比如矩阵乘法）。输入向量是红色，输出向量是蓝色，绿色向量装的是RNN的状态。上图从左至右依次为：</p>
<ul>
<li>非RNN的普通过程，从固定尺寸的输入到固定尺寸的输出（比如图像分类）。</li>
<li>输出是序列（例如图像标注：输入是一张图像，输出是单词的序列）。</li>
<li>输入是序列（例如情绪分析：输入是一个句子，输出是对句子属于正面还是负面情绪的分类）。</li>
<li>输入输出都是序列（比如机器翻译：RNN输入一个英文句子输出一个法文句子）。</li>
<li>同步的输入输出序列（比如视频分类中，我们将对视频的每一帧都打标签）</li>
</ul>
<blockquote>
<h4 id="3-4-1-记忆抽象"><a href="#3-4-1-记忆抽象" class="headerlink" title="3.4.1 记忆抽象"></a>3.4.1 记忆抽象</h4></blockquote>
<p>若RNN是一个类，存在API只包含一个step方法：则step方法接收输入向量x，返回输出向量y。然而这个输出向量的内容不仅被输入数据影响，而且会收到整个历史输入的影响。</p>
<pre><code>rnn = RNN()
y = rnn.step(x) # x is an input vector, y is the RNN&apos;s output vector
</code></pre><p>每当step方法被调用的时候，RNN的内部状态就被更新。在最简单情况下，该内部装着仅包含一个内部隐向量h。下面是一个普通RNN的step方法的实现：</p>
<pre><code>class RNN:
  # ...
  def step(self, x):
    # update the hidden state
    self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))
    # compute the output vector
    y = np.dot(self.W_hy, self.h)
    return y
</code></pre><p>以上代码说明了普通RNN的前向传播。</p>
<p>更深层网络。</p>
<pre><code>y1 = rnn1.step(x)
y = rnn2.step(y1)
</code></pre><h3 id="3-5-卷积神经网络"><a href="#3-5-卷积神经网络" class="headerlink" title="3.5 卷积神经网络"></a>3.5 卷积神经网络</h3><p><a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="external">卷积神经网络</a></p>
<p><a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external"> cnn - example </a></p>
<p>卷积神经网络(Convolutional Neural Network, CNN)是深度学习技术中极具代表的网络结构之一，主要处理图像处理，避免对图像复杂的前期预处理过程（提取人工特征等），可以直接输入原始图像。</p>
<ul>
<li>由来：神经元网络的直接升级版</li>
<li>相关：Yann LeCun和他的LeNet</li>
<li>影响：在图像、语音领域不断突破，复兴了神经元网络并进入“深度学习”时代</li>
</ul>
<p>卷积神经网络沿用了普通的神经元网络即多层感知器的结构，是一个前馈网络。应用于图像领域。</p>
<p><img src="/images/2017/spring/CNN学习路线.png" alt="CNN"></p>
<blockquote>
<h4 id="3-5-1-网络结构"><a href="#3-5-1-网络结构" class="headerlink" title="3.5.1 网络结构"></a>3.5.1 网络结构</h4></blockquote>
<ul>
<li>输入图像I。为了减小复杂度，一般使用灰度图像。当然，也可以使用RGB彩色图像，此时输入图像有三张，分别为RGB分量。输入图像一般需要归一化，如果使用sigmoid激活函数，则归一化到[0, 1]，如果使用tanh激活函数，则归一化到[-1, 1]。</li>
<li>多个卷积（C）-下采样（S）层。将上一层的输出与本层权重W做卷积得到各个C层，然后下采样得到各个S层。怎么做以及为什么，下面会具体分析。这些层的输出称为Feature Map。</li>
<li>光栅化（X）。是为了与传统的多层感知器全连接。即将上一层的所有Feature Map的每个像素依次展开，排成一列。</li>
<li>传统的多层感知器（N&amp;O）。最后的分类器一般使用Softmax，如果是二分类，当然也可以使用LR。</li>
</ul>
<p>常用架构模式为：</p>
<pre><code>INPUT -&gt; [[CONV] * N -&gt; POOL?] * M -&gt; [FC] * K
</code></pre><p>也就是N个卷积层叠加，然后(可选)叠加一个Pooling层，重复这个结构M次，最后叠加K个全连接层。</p>
<p>对于图</p>
<p><img src="/images/2017/spring/积卷神经网络.png" alt="积卷神经网络"></p>
<p>网络结构为：</p>
<pre><code>INPUT -&gt; CONV -&gt; POOL -&gt; CONV -&gt; POOL -&gt; FC -&gt; FC
</code></pre><blockquote>
<h4 id="3-5-1-API及出发点"><a href="#3-5-1-API及出发点" class="headerlink" title="3.5.1 API及出发点"></a>3.5.1 API及出发点</h4></blockquote>
<pre><code>将输入3D体积转换为具有一些可能具有参数的可微函数的输出3D体积。
</code></pre><ul>
<li><p>局部感受野。</p>
<p>  形象地说，就是模仿你的眼睛，想想看，你在看东西的时候，目光是聚焦在一个相对很小的局部的吧？严格一些说，普通的多层感知器中，隐层节点会全连接到一个图像的每个像素点上，而在卷积神经网络中，每个隐层节点只连接到图像某个足够小局部的像素点上，从而大大减少需要训练的权值参数。举个栗子，依旧是1000×1000的图像，使用10×10的感受野，那么每个神经元只需要100个权值参数；不幸的是，由于需要将输入图像扫描一遍，共需要991×991个神经元！参数数目减少了一个数量级，不过还是太多。</p>
</li>
<li><p>权值共享</p>
<p>  形象地说，就如同你的某个神经中枢中的神经细胞，它们的结构、功能是相同的，甚至是可以互相替代的。也就是，在卷积神经网中，同一个卷积核内，所有的神经元的权值是相同的，从而大大减少需要训练的参数。继续上一个栗子，虽然需要991×991个神经元，但是它们的权值是共享的呀，所以还是只需要100个权值参数，以及1个偏置参数。从MLP的 10^9 到这里的100，就是这么狠！作为补充，在CNN中的每个隐藏，一般会有多个卷积核。</p>
</li>
<li><p>池化</p>
<p>  形象地说，你先随便看向远方，然后闭上眼睛，你仍然记得看到了些什么，但是你能完全回忆起你刚刚看到的每一个细节吗？同样，在卷积神经网络中，没有必要一定就要对原图像做处理，而是可以使用某种“压缩”方法，这就是池化，也就是每次将原图像卷积后，都通过一个下采样的过程，来减小图像的规模。以最大池化（Max Pooling）为例，1000×1000的图像经过10×10的卷积核卷积后，得到的是991×991的特征图，然后使用2×2的池化规模，即每4个点组成的小方块中，取最大的一个作为输出，最终得到的是496×496大小的特征图。</p>
</li>
</ul>
<blockquote>
<h4 id="3-5-2-局部连接与权值共享"><a href="#3-5-2-局部连接与权值共享" class="headerlink" title="3.5.2 局部连接与权值共享"></a>3.5.2 局部连接与权值共享</h4></blockquote>
<p><code>局部连接</code></p>
<p>1000 × 1000的输入图像，若下一个隐藏层的神经元数目为10^6个</p>
<ul>
<li>全连接：1000 × 1000 × 10^6 = 10^12个权值参数</li>
<li>局部连接：隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8</li>
</ul>
<p><code>权值共享</code></p>
<p>在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数。但是，这样仅提取了图像的一种特征，如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像的不同映射下的特征，称之为Feature Map。如果有100个卷积核，最终的权值参数也仅为100 × 100 = 10^4个而已。</p>
<blockquote>
<h4 id="3-5-3-卷积"><a href="#3-5-3-卷积" class="headerlink" title="3.5.3 卷积"></a>3.5.3 卷积</h4></blockquote>
<p>卷积层的作用是提取图像的各种特征</p>
<ul>
<li>卷积核尺寸: DHW, 卷积核的深度和输入图像是一致的</li>
<li>卷积滑动参数: stride/padding</li>
<li><p>每个卷积核带有一个bias</p>
<pre><code>require(&apos;nn&apos;)
img = torch.rand(3,5,5)    #输入x: 深度为3, 高和宽均为5

conv = nn.SpatialConvolution(3,2,3,3,2,2,1,1)
#参数分别表示输入深度(3),卷积核个数(2),卷积核的尺寸(3*3),
h方向的stride(2),w方向的stride(2),
h方向的padding大小(1),w方向的padding大小(1)(padding:补0或补重复数)

img_out=conv:forward(img)        #Forward计算
</code></pre></li>
</ul>
<p>假设有一个5 <em> 5的图像，使用一个3 </em> 3的filter进行卷积，想得到一个3 * 3的Feature Map</p>
<p><img src="/images/2017/spring/卷积例子.png" alt="卷积例子"></p>
<blockquote>
<h4 id="3-5-4-池化（Pooling）"><a href="#3-5-4-池化（Pooling）" class="headerlink" title="3.5.4 池化（Pooling）"></a>3.5.4 池化（Pooling）</h4></blockquote>
<p>池化层的作用是对原始特征信号进行抽象，从而大幅度减少训练参数，另外还可以减轻模型过拟合的程度。</p>
<ul>
<li>改变图像尺寸的操作, 可以逐层的把图像尺寸一点点降下来, 减少维度</li>
<li>max pool / average pool</li>
</ul>
<p><img src="/images/2017/spring/卷积池化.png" alt="卷积池化"></p>
<h3 id="3-6-Long-Short-Term-网络（LSTM）"><a href="#3-6-Long-Short-Term-网络（LSTM）" class="headerlink" title="3.6 Long Short Term 网络（LSTM）"></a>3.6 Long Short Term 网络（LSTM）</h3><p>几乎所有的令人振奋的关于 RNN 的结果都是通过 LSTM 达到的。LSTM 由 Hochreiter &amp; Schmidhuber (1997) 提出，并在近期被 Alex Graves 进行了改良和推广。</p>
<p>LSTM 可以学习长期依赖信息，避免长期依赖问题。LSTM 的关键就是细胞状态，水平线在图上方贯穿运行。细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传保持不变会很容易。 </p>
<p><img src="/images/2017/spring/LSTM.png" alt="LSTM"></p>
<p>其中，每一条黑线传输着一整个向量，从一个节点的输出到其他节点的输入。粉色的圈代表 pointwise 的操作，诸如向量的和，而黄色的矩阵就是学习到的神经网络层。合在一起的线表示向量的连接，分开的线表示内容被复制，然后分发到不同的位置。</p>
<blockquote>
<h4 id="3-6-1-逐步理解"><a href="#3-6-1-逐步理解" class="headerlink" title="3.6.1 逐步理解"></a>3.6.1 逐步理解</h4></blockquote>
<p>案例：基于已经看到的词预测下一个词。细胞状态可能包含当前‘主语’的类别，因此正确的‘代词’可以被选择出来。</p>
<ul>
<li><p>第一步：确定是否更新。通过’忘记门层’完成。该门会读取h(t-1)和xt，输出一个在 0 到 1 之间的数值给每个在细胞状态C(t-1)中的数字。1 表示“完全保留”，0 表示“完全舍弃”。当我们看到新的‘代词’，我们希望忘记旧的‘代词’。</p>
<p>  <img src="/images/2017/spring/LSTMstep1.png" alt="LSTMstep1"></p>
</li>
<li><p>第二步：确定更新信息。首先，sigmoid层称 “输入门层”决定什么值我们将要更新。其次，tanh层创建一个新的候选值向量，会被加入到状态中。我们希望增加新的代词的类别到细胞状态中，来替代旧的需要忘记的代词。</p>
<p><img src="/images/2017/spring/LSTMstep2.png" alt="LSTMstep2"></p>
</li>
<li><p>第三步：更新细胞状态。更新旧细胞状态，把旧状态与ft相乘，丢弃掉我们确定需要丢弃的信息。接着加上新的候选值，根据每个状态的程度进行变化。丢弃旧代词的类别信息并添加新的信息的地方。</p>
<p> <img src="/images/2017/spring/LSTMstep3.png" alt="LSTMstep3"></p>
</li>
<li><p>第四步：输出信息。首先，运行sigmoid层来确定细胞状态的哪个部分将输出出去。接着，把细胞状态通过tanh进行处理（得到一个在 -1 到 1 之间的值）并将它和sigmoid门的输出相乘，输出确定输出的那部分。代词需要输出与一个动词相关的信息。例如，可能输出是否代词是单数还是负数，这样如果是动词的话，我们也知道动词需要进行的词形变化。</p>
<p> <img src="/images/2017/spring/LSTMstep4.png" alt="LSTMstep4"></p>
</li>
</ul>
<blockquote>
<h2 id="第四章：playground实例"><a href="#第四章：playground实例" class="headerlink" title="第四章：playground实例"></a>第四章：playground实例</h2></blockquote>
<p><a href="http://playground.tensorflow.org/" target="_blank" rel="external">谷歌</a></p>
<p>打开网页后，总体来说，蓝色代表正值，黄色代表负值。拿分类任务来分析。</p>
<ul>
<li><p>数据</p>
<p>  在二维平面内，若干点被标记成了两种颜色。黄色，蓝色，表示想要区分的两类。你可以把平面内的任意点标记成任意颜色。网页给你提供了4种规律。神经网络会根据你给的数据训练，再分类相同规律的点。</p>
</li>
<li><p>输入</p>
<p>  在二维平面内，你想给网络多少关于“点”的信息。从颜色就可以看出来，x1左边是负，右边是正，x1表示此点的横坐标值。同理，x2表示此点的纵坐标值。x1~2是关于横坐标值的“抛物线”信息。你也可以给更多关于这个点的信息。给的越多，越容易被分开。</p>
</li>
<li><p>连接线</p>
<p>  表示权重，蓝色表示用神经元的原始输出，黄色表示用负输出。深浅表示权重的绝对值大小。鼠标放在线上可以看到具体值。也可以更改。</p>
</li>
<li><p>输出</p>
<p>  黄色背景颜色都被归为黄点类，蓝色背景颜色都被归为蓝点类。深浅表示可能性的强弱。</p>
<p><img src="/images/2017/spring/playground.png" alt="playground.png"></p>
</li>
</ul>
<blockquote>
<h2 id="第五章：如何选择合适的算法"><a href="#第五章：如何选择合适的算法" class="headerlink" title="第五章：如何选择合适的算法"></a>第五章：如何选择合适的算法</h2></blockquote>
<h3 id="第一步：问题分类"><a href="#第一步：问题分类" class="headerlink" title="第一步：问题分类"></a>第一步：问题分类</h3><ul>
<li>根据输入数据分类<ul>
<li>如果我们的数据有标签，这就是一个监督学习问题</li>
<li>如果数据没有标签而且我们想找出数据的内在结构，那这就是无监督学习</li>
<li>如果我们想通过与环境交互来优化目标函数，这是强化学习</li>
</ul>
</li>
<li>根据输出结果分类<ul>
<li>如果模型输出结果是一个数值，这是回归问题</li>
<li>如果输出结果是一个类别，这是分类问题</li>
<li>如果输出结果是一组输入数据，那这是聚类问题</li>
</ul>
</li>
</ul>
<p><img src="/images/2017/spring/问题分类.png" alt="问题分类"></p>
<ul>
<li>分类（classification）：当使用数据来预测类别时，监督学习也被叫做分类。比如将含有「猫」或「狗」的图片识别出来，分类为「猫」或「狗」，这就是二分类问题（two-class or binomial classification）。当存在更多类别时（例如预测下一届诺贝尔物理学家的获得者是谁），这就是所谓的多分类问题（multi-class classification）。</li>
<li>回归（regression）：当要预测数值时（比如预测股价），监督学习也被称为回归。</li>
<li>聚类（clustering）：聚类或聚类分析（cluster analysis）是无监督学习中最常见的方法之一。聚类是将一组对象以某种方式分组，使得同一组中的数据比不同组的数据有更多的相似性。</li>
<li>异常检测（Anomaly detection）：有时我们需要找出数据点中的异常点。例如，在欺诈检测中，任何极不寻常的信用卡消费都是可疑的；欺诈具有大量不同的形式，而训练样本又非常少，使得我们不可能完全了解欺诈活动应该是什么样。异常检测所采取的方法就是了解正常情况下的表现行为（使用非欺诈交易的历史数据），并识别出显著不同的表现行为。</li>
</ul>
<h3 id="第二步：寻找算法"><a href="#第二步：寻找算法" class="headerlink" title="第二步：寻找算法"></a>第二步：寻找算法</h3><p><img src="/images/2017/spring/寻找算法.png" alt="寻找算法"></p>
<ul>
<li>分类：<ul>
<li>支持向量机（SVM）可用于找到尽可能宽的分类的边界。当两个分类不能被清楚地分开时，该算法会找到其所能找到的最佳边界。其真正的亮点在于处理特征密集的数据，比如文本或者基因组（特征数量&gt; 100）。在这些情况下，除了仅需要适量的记忆外，支持向量机（SVM）能够比其它大多数算法更快且更少过拟合地进行分类。</li>
<li>人工神经网络是涵盖二分类、多分类和回归问题的脑启发式学习算法。它们有无限的种类，包括感知器和深度学习。它们需要很长时间来训练，但已知其在多种应用领域都实现了当前最佳的表现。</li>
<li>logistic 回归：即便名字中有着「回归」，但 logistic 回归实际上是一种可用于二分类和多分类问题的强大工具。它快速且简单。事实上，它使用「S」形曲线而非直线，所以它自然适合用于数据分组。logistic 回归可以给出线性分类边界，所以如果你要使用它，你一定要确保你能接受线性的近似。</li>
<li>决策树和随机森林：决策森林（decision forests）（回归、二分类、多分类），决策丛林（decision jungles）（二分类和多分类）和提升决策树（boosted decision trees）（回归和二分类）都基于决策树。这是一个基本的机器学习概念。决策树有许多不同的变体，但它们都在做同样的事情—将特征空间（feature space）细分为具有大致相同标签的区域。这些区域可以是一致的类别或者恒定值，具体取决于你进行的是分类还是回归。</li>
</ul>
</li>
<li>回归：<ul>
<li>线性回归是将一条线（或平面、或超平面）拟合到一个数据集上。这是一种主要的工具，简单且快速，但对于一些问题而言，它可能过于简单。</li>
<li>贝叶斯线性回归有着非常理想的特性：它可以避免过拟合。贝叶斯方法通过事先对答案的可能分布做出一些假设来做到这一点。这种方法的另一个副产品是它们具有非常少的参数。</li>
<li>提升决策树回归（Boosted decision tree regression）：如上所述，提升决策树（回归和二分类）均基于决策树，并通过将特征空间细分为具有大致相同标签的区域发挥效用。提升决策树通过限制其可以细分的次数以及每个区域中所允许的最少数据点来避免过拟合。该算法会构造一个树的序列，其中每棵树都会学习弥补之前的树留下来的误差。这能得到一个会使用大量的内存的非常精确的学习器。</li>
</ul>
</li>
<li>聚类：<ul>
<li>层次聚类（Hierarchical Clustering）的目标是构建聚类的层次结构，它有两种形式。聚集聚类（agglomerative clustering）是一种「自下而上」的方法，其中每个观察（observation）在其自己的聚类中开始，随着其在层次中向上移动，成对的聚类会进行融合。分裂聚类（divisive clustering）则是一种「自上而下」的方法，其中所有的观察都从一个聚类开始，并且会随观察向下的层次移动而递归式地分裂。整体而言，这里的融合和分裂是以一种激进的方式确定的。层次聚类的结果通常表示成树状图（dendrogram）的形式。</li>
<li>k-均值聚类（k-means clustering）的目标是将 n 组观测值分为 k 个聚类，其中每个观测值都属于其接近的那个均值的聚类——这些均值被用作这些聚类的原型。这会将数据空间分割成 Voronoi 单元。</li>
</ul>
</li>
<li>异常检测：<ul>
<li>k 最近邻（k-nearest neighbors / k-NN）是用于分类和回归的非参数方法。在这两种情况下，输入都是由特征空间中与 k 最接近的训练样本组成的。在 k-NN 分类中，输出是一个类成员。对象通过其 k 最近邻的多数投票来分类，其中对象被分配给 k 最近邻中最常见的类（k 为一正整数，通常较小）。在 k-NN 回归中，输出为对象的属性值。该值为其 k 最近邻值的平均值。</li>
<li>单类支持向量机（One-class SVM）：使用了非线性支持向量机的一个巧妙的扩展，单类支持向量机可以描绘一个严格概述整个数据集的边界。远在边界之外的任何新数据点都是非正常的，值得注意。</li>
</ul>
</li>
</ul>
<h3 id="第三步：实现算法"><a href="#第三步：实现算法" class="headerlink" title="第三步：实现算法"></a>第三步：实现算法</h3><p>问题通常存在多种候选算法，选择算法应反复试验。</p>
<p>原型开发最好分两步完成。</p>
<ol>
<li><p>最小特征工程快速实现。该阶段，主要目标是大概了解哪个算法表现得更好。将列表减少至几个候选算法。</p>
</li>
<li><p>建立机器学习流程，使用一组经过仔细选择的评估标准来比较每个算法在数据集上的表现。该阶段，只处理小部分算法，把注意力放在：特征工程。</p>
</li>
</ol>
<p>如下是深度学习的实现步骤：</p>
<ul>
<li>数据扩增<ul>
<li>水平翻转</li>
<li>随机剪裁</li>
<li>颜色抖动</li>
</ul>
</li>
<li>预处理<ul>
<li>去均值与规范化</li>
<li>主成分分析白化（数据先经过去均值，然后计算出（能刻画数据内部相关结果的）协方差矩阵）</li>
</ul>
</li>
<li>参数初始化<ul>
<li>全零初始化：若初始权值相同，神经元就不具有非对称性（asymmetry）。</li>
<li>小随机数初始化：在网络的回传过程中，小值权重会减弱“梯度信号”</li>
<li>方差校准：确保了网络中神经元在最初时有着大致相同的输出分布，以及收敛速度的提升。</li>
<li>np.random.randn(n) * sqrt(2.0/n) # 推荐，方差为2.0/n </li>
</ul>
</li>
<li>训练<ul>
<li>滤波器与池化</li>
<li>学习率</li>
<li>参数微调</li>
</ul>
</li>
<li>正则化<ul>
<li>L2正则化：惩罚目标函数中所有参数的平方。对权重向量的加强惩罚(heavily penalizing peaky weight vectors)和对权重向量的发散(diffuse weight vectors)。</li>
<li>L1正则化：将权重向量中的每个权重参数累加后加入目标函数中。带有L1正则化的神经元最终会将输入的数据中的重要输入元素得到保留，其余会变成或接近00。</li>
<li>最大模限制(max norm constraints)：让每个神经元的权重向量有一个绝对上限(upper bound)的约束，使用投影梯度下降(projected gradient descent)来执行这个约束。</li>
<li>Dropout：对整个神经网络进行抽样，并基于输入数据仅仅更新抽样网络的参数。</li>
</ul>
</li>
</ul>
<h3 id="第四步：特征工程"><a href="#第四步：特征工程" class="headerlink" title="第四步：特征工程"></a>第四步：特征工程</h3><p>特征工程却更像是一门艺术。</p>
<p>主要问题在于我们试图分类的数据在特征空间的描述极少。利如，用像素的灰度值来预测图片通常是不佳的选择；相反，我们需要找到能提高信噪比的数据变换。如果没有这些数据转换，我们的任务可能无法解决。利如，在方向梯度直方图（HOG）出现之前，复杂的视觉任务（像行人检测或面部检测）都是很难做到的。</p>
<p>常见的选取数据特征的方法：（大多数特征的有效性需靠实验评估）</p>
<ul>
<li>主成分分析（PCA）：一种线性降维方法，可以找出包含信息量较高的特征主成分，可以解释数据中的大多数方差。</li>
<li>尺度不变特征变换（SIFT）：计算机视觉领域中的一种有专利的算法，用以检测和描述图片的局部特征。它有一个开源的替代方法 ORB（Oriented FAST and rotated BRIEF）。</li>
<li>加速稳健特征（SURF）：SIFT 的更稳健版本，有专利。<br>方向梯度直方图（HOG）：一种特征描述方法，在计算机视觉中用于计数一张图像中局部部分的梯度方向的 occurrence。</li>
</ul>
<p><a href="https://en.wikipedia.org/wiki/Visual_descriptor" target="_blank" rel="external">更多算法</a>请参考</p>
<p>或者通过交叉验证误差最大的候选特征，前向或反向搜索获取期望数量的特征。</p>
<h3 id="第五步：优化算法"><a href="#第五步：优化算法" class="headerlink" title="第五步：优化算法"></a>第五步：优化算法</h3><blockquote>
<h4 id="5-1-调整超参"><a href="#5-1-调整超参" class="headerlink" title="5.1 调整超参"></a>5.1 调整超参</h4><p><img src="/images/2017/spring/超参调整.png" alt="超参调整"></p>
</blockquote>
<p>优化算法超参数。例如，主成分分析中的主成分个数，k 近邻算法的参数 k，或者是神经网络中的层数和学习速率。最好的方法是使用交叉验证来选择。</p>
<ul>
<li>新数据与当初预训练模型的数据相似时，<ul>
<li>若数据少就训练一个线性分类器，作为预训练模型的顶层特征抽取部分。</li>
<li>若数据时就使用一个较小的学习率，对预训练模型的多个顶层进行微调。</li>
</ul>
</li>
<li>如果数据与当初训练模型的数据相差大，但数据多。那么网络的大多数层的参数都应该基于新的数据做微调，同时用一个较小的学习率以提升性能。</li>
<li>如果数据与当初训练模型的数据相差大，且数据少，那就很难。因为数据量的限制，还不如单独训练一个线性模型，因为数据就与原本训练深层模型的不同，如若从顶层开始用自己差异大的数据（预训练模型得到的参数体现的是原始数据的特征）来训练，不见得会有多么好，反倒不如训练一个支持向量机模型替换深层模型中的某些层。</li>
</ul>
<blockquote>
<h4 id="5-2-优化方法"><a href="#5-2-优化方法" class="headerlink" title="5.2 优化方法"></a>5.2 优化方法</h4></blockquote>
<ul>
<li>一阶梯度法<ul>
<li>手动指定学习速率：SGD, Momentum, Nesterov Momentum</li>
<li>自动调节学习速率AdaGrad, RMSProp, Adam</li>
</ul>
</li>
<li>二阶梯度法</li>
</ul>

      

      
        <div class="page-reward">
          <a href="javascript:;" class="page-reward-btn tooltip-top">
            <div class="tooltip tooltip-east">
            <span class="tooltip-item">
              赏
            </span>
            <span class="tooltip-content">
              <span class="tooltip-text">
                <span class="tooltip-inner">
                  <p class="reward-p"><i class="icon icon-quo-left"></i>谢谢你请我吃糖果<i class="icon icon-quo-right"></i></p>
                  <div class="reward-box">
                    
                    
                  </div>
                </span>
              </span>
            </span>
          </div>
          </a>
        </div>
      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">深度学习</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">神经网络</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/deep-learning/" class="article-tag-list-link color4">deep-learning</a>
        		</li>
      		
		</ul>
	</div>


      

      
        
<div class="share-btn share-icons tooltip-left">
  <div class="tooltip tooltip-east">
    <span class="tooltip-item">
      <a href="javascript:;" class="share-sns share-outer">
        <i class="icon icon-share"></i>
      </a>
    </span>
    <span class="tooltip-content">
      <div class="share-wrap">
        <div class="share-icons">
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="icon icon-weibo"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="icon icon-weixin"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="icon icon-qq"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="icon icon-douban"></i>
          </a>
          <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a>
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="icon icon-facebook"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="icon icon-twitter"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="icon icon-google"></i>
          </a>
        </div>
      </div>
    </span>
  </div>
</div>

<div class="page-modal wx-share js-wx-box">
    <a class="close js-modal-close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="http://s.jiathis.com/qrcode.php?url=https://galaxias-sapphi-ren.github.io/2017/02/21/machine-learning-nn-dl/" alt="微信分享二维码">
    </div>
</div>

<div class="mask js-mask"></div>
      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
  
    <a href="/2017/02/15/machine-learning-recommend-sys-tech-framework-of-toutiao/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Machine Learning | 今日头条又推荐美女图片了，扒扒它的技术架构吧</div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>






  
  <div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="machine-learning-nn-dl" data-title="Machine Learning | 扬帆起航神经网络与深度学习" data-url="https://galaxias-sapphi-ren.github.io/2017/02/21/machine-learning-nn-dl/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"galaxias-sapphi-ren"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>

  




          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2017 Galaxias-Sapphi-REN
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(r){if(e[r])return e[r].exports;var o=e[r]={exports:{},id:r,loaded:!1};return t[r].call(o.exports,o,o.exports,n),o.loaded=!0,o.exports}var e={};return n.m=t,n.c=e,n.p="./",n(0)}([function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}function o(t,n){var e=/\/|index.html/g;return t.replace(e,"")===n.replace(e,"")}function i(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,e=0,r=t.length;e<r;e++){var i=t[e];o(n,i.getAttribute("href"))&&(0,d.default)(i,"active")}}function u(t){for(var n=t.offsetLeft,e=t.offsetParent;null!==e;)n+=e.offsetLeft,e=e.offsetParent;return n}function f(t){for(var n=t.offsetTop,e=t.offsetParent;null!==e;)n+=e.offsetTop,e=e.offsetParent;return n}function c(t,n,e,r,o){var i=u(t),c=f(t)-n;if(c-e<=o){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,h.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(e||c)+"px",a.style.left=i+"px",a.style.zIndex=r||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");c(t,document.body.scrollTop,-63,2,0),c(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}function l(){x.default.versions.mobile&&window.screen.width<800&&(i(),s())}var p=e(71),d=r(p),v=e(72),y=(r(v),e(84)),h=r(y),b=e(69),x=r(b),m=e(75),g=r(m),w=e(70);l(),(0,w.addLoadEvent)(function(){g.default.init()}),t.exports={}},function(t,n){var e=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=e)},function(t,n){var e={}.hasOwnProperty;t.exports=function(t,n){return e.call(t,n)}},function(t,n,e){var r=e(49),o=e(15);t.exports=function(t){return r(o(t))}},function(t,n,e){t.exports=!e(8)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,e){var r=e(6),o=e(12);t.exports=e(4)?function(t,n,e){return r.f(t,n,o(1,e))}:function(t,n,e){return t[n]=e,t}},function(t,n,e){var r=e(10),o=e(30),i=e(24),u=Object.defineProperty;n.f=e(4)?Object.defineProperty:function(t,n,e){if(r(t),n=i(n,!0),r(e),o)try{return u(t,n,e)}catch(t){}if("get"in e||"set"in e)throw TypeError("Accessors not supported!");return"value"in e&&(t[n]=e.value),t}},function(t,n,e){var r=e(22)("wks"),o=e(13),i=e(1).Symbol,u="function"==typeof i,f=t.exports=function(t){return r[t]||(r[t]=u&&i[t]||(u?i:o)("Symbol."+t))};f.store=r},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,e){var r=e(35),o=e(16);t.exports=Object.keys||function(t){return r(t,o)}},function(t,n,e){var r=e(11);t.exports=function(t){if(!r(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var e=0,r=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++e+r).toString(36))}},function(t,n){var e=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=e)},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,e){var r=e(6).f,o=e(2),i=e(7)("toStringTag");t.exports=function(t,n,e){t&&!o(t=e?t:t.prototype,i)&&r(t,i,{configurable:!0,value:n})}},function(t,n,e){var r=e(22)("keys"),o=e(13);t.exports=function(t){return r[t]||(r[t]=o(t))}},function(t,n,e){var r=e(1),o="__core-js_shared__",i=r[o]||(r[o]={});t.exports=function(t){return i[t]||(i[t]={})}},function(t,n){var e=Math.ceil,r=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?r:e)(t)}},function(t,n,e){var r=e(11);t.exports=function(t,n){if(!r(t))return t;var e,o;if(n&&"function"==typeof(e=t.toString)&&!r(o=e.call(t)))return o;if("function"==typeof(e=t.valueOf)&&!r(o=e.call(t)))return o;if(!n&&"function"==typeof(e=t.toString)&&!r(o=e.call(t)))return o;throw TypeError("Can't convert object to primitive value")}},function(t,n,e){var r=e(1),o=e(14),i=e(18),u=e(26),f=e(6).f;t.exports=function(t){var n=o.Symbol||(o.Symbol=i?{}:r.Symbol||{});"_"==t.charAt(0)||t in n||f(n,t,{value:u.f(t)})}},function(t,n,e){n.f=e(7)},function(t,n,e){var r=e(1),o=e(14),i=e(46),u=e(5),f="prototype",c=function(t,n,e){var a,s,l,p=t&c.F,d=t&c.G,v=t&c.S,y=t&c.P,h=t&c.B,b=t&c.W,x=d?o:o[n]||(o[n]={}),m=x[f],g=d?r:v?r[n]:(r[n]||{})[f];d&&(e=n);for(a in e)s=!p&&g&&void 0!==g[a],s&&a in x||(l=s?g[a]:e[a],x[a]=d&&"function"!=typeof g[a]?e[a]:h&&s?i(l,r):b&&g[a]==l?function(t){var n=function(n,e,r){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,e)}return new t(n,e,r)}return t.apply(this,arguments)};return n[f]=t[f],n}(l):y&&"function"==typeof l?i(Function.call,l):l,y&&((x.virtual||(x.virtual={}))[a]=l,t&c.R&&m&&!m[a]&&u(m,a,l)))};c.F=1,c.G=2,c.S=4,c.P=8,c.B=16,c.W=32,c.U=64,c.R=128,t.exports=c},function(t,n){var e={}.toString;t.exports=function(t){return e.call(t).slice(8,-1)}},function(t,n,e){var r=e(11),o=e(1).document,i=r(o)&&r(o.createElement);t.exports=function(t){return i?o.createElement(t):{}}},function(t,n,e){t.exports=!e(4)&&!e(8)(function(){return 7!=Object.defineProperty(e(29)("div"),"a",{get:function(){return 7}}).a})},function(t,n,e){"use strict";var r=e(18),o=e(27),i=e(36),u=e(5),f=e(2),c=e(17),a=e(51),s=e(20),l=e(58),p=e(7)("iterator"),d=!([].keys&&"next"in[].keys()),v="@@iterator",y="keys",h="values",b=function(){return this};t.exports=function(t,n,e,x,m,g,w){a(e,n,x);var O,S,_,j=function(t){if(!d&&t in A)return A[t];switch(t){case y:return function(){return new e(this,t)};case h:return function(){return new e(this,t)}}return function(){return new e(this,t)}},P=n+" Iterator",E=m==h,M=!1,A=t.prototype,T=A[p]||A[v]||m&&A[m],L=T||j(m),N=m?E?j("entries"):L:void 0,C="Array"==n?A.entries||T:T;if(C&&(_=l(C.call(new t)),_!==Object.prototype&&(s(_,P,!0),r||f(_,p)||u(_,p,b))),E&&T&&T.name!==h&&(M=!0,L=function(){return T.call(this)}),r&&!w||!d&&!M&&A[p]||u(A,p,L),c[n]=L,c[P]=b,m)if(O={values:E?L:j(h),keys:g?L:j(y),entries:N},w)for(S in O)S in A||i(A,S,O[S]);else o(o.P+o.F*(d||M),n,O);return O}},function(t,n,e){var r=e(10),o=e(55),i=e(16),u=e(21)("IE_PROTO"),f=function(){},c="prototype",a=function(){var t,n=e(29)("iframe"),r=i.length,o="<",u=">";for(n.style.display="none",e(48).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write(o+"script"+u+"document.F=Object"+o+"/script"+u),t.close(),a=t.F;r--;)delete a[c][i[r]];return a()};t.exports=Object.create||function(t,n){var e;return null!==t?(f[c]=r(t),e=new f,f[c]=null,e[u]=t):e=a(),void 0===n?e:o(e,n)}},function(t,n,e){var r=e(35),o=e(16).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return r(t,o)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,e){var r=e(2),o=e(3),i=e(45)(!1),u=e(21)("IE_PROTO");t.exports=function(t,n){var e,f=o(t),c=0,a=[];for(e in f)e!=u&&r(f,e)&&a.push(e);for(;n.length>c;)r(f,e=n[c++])&&(~i(a,e)||a.push(e));return a}},function(t,n,e){t.exports=e(5)},function(t,n,e){var r=e(15);t.exports=function(t){return Object(r(t))}},function(t,n,e){t.exports={default:e(41),__esModule:!0}},function(t,n,e){t.exports={default:e(42),__esModule:!0}},function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var o=e(39),i=r(o),u=e(38),f=r(u),c="function"==typeof f.default&&"symbol"==typeof i.default?function(t){return typeof t}:function(t){return t&&"function"==typeof f.default&&t.constructor===f.default&&t!==f.default.prototype?"symbol":typeof t};n.default="function"==typeof f.default&&"symbol"===c(i.default)?function(t){return"undefined"==typeof t?"undefined":c(t)}:function(t){return t&&"function"==typeof f.default&&t.constructor===f.default&&t!==f.default.prototype?"symbol":"undefined"==typeof t?"undefined":c(t)}},function(t,n,e){e(65),e(63),e(66),e(67),t.exports=e(14).Symbol},function(t,n,e){e(64),e(68),t.exports=e(26).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,e){var r=e(3),o=e(61),i=e(60);t.exports=function(t){return function(n,e,u){var f,c=r(n),a=o(c.length),s=i(u,a);if(t&&e!=e){for(;a>s;)if(f=c[s++],f!=f)return!0}else for(;a>s;s++)if((t||s in c)&&c[s]===e)return t||s||0;return!t&&-1}}},function(t,n,e){var r=e(43);t.exports=function(t,n,e){if(r(t),void 0===n)return t;switch(e){case 1:return function(e){return t.call(n,e)};case 2:return function(e,r){return t.call(n,e,r)};case 3:return function(e,r,o){return t.call(n,e,r,o)}}return function(){return t.apply(n,arguments)}}},function(t,n,e){var r=e(9),o=e(34),i=e(19);t.exports=function(t){var n=r(t),e=o.f;if(e)for(var u,f=e(t),c=i.f,a=0;f.length>a;)c.call(t,u=f[a++])&&n.push(u);return n}},function(t,n,e){t.exports=e(1).document&&document.documentElement},function(t,n,e){var r=e(28);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==r(t)?t.split(""):Object(t)}},function(t,n,e){var r=e(28);t.exports=Array.isArray||function(t){return"Array"==r(t)}},function(t,n,e){"use strict";var r=e(32),o=e(12),i=e(20),u={};e(5)(u,e(7)("iterator"),function(){return this}),t.exports=function(t,n,e){t.prototype=r(u,{next:o(1,e)}),i(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,e){var r=e(9),o=e(3);t.exports=function(t,n){for(var e,i=o(t),u=r(i),f=u.length,c=0;f>c;)if(i[e=u[c++]]===n)return e}},function(t,n,e){var r=e(13)("meta"),o=e(11),i=e(2),u=e(6).f,f=0,c=Object.isExtensible||function(){return!0},a=!e(8)(function(){return c(Object.preventExtensions({}))}),s=function(t){u(t,r,{value:{i:"O"+ ++f,w:{}}})},l=function(t,n){if(!o(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!i(t,r)){if(!c(t))return"F";if(!n)return"E";s(t)}return t[r].i},p=function(t,n){if(!i(t,r)){if(!c(t))return!0;if(!n)return!1;s(t)}return t[r].w},d=function(t){return a&&v.NEED&&c(t)&&!i(t,r)&&s(t),t},v=t.exports={KEY:r,NEED:!1,fastKey:l,getWeak:p,onFreeze:d}},function(t,n,e){var r=e(6),o=e(10),i=e(9);t.exports=e(4)?Object.defineProperties:function(t,n){o(t);for(var e,u=i(n),f=u.length,c=0;f>c;)r.f(t,e=u[c++],n[e]);return t}},function(t,n,e){var r=e(19),o=e(12),i=e(3),u=e(24),f=e(2),c=e(30),a=Object.getOwnPropertyDescriptor;n.f=e(4)?a:function(t,n){if(t=i(t),n=u(n,!0),c)try{return a(t,n)}catch(t){}if(f(t,n))return o(!r.f.call(t,n),t[n])}},function(t,n,e){var r=e(3),o=e(33).f,i={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],f=function(t){try{return o(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==i.call(t)?f(t):o(r(t))}},function(t,n,e){var r=e(2),o=e(37),i=e(21)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=o(t),r(t,i)?t[i]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,e){var r=e(23),o=e(15);t.exports=function(t){return function(n,e){var i,u,f=String(o(n)),c=r(e),a=f.length;return c<0||c>=a?t?"":void 0:(i=f.charCodeAt(c),i<55296||i>56319||c+1===a||(u=f.charCodeAt(c+1))<56320||u>57343?t?f.charAt(c):i:t?f.slice(c,c+2):(i-55296<<10)+(u-56320)+65536)}}},function(t,n,e){var r=e(23),o=Math.max,i=Math.min;t.exports=function(t,n){return t=r(t),t<0?o(t+n,0):i(t,n)}},function(t,n,e){var r=e(23),o=Math.min;t.exports=function(t){return t>0?o(r(t),9007199254740991):0}},function(t,n,e){"use strict";var r=e(44),o=e(52),i=e(17),u=e(3);t.exports=e(31)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,e=this._i++;return!t||e>=t.length?(this._t=void 0,o(1)):"keys"==n?o(0,e):"values"==n?o(0,t[e]):o(0,[e,t[e]])},"values"),i.Arguments=i.Array,r("keys"),r("values"),r("entries")},function(t,n){},function(t,n,e){"use strict";var r=e(59)(!0);e(31)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,e=this._i;return e>=n.length?{value:void 0,done:!0}:(t=r(n,e),this._i+=t.length,{value:t,done:!1})})},function(t,n,e){"use strict";var r=e(1),o=e(2),i=e(4),u=e(27),f=e(36),c=e(54).KEY,a=e(8),s=e(22),l=e(20),p=e(13),d=e(7),v=e(26),y=e(25),h=e(53),b=e(47),x=e(50),m=e(10),g=e(3),w=e(24),O=e(12),S=e(32),_=e(57),j=e(56),P=e(6),E=e(9),M=j.f,A=P.f,T=_.f,L=r.Symbol,N=r.JSON,C=N&&N.stringify,k="prototype",F=d("_hidden"),q=d("toPrimitive"),I={}.propertyIsEnumerable,B=s("symbol-registry"),D=s("symbols"),W=s("op-symbols"),H=Object[k],K="function"==typeof L,R=r.QObject,J=!R||!R[k]||!R[k].findChild,U=i&&a(function(){return 7!=S(A({},"a",{get:function(){return A(this,"a",{value:7}).a}})).a})?function(t,n,e){var r=M(H,n);r&&delete H[n],A(t,n,e),r&&t!==H&&A(H,n,r)}:A,G=function(t){var n=D[t]=S(L[k]);return n._k=t,n},$=K&&"symbol"==typeof L.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof L},z=function(t,n,e){return t===H&&z(W,n,e),m(t),n=w(n,!0),m(e),o(D,n)?(e.enumerable?(o(t,F)&&t[F][n]&&(t[F][n]=!1),e=S(e,{enumerable:O(0,!1)})):(o(t,F)||A(t,F,O(1,{})),t[F][n]=!0),U(t,n,e)):A(t,n,e)},Y=function(t,n){m(t);for(var e,r=b(n=g(n)),o=0,i=r.length;i>o;)z(t,e=r[o++],n[e]);return t},Q=function(t,n){return void 0===n?S(t):Y(S(t),n)},X=function(t){var n=I.call(this,t=w(t,!0));return!(this===H&&o(D,t)&&!o(W,t))&&(!(n||!o(this,t)||!o(D,t)||o(this,F)&&this[F][t])||n)},V=function(t,n){if(t=g(t),n=w(n,!0),t!==H||!o(D,n)||o(W,n)){var e=M(t,n);return!e||!o(D,n)||o(t,F)&&t[F][n]||(e.enumerable=!0),e}},Z=function(t){for(var n,e=T(g(t)),r=[],i=0;e.length>i;)o(D,n=e[i++])||n==F||n==c||r.push(n);return r},tt=function(t){for(var n,e=t===H,r=T(e?W:g(t)),i=[],u=0;r.length>u;)!o(D,n=r[u++])||e&&!o(H,n)||i.push(D[n]);return i};K||(L=function(){if(this instanceof L)throw TypeError("Symbol is not a constructor!");var t=p(arguments.length>0?arguments[0]:void 0),n=function(e){this===H&&n.call(W,e),o(this,F)&&o(this[F],t)&&(this[F][t]=!1),U(this,t,O(1,e))};return i&&J&&U(H,t,{configurable:!0,set:n}),G(t)},f(L[k],"toString",function(){return this._k}),j.f=V,P.f=z,e(33).f=_.f=Z,e(19).f=X,e(34).f=tt,i&&!e(18)&&f(H,"propertyIsEnumerable",X,!0),v.f=function(t){return G(d(t))}),u(u.G+u.W+u.F*!K,{Symbol:L});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),et=0;nt.length>et;)d(nt[et++]);for(var nt=E(d.store),et=0;nt.length>et;)y(nt[et++]);u(u.S+u.F*!K,"Symbol",{for:function(t){return o(B,t+="")?B[t]:B[t]=L(t)},keyFor:function(t){if($(t))return h(B,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){J=!0},useSimple:function(){J=!1}}),u(u.S+u.F*!K,"Object",{create:Q,defineProperty:z,defineProperties:Y,getOwnPropertyDescriptor:V,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),N&&u(u.S+u.F*(!K||a(function(){var t=L();return"[null]"!=C([t])||"{}"!=C({a:t})||"{}"!=C(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!$(t)){for(var n,e,r=[t],o=1;arguments.length>o;)r.push(arguments[o++]);return n=r[1],"function"==typeof n&&(e=n),!e&&x(n)||(n=function(t,n){if(e&&(n=e.call(this,t,n)),!$(n))return n}),r[1]=n,C.apply(N,r)}}}),L[k][q]||e(5)(L[k],q,L[k].valueOf),l(L,"Symbol"),l(Math,"Math",!0),l(r.JSON,"JSON",!0)},function(t,n,e){e(25)("asyncIterator")},function(t,n,e){e(25)("observable")},function(t,n,e){e(62);for(var r=e(1),o=e(5),i=e(17),u=e(7)("toStringTag"),f=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],c=0;c<5;c++){var a=f[c],s=r[a],l=s&&s.prototype;l&&!l[u]&&o(l,u,a),i[a]=i.Array}},function(t,n){"use strict";var e={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&t.indexOf("KHTML")==-1,mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:t.indexOf("Safari")==-1,weixin:t.indexOf("MicroMessenger")==-1}}()};t.exports=e},function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}var o=e(40),i=r(o),u=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):o[t]||t}function n(t){return l[t]}var e=/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,r=/['<> "&]/g,o={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},f=/\u00a0/g,c=/<br\s*\/?>/gi,a=/\r?\n/g,s=/\s/g,l={};for(var p in o)l[o[p]]=p;return o["&apos;"]="'",l["'"]="&#39;",{encode:function(t){return t?(""+t).replace(r,n).replace(a,"<br/>").replace(s,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(c,"\n").replace(e,t).replace(f," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],e=0,r=t.length;r>e;e++)n.push(t.charCodeAt(e).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],e=0,r=t.length;r>e;e++)n.push(t.charCodeAt(e).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],e=0,r=t.length;r>e;e+=2)n.push(String.fromCharCode("0x"+t.slice(e,e+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,e=t.length;e>n;n++)t[n]=u.encodeObject(t[n]);else if("object"==("undefined"==typeof t?"undefined":(0,i.default)(t)))for(var r in t)t[r]=u.encodeObject(t[r]);else if("string"==typeof t)return u.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=u},function(t,n){function e(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=e},function(t,n){function e(t,n){if(t.classList)t.classList.remove(n);else{var e=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(e," ")}}t.exports=e},,,function(t,n){"use strict";function e(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){var n=document.querySelectorAll(".article-entry a:not(.article-more-a)");n.forEach(function(t){t.setAttribute("target","_blank")})}var e=document.querySelector("#js-aboutme");e&&0!==e.length&&(e.innerHTML=e.innerText)}t.exports={init:e}},,,,,,,,,function(t,n){function e(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var e=t.nextSibling;return e?t.parentNode.insertBefore(n,e):t.parentNode.appendChild(n)}t.exports=e}])</script><script src="/./main.2d7529.js"></script><script>!function(){var e=function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)};e("/slider.885efe.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 50%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">博文</a></li>
      
        
      
        
      
      <li style="width: 50%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">博主</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">推荐系统</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">深度学习</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">markdown</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">npm</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">yeoman</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">神经网络</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">机器学习</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            2、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: true
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">时间总是先给予&lt;br&gt;&lt;br&gt;然后悄悄拿走&lt;br&gt;&lt;br&gt;亿万年前不同恒星的原子基因决定&lt;br&gt;兴趣使然&lt;br&gt;热爱生活</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>