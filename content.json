[{"title":"Mac 上使用 IntelliJ IDEA","date":"2019-09-20T01:23:12.000Z","path":"2019/09/ideaOnMac/","text":"the most intelligent java IDE IntelliJ Idea 前言 IntelliJ IDEA 是如今最好用的 java IDE 工具。这里比较系统的总结了 Idea IDE 的主要优势，模块化概念的转变，以及如何安装、新建工程、操作。便于学习 Java 项目。 介绍了IDE的组成，如个性化推荐配置、参数调优、修改热键、调试流程、常用视图（使用习惯）、常用命令、使用技巧、代码模板、版本控制、集成常用插件介绍等。 智能是IDEA工具的代名词，文本旨在于 mac 上使用 Idea 过程中，理清 IDEA 相关概念的层级关系。 1 Introduction JetBrains 捷克 布拉格（etc : pyCharm DataGrip Goland…） jetbrains.com/idea 📖 学习文档 w3cshool jetbrains help 👍 优势 内存空间 -&gt; 速度 idea安装包小。 运行时会把建立的索引保存到内存空间中，加快文件查询，从而加快各种查找、代码提示等操作的速度。 实际占用CPU少。尤其当Eclipse使用JSP等语法检查时很慢。 🗣 Tips 索引：idea会建立文件、类、方法等索引。如：抽象类、注解类、普通类、枚举类、异常类、接口、含main类、方法、属性及其修饰符，建立语法树，分析上下文。 idea的缓存和索引文件也是会损坏的，如断电、蓝屏引起的强制关机。 &quot;File&quot; -&gt; &quot;Invalidate Caches / Restart...&quot; -&gt; Invalidate and Restart #修复 概念切换 -&gt; 灵活 eclipse IntelliJ IDEA Workspace Project Project Module Facet Facet Library Library JRE SDK classpath variable path variable 工作空间 -&gt; 模块化 ：IDEA不需要设置工作空间，每一个项目工程（Project）都具备一个工作空间，每一个子模块（Module）都可以使用独立的JDK和MAVEN配置。新项目配置（ProjectStructs）后，子模块初始化继承项目配置。 ⌘ ; -&gt; &quot;Project|Module&quot; 工作区间最大化 -&gt; 专注 ⌘ ⇧ F12 -&gt; &quot;Project|Module&quot; 功能 -&gt; 便捷 整合能力：各类版本工具(git、svn等)、JUnit、CVS、Spring、Tomcat、Maven 提示功能：快速、范围广 ⌥ ⏎ #代码提示 快捷键及模板代码（live Templates，postfix） #&quot;⌘ ,&quot; -&gt; &quot; Editor | Live Templates&quot; psvm #main函数 iter #foreach fori #iterate 精确搜索：视图、定位 ⇧ ⌥ ⌘ U #视图 ⇧ ⇧ #定位 重构、代码审查 ⇧ F6 #rename ⌘ F6 #重构方法 ⌥ ⌘ V|C|F|P|M #抽取变量|静态变量|成员变量|方法参数|方法 ⌥ ⌘ L #格式化代码 debug -&gt; 调试（detail in 5 How to Debug） 调试时，灵活查看对象的值。 选中对象后，拖动到Variables中。新建Watch。 选中对象后，使用快捷键”⌥ F8” 动态编辑值Evaluate expression。 选中对象后，鼠标悬停。 查看Map类型的对象，如果实现类采用的是哈希映射，则会自动过滤空的Entry实例。 右击断点，可以设置多线程调试，并添加条件，当满足条件后进入断点。多线程执行的情况在Log on console。 ✨ 技巧 ⇧ ⌘ A #Actions，输入关键字查找命令2 Support plugins SQL JVM PHP postgreSQL Java Python MySQL Groovy Ruby Orecle Scala SQL server Kotlin Clojure framework 代码提示 容器 Spring MVC HTML5 Tomcat GWT CSS3 TomEE Vaadin SASS Weblogin Play SESS Jboss Grails JavaScript Jetty Web Service CoffeeScript WebShpere JSF Node.js Struts ActionScript Hibernate Flex 3 Install download 仅用于个人学习 参考：2019.8.23更新 推荐：企业版 &gt; 淘宝版 &gt; 正版 &gt; 破解版 预备JetbrainsCrack.jar放入idea的bin目录下 修改配置文件（idea.vmoptions） 试用 -&gt; &quot;Help&quot; -&gt; &quot;Edit Custom VM Options ...&quot;，若提示创建文件，点&quot;是|Yes&quot;。linux系统/root/.idea中idea.vmoptions，javaagent也要改 末行添加jar文件的绝对路径 -javaagent:/Applications/IntelliJ IDEA.app/Contents/bin/JetbrainsCrack.jar 目录结构 说明 bin 启动脚本、虚拟机配置文件、属性信息等 help 热键帮助文档 jdk 自带jre环境 lib 依赖的类库 license 插件的许可信息 plugins 插件 👉参数调优（启动项配置） &#39;&#39;&#39;vim # vi idea.vmoptions -Xms2048m #初始内存 -Xmx2048m #最大内存 -XX:MaxPermSize=1024m #最大允许分配的非堆内存 -XX:ReservedCodeCacheSize=512m #可保留代码的缓存大小 &#39;&#39;&#39;Idea 启动时间并不依赖于内存设置。Idea 在所有场景下的测试时间都是10秒，无论内存分配有多少。而 Xmx 内存大些对响应能力提升的帮助非常明显。其他jvm参数效果忽略不计。参考资料 🗣 Tips idea执行时会有大量缓存、索引文件（caches目录），对硬件设备要求更高。 🗣 Tips 不是修改IDEA安装应用包内容中的 idea.vmoptions 配置文件，而是修改 ~/Library/Preferences/IntelliJIdea…中的 idea.vmoptions 配置文件jetbrains配置文档 oracle配置文档 🗣 Tips 选用正确的JDK后，再根据文档配置jvm运行参数。 4 Hello World！ 4.1 first IDEA Project &quot;File&quot; -&gt; &quot;new&quot; -&gt; &quot;Project&quot; -&gt; &quot;SDK archetype GroupId ArtifactId Version&quot; #创建Project &quot;⌘ N&quot; -&gt; &quot;Module&quot; -&gt; &quot;SDK...&quot; #创建Module &quot;⌘ ;&quot; #查看Module依赖关系，删除目录前先移除Module &quot;⌘ N&quot; -&gt; &quot;Java Class&quot; -&gt; &quot;per.rsf.HelloIdea.java&quot; #创建.java &quot;psvm&quot; -&gt; &quot;ctr + sft + R&quot; #运行 👉项目配置说明 .iml 模块module配置文件 .idea 工程Project的配置文件 IDEA是没有 ⌘ S （保存）的 IDE，每次修改完代码直接运行或调试，无需担心保存或者丢失代码问题。对于代码的错误检查是实时的，无需担心代码编译问题。 如果需要整体编译项目，则需要手动build一下。 4.2 commons Preferences Configure&quot;⌘ ,&quot; #settings 设置 = 偏好设置，独立于项目设置 #或点击Toorbar小扳手图标 外观和行为 Appearance &amp; Behavior “Appearance | Show memory indicator” #打开内存使用状态 “System Settings | Updates | Automatically check updates” #取消自动更新 “System Settings | Reopen last project on startup” #启动时不打开工程 Theme download &quot;File&quot; -&gt; &quot;Import Settings...&quot; #主题 Theme : Darcla Light... 快捷键 Keymap 热键文档 最常用快捷键 说明 ⌃ Space Basic code completion 代码建议 ⌃ ⇧ Space Smart code completion 代码建议 ⇧ ⇧ Search everywhere 查询 ⌥ ⏎ Show intention actions and quick-fixes 万能纠错 ⌘ N Generate code 覆盖方法 ⌘ P Parameter info 查看函数的参数信息 ⌘ E Recent files popup 最近打开的文件栈 自己修改的快捷键 功能 默认 配置 原因 调用结构导航 ⌃ ⌥ H ⌘ H 被VimEditor占用 Refactor Copy F5 - 不常用，给debug让道 Refactor Move F6 ⌘ M 不常用，给debug让道 smart step into ⇧ F7 F5 不常用，智能跳入调试方法 force step into ⇧ ⌥ F7 F6 常用，强制跳入方法，可查看JDK源码 编辑器 Editor &quot;General | Auto Import | Insert Imports on paste - All&quot; #自动导入 &quot;General | Limits | Recent files limit — 20&quot; #&quot;⌘ E&quot;弹层文件个数 &quot;General | Appearance | how method separators&quot; #方法分隔行 &quot;General | Code Completion | Match Case&quot; #提示忽略大小写 &quot;General | Editor Tabs | Show tabs in one row&quot; #多行显示tab不隐藏 &quot;Font | Size - 16&quot; #字体 &quot;Code Style | Visual guides - 80&quot; #设置换行符和自动换行 &quot;File and Code Templates | Class&quot; #类注释 &quot;Live Templates | + Template Group - Method | + Live Templates | Abbr Desc Edit Vars | Define - java&quot; #快捷方法注释 * + Tab &quot;File Encodings | Global Project Default Encodings - UTF-8 Transparent native-to-ascii conversion&quot; #字符集中文显示，当打开其他编码类型文件时，可以通过状态栏的编码类型重新读文件 &quot;File Types | Ignore files and folders —target;.gradle;.iml;.idea;&quot; #隐藏文件和文件夹 插件 版本控制 Version Control &quot;Show directories with changed descendants&quot; #版本控制文件变化显示 构建、执行、部署 Build, Execution, Deployment &quot;Compiler | build project automatically&quot; #自动编译 &quot;Compiler | in parallel&quot; #多模块并行编译 &quot;Compiler | build process heap size - 1500&quot; #防止编译报错OutOfMemoryError &quot;Build Tools | Maven | home directory Print exception stack traces #Maven配置 &quot;Build Tools | Maven | Importing | Import Maven projects automatically #Maven动刷新 &quot;Build Tools | Maven | Importing | Automatically download — Sources #Maven自动导入源码 语音、框架 工具 5 How to Debug 5.1 流程 Compile &quot;⌘ F9&quot; Make Project 或自动编译 Breakpoint &quot;⌘ F8&quot; 设置断点，或者点击行号添加断点。 &quot;⌘ 2&quot; Favorites视图查看断点 &quot;⌘ ⇧ F8&quot; 断点视图查看断点 Thread 右键断点 -&gt; &quot;Suspend - Thread&quot;设置多线程调试模式 Run | Debug &quot;⌃ ⌥ R|D&quot; #hold &quot;⇧&quot;改变 Run|Debug 模式，打开调试 Debugging ”F7“ Step into 跳入该方法 ”F8“ Step over 跳到下一个方法 ”⇧ F8“ Step out 跳出该方法 ”F9“ Resume Program 跳到下一个断点 ”⌥ F9“ Run to cursor 跳到下一个断点或光标处 Watches &quot;⌥ F8&quot; Evaluate expression 执行表达式动态窗口 跳转至&quot;Debugger | Threads&quot;面板调试多线程 6 View &amp; Actions 6.1 Tool Windows 工具窗口使用IntelliJ IDEA，根据编码需求组织一个布局，专注于代码和编辑器，进入 自由模式 使编辑器有最多的屏幕空间，因为辅助控件（如工具栏和窗口）是隐藏的。 工具窗口 快捷键 返回编辑器窗口 esc 编辑器自由模式（最大化） ⇧ ⌘ F12 项目窗口 ⌘ 1 收藏窗口、书签、断点 ⌘ 2 运行窗口 ⌘ 4 调试窗口 ⌘ 5 TODO窗口 ⌘ 6 结构窗口 ⌘ 7 依赖树窗口 ⌘ 8 版本控制窗口 ⌘ 9 # 常用 &quot;⌘ E&quot; #最近打开的文件 &quot;⇧ ⌘ E&quot; #最近打开的修改的文件 &quot;⌥ ⇧ C&quot; #最近修改的文件6.2 Edit 编辑 # 常用 &quot;⌘ Z&quot; #撤销 &quot;⌘ D&quot; #复制一行 &quot;⌘ X&quot; #剪切一行 &quot;⌘ Delete&quot; #删除一行 &quot;⇧ ⌥ ↑ | ↓&quot; #上下移动行 &quot;⌘ C&quot; #复制 &quot;⌘ V&quot; #粘贴 &quot;⇧ ⌘ C&quot; #复制路径 &quot;⇧ ⌘ V&quot; #粘贴历史板 &quot;⇧ ⌘ U&quot; #大小写转换 &quot;⌘ F&quot; #在当前文件中查找，出现Find工具窗口 &quot;⇧ ⌘ F&quot; #在路径中查找 &quot;⌘ R&quot; #在当前文件中替换 &quot;⇧ ⌘ R&quot; #在路径中替换 6.3 Navigate 导航标记 # 常用 &quot;⌘ O&quot; #类导航 &quot;⇧ ⌘ O&quot; #文件导航 &quot;⌥ ⌘ O&quot; #符号导航 &quot;⌘ E&quot; #最近文件导航 &quot;⌘ L&quot; #代码行导航 &quot;⇧ ⌘ Delete&quot; #上次编辑定位导航 &quot;F3&quot; #标记 &quot;⌥ F1&quot; #选择 &quot;⌘ F12&quot; #结构导航，区分&quot;⌘ 7&quot;方法结构视图 &quot;⌃ ⌥ H&quot; #调用结构导航，被VimEditor占用添加&quot;⌘ H&quot;快捷键 &quot;F2&quot; #高亮错误导航 &quot;⌃ 上下箭头&quot; #上、下个方法导航 &quot;⌥ ⌘ 左右箭头&quot; #上、下次查看的方法导航6.4 Code 代码# 常用 &quot;⌘ N&quot; #生成器代码块 &quot;⌥ ⌘ T&quot; #围绕代码块 &quot;⌘ J&quot; #代码模板代码块 &quot;⌘ /&quot; #单行注释 &quot;⌥ ⌘ /&quot; #多行注释 &quot;⌥ ⌘ L&quot; #代码规范 &quot;⌃ ⌥ O&quot; #优化导入 6.5 Refactor 重构🗣 Tips：要撤消上一次重构，将焦点切换到项目工具窗口，然后 ⌘ Z。 # 常用 &quot;⌃ T&quot; #显示可用的重构提取 部分字符串表达式。选择一个字符串片段并应用重构, 将所选的所有片段用法替换为引入的常量或变量。 6.6 Analyze 检查检查是内置静态代码分析工具，寻找可能的错误，查找死代码，检测性能问题及改进整体代码结构。通过 “⌥ ⏎” 快速修复。 &quot;Analyze | Inspect Code” &quot;Analyze | Run Inspection by Name&quot;6.7 Live Templates &amp; Postfix 代码模板 新增 Template Group 新增 Live Templates 定义 Abbr Desc Edit Vars 应用 Define 如用main代替psvm生成main函数和生成方法注释代码块。 7 Tomcat 7.1 Tomcat配置&quot;Run&quot; -&gt; &quot;Edit Configurations&quot; -&gt; &quot;+ New Configuration - Tomcat Server&quot; &quot;Deployment&quot; 8 Database 8.1 Database Mysql配置 9 VCS GitHub 9.1 checkout clone&quot;⌘ , | Version Control | GitHub + &quot; #注册GitHub “VCS” -&gt; &quot;ckeckout from Version Control&quot; -&gt; &quot;git - &lt;URL&gt;&quot; #克隆项目 &quot;VCS&quot; -&gt; &quot;import into Version Control&quot; -&gt; &quot;share...&quot; #发布项目10 Plugins 关闭不必要的IDEA Plugins，能极大减少内存占用。 插件关闭参考 10.1 installPreferences | Plugins | Install - 所需插件 Preferences | Plugins | Install plug from disk - 下载好的插件 10.2 recommend Maven Helper 打开pom文件的Dependency Analyzer视图查看maven的依赖冲突、列表与树。 Ali-CodeAnalysis 2017年10月14日杭州云栖大会Java代码规引发布。阿里巴巴Java开发手册 插件采用kotlin语言开发的，包含三个子菜单：编码规约扫描、关闭试试检测功能、切换语言至英文。 GsonFormat Java开发中，经常有把json格式的内容转成Object的需求，GsonFormat这款插件可以实现该功能。 Free Mybatis plugin Mybatis的JavaMapper文件中会根据xml配置关联定位。（绿色箭头） MyBatis Log Plugin 将Mybatis执行的sql脚本在日志中显示，清晰执行sql脚本。 Lombok 使用了lombok的注解(@Setter, @Getter, @ToString, @Data)后，不需编写或生成get/set等方法，减少了代码量与代码维护负担。 &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; RestfulToolkit Spring MVC开发中通过URL地址定位controller，并根据controller生成默认的测试数据，解决了postman调试数据时，无需自己组装数据或在console找数据包。 Rainbow Brackets 括号高亮插件 VisualVM Launcher jvm调优必备工具，查看某个对象占用了多大的内存。 11 BiliBili 参考的哔哩哔哩视频。","tags":[{"name":"Java","slug":"Java","permalink":"https://galaxias-sapphi-ren.github.io/tags/Java/"},{"name":"IDE","slug":"IDE","permalink":"https://galaxias-sapphi-ren.github.io/tags/IDE/"},{"name":"Mac","slug":"Mac","permalink":"https://galaxias-sapphi-ren.github.io/tags/Mac/"}]},{"title":"jvm specification","date":"2019-04-23T10:23:07.000Z","path":"2019/04/jvmspecification/","text":"引语 – jvm specification 前言 more 1 2 3","tags":[{"name":"JVM","slug":"JVM","permalink":"https://galaxias-sapphi-ren.github.io/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://galaxias-sapphi-ren.github.io/tags/Java/"}]},{"title":"Hexo 与 GitHubPages 搭建个人博客","date":"2018-08-06T12:34:06.000Z","path":"2018/08/useHexoBlog/","text":"Hexo is a fast, simple and powerful blog framework. You write posts in Markdown and Hexo generates static files with a beautiful theme in seconds. – hexo.io 前言 博客是一个可以集中思考，解构思维、技巧、客观存在的地方。写博客需要内驱与热情驱动。 Hexo 和 GitHubPages 是一套快速、简洁且高效的博客搭建方案。易于拓展定制，适合喜欢折腾的程序员。 markdown 风格的文档是一种思路，往往简单的表格、图片、组织架构就足以说明问题，辅以高亮代码，可以简洁直观轻松的表达观点。在书写 md 博客时，不要刻意概全，加深层级结构。要突出问题和解决方法，将深层的问题剖析出来。少拿来主义的复制，多反复的摸索。 本文简述个人在使用 Hexo 和 GitHubPages 博客搭建方案中的出现的一些情况的解决方案或思路。 基于Hexo与GitHubPages搭建个人博客 1 技术栈 模块 简介 Markdown 轻量级标记语言，易读易写纯文本格式文档，易转化为html文件 Hexo 根据配置文件和组件渲染md生成静态文件的博客系统 git 分布式版本控制系统，代码文件提交 Github 基于git的免费远程仓库，开源协作社区 Github Pages 静态站点托管服务，提供仓储库中的静态文件 DNS 绑定个人网站域名 万网购买域名 2 流程协同示意图 用红色Actor博主到紫色Actor访客，主要有五个流程。 Hexo 的安装及功能。 使用 Hexo 书写文章。以 MarkDown 书写博客文档并生成静态html博客资源。 部署到 GitHub 资源库生成 GitHubPages 服务。 博客的个性化定制。 DNS绑定个人网站域名。 3 Hexo 的安装及功能 3.1 What 基于 Node.js 实现的开源静态博客系统。部署要求低，只需简单的虚拟空间即可部署。主题Theme丰富，易于定制个性化，适用熟悉前端的工程师使用。 官方文档 3.2 Install3.2.1 安装前提 Node.js (版本需不低于 8.6，建议 10.0 及以上) Git Mac 用户需要 Xcode 3.2.2 安装及基础组件命令行 $ npm install -g hexo-cli $ hexo init &lt;folder&gt; $ cd &lt;folder&gt; &amp;&amp; npm install 目录结构 blog ├── _config.yml # 网站配置信息。配置博客相关的参数。初始化时自动创建。 ├── db.json：# source解析缓存文件。 ├── node_modules：# nodejs依赖包。插件及所需模块。 ├── package.json # 应用程序信息。查看 Hexo 的版本以及相关依赖包的版本。可自由移除依赖包。 ├── public # 网页发布信息。存放被解析md、html文件。hexo将source文件夹里的md转换成html。结合主题进行渲染，是最终看到的博客。 ├── scaffolds # 模板文件夹。新建文章时，根据 scaffold 生成文件。 ├── source # 资源 | └── _posts # 博客文章目录。 └── themes # 主题。Hexo 根据主题生成静态页面。 └── yilia 4.1 主题个性化定制。 ├── _config.yml # 主题的配置信息。修改时会自动更新，无需重启服务器。 ├── languages # 语言 ├── layout # 布局。存放主题的模板文件，呈现网站内容。Hexo 使用模板引擎根据模板文件的扩展名来决定所使用的模板引擎。 ├── package.json # 应用程序信息。查看 Theme 的版本以及相关依赖包的版本。 ├── source # 博客初始化后将 source-src 中的文件打包后的js css文件，个性化定制将依赖的js css文件。存放图片、md、html。部署时直接拷贝到 public 文件夹，以下划线开头自动忽略。 ├── source-src # 主题使用到的js css文件 └── webpack.config.js # 打包配置文件🗣 Tips .deploy_git文件由public文件夹的内容提交到Github后生成，内容与public文件夹基本一致。文件关系大致是：source -&gt; public -&gt; .deploy_git 🗣 Tips Yaml专门用来写配置文件，一种通用的数据串行化格式。 大小写敏感。 使用缩进表示层级关系。 缩进时不允许使用Tab键，只允许使用空格。 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可。 Hexo默认安装 hexo：主程序 hexo-util： spawn系统命令、Promise异步流程控制、highlight高亮显示、Stream流等nodejs工具 hexo-deployer-git：基于hexo-util实现git部署方式 hexo-generator-archive：存档分页页面生成器 hexo-generator-category：分类分页页面生成器 hexo-generator-index：index生成器 hexo-generator-tag：标签分页页面生成器 hexo-renderer-ejs：支持EJS渲染 hexo-renderer-marked：Markdown引擎 hexo-renderer-stylus：支持stylus渲染 hexo-server：支持本地预览，默认地址 localhost:4000，Hexo 3.0 后独立模块 … 3.2.3 插件插件使用过程中，尤其是更换主题时，需要安装其它的依赖包，保存在node_module文件夹。如： hexo-renderer-scss：支持scss渲染。某些主题需要安装的依赖包。 hexo-generator-json-content：缺失模块解决方法。 hexo-wordcount：支持字数、阅读时长添加 hexo-generator-feed：支持博客订阅 hexo-neat：压缩静态资源插件 hexo-generator-sitemap：添加站点地图 hexo-generator-baidu-sitemap：添加百度站点地图 … 命令行 $ npm install &lt;module name&gt; --save $ hexo init &lt;folder&gt; $ cd &lt;folder&gt; &amp;&amp; npm install 3.3 WorkHexo工作流程 Hexo模板引擎生成工具将界面同数据分离，模板内容替换指定地方数据，实现业务和逻辑代码分离。Hexo默认用ejs模板，根据模板文件后缀名解析：md文件、layout布局调用其他文件。具有高代码复用性，最终生成html页面。 “hexo init” -&gt; “node-module | hexo | hexo-cli | lib | init.js” “hexo g” -&gt; “node-module | hexo-generator-index | lib | generator.js” “hexo s” -&gt; “node-module | hexo-server | middlewares | server.js” 4 使用 Hexo 书写文章自建脚本： #! ~/.blog.sh export BLOG_FOLDER=&lt;default_blog_folder&gt; #! ~/.zshrc source ~/.blog.sh # 打开博客文章目录 alias blog=&#39;cd $BLOG_FOLDER/source/_post/ &amp;&amp; ls -l&#39; # 将当前目录设置为默认博客目录 alias blog.=&#39;echo &quot;export BLOG_FOLDER=$PWD&quot; &gt; ~/.blog.sh &amp;&amp; source ~/.blog.sh&quot; # 初始化当前目录博客 alias blogi=&#39;blog. &amp;&amp; hexo init $BLOG_FOLDER &amp;&amp; cd $BLOG_FOLDER &amp;&amp; npm install&#39; # 根据自定义配置新建md博客文件 alias blogn=&#39;cd $BLOG_FOLDER &amp;&amp; hexo new myphoto&#39; alias blogs=&#39;cd $BLOG_FOLDER &amp;&amp; hexo clean &amp;&amp; hexo g &amp;&amp; hexo s&#39; alias blogd=&#39;cd $BLOG_FOLDER &amp;&amp; hexo d -g&#39; 4.1 更换主题4.1.1 选择主题 yilia$ cd $BLOG_FOLDER $ git clone https://github.com/fan-haobai/hexo-theme-yilia.git themes/hexo-theme-yilia 4.1.2 修改配置文件config.yml配置文件参考 4.2 新建 Markdown 文档# 在 $BLOG_FOLDER/source/post/ 中新建 Markdown 文件 $ hexo new [layout] &lt;title&gt; 根据 [layout] 生成 Markdown 文件，默认post，使用 scaffolds/post.md 作为默认模板。可以定制想要的 Front-matter 和基础 Markdown 格式。 4.3 Markdown 写博客Front-matter 指生成的 Markdown 文档上方的标识，使 Hexo 在解析过程中正常工作。 --- title: Hello World! date: 2018-08-06 20:34:06 --- markdown 是面向Web作家的文本到HTML转换工具。Markdown 允许您使用易于阅读，易于编写的纯文本格式进行编写，然后将其转换为结构上有效的XHTML（或HTML）。Markdown 格式化语法的首要设计目标是使其更具可读性。 使用数据文件夹 在 source/_data 放入YAML 或 JSON 文件，如 menu.yml在模板中使用 &lt;% for (var link in site.data.menu) { %&gt; &lt;a href=&quot;&lt;%= site.data.menu[link] %&gt;&quot;&gt; &lt;%= link %&gt; &lt;/a&gt; &lt;% } %&gt; 4.4 生成博客资源文件$ hexo g | 渲染过程 | 输入 | 模板引擎 | 输出 | |:-:|:-:|:-:|:-:| | 1 | source目录文件 | yml 和 markdown | article对象 | | 2 | themes目录文件 article对象 | ejs，取决于themes/layouts文件格式 | public目录文件 | ### 4.5 生成本地服务 ​```bash $ hexo s启动服务器，网站会在 http://localhost:4000 下启动。在服务器启动期间，Hexo 会监视文件变动并自动更新，无须重启服务器。 5 部署到 GitHub 资源库生成 GitHubPages 服务GitHub Github Pages 是静态站点托管服务，可直接从GitHub上的存储库中获取HTML，CSS和JavaScript文件，还可以选择在构建过程中运行这些文件并发布网站。 注册 GitHub帐号 New repository 创建新仓库：[GitHub UserName].github.io，即将站点托管在GitHub的github.io域上，也可以绑定到自定义域上。 5.1 使用SSH连接到GitHub 使用SSH协议，可以连接到远程服务器和服务并进行身份验证。使用SSH密钥，您可以连接到GitHub，而无需在每次访问时都提供用户名或密码。 如何生成密钥并将其添加到GitHub 测试SSH连接 ssh -T git@GitHub.com 5.2 Hexo部署修改config.yml配置文件信息 ## Docs: https://hexo.io/docs/deployment.html deploy: type: git repository: git@github.com:Galaxias-Sapphi-REN/Galaxias-Sapphi-REN.github.io.git branch: master Hexo部署 $ hexo d -g 6 个性化定制基本原理个性化定制 主要是对页面功能的拓展和对样式的调整，对页面局部结构的修改。而对页面功能的拓展包括本地模块支持和导入第三库支持。个性化定制首先要了解主要修改的文件目录结构： custumer_theme 使用的主题 ├─ _config.yml 配置文件，自定义属性后和ejs模板文件协同工作 ├─ source | ├─ main.[trunk].css 主要修改的样式文件！！！ | ├─ main.[trunk].js 打包后的js，一般只在其他js中extends，而不做修改。 | └── &lt;custumer&gt;.js 自己写的js或本地下载的js └── layout ├─ layout.ejs 首页展示入口 ├─ index.ejs 点击文章引导入口 └── _partial 页面部分结构 ├─ left-col.ejs 左侧站点信息 ├─ css.ejs 导入结构layout|head|css，需要导入的css文件添加到这里 ├─ script.ejs 导入结构layout|after-footer|script，需要导入的js文件添加在这里 ├─ archive.ejs 归档页面 ├─ article.ejs 文章页面，文章内修改主要在这里 └── post 更小的模块功能结构，如第三方评论，分享等。一般由article.ejs调用在不调整页面主题结构的情况下，一般选择 页面样式调整 -&gt; 修改 mytheme|source|main.[trunk].css，看别人的博客喜欢谁的样式果断F12选取喜欢部分，查看计算出的styles，在这里修改样式。或者自定义css。 喜欢的组件 -&gt; 如果CDN，直接引用到css.ejs script.ejs文件中。如： &lt;!-- jquery 看板娘依赖 css.ejs --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css&quot;&gt; &lt;!-- 卜蒜子统计 script.ejs 依赖第三方js --&gt; &lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; &lt;!-- 点击爱心 script.ejs 依赖本地js --&gt; &lt;script src=&quot;&lt;%=config.root%&gt;./love.js&quot;&gt;&lt;/script&gt; 需要添加dom元素，主要在left-col.ejs article.ejs archive.ejs中适合的dom位置添加，添加css文件。如需配合配置文件，在_config.yml自定义属性后，在ejs文件中按ejs结构书写。如： left-col.ejs 替换原来的头像dom元素 &lt;!--自动旋转头像 --&gt; &lt;% if(theme.Rotate == true){ %&gt; &lt;div id=&quot;ds-reset&quot; class=&quot;ds-post-self&quot;&gt; &lt;div class=&quot;ds-avatar&quot; &gt; &lt;img src=&quot;&lt;%=theme.avatar%&gt;&quot;&gt; &lt;% } %&gt; &lt;!--自动旋转头像 --&gt; **main.[trunk].css** 添加样式 /*头像旋转*/ #ds-reset .ds-avatar img { width: 124px; height: 124px; /*设置图像的长和宽*/ border: 5px solid #fff; border-radius: 62px;/*设置图像圆角效果,在这里我直接设置了超过width/2的像素，即为圆形了*/ -webkit-border-radius: 62px;/*圆角效果：兼容webkit浏览器*/ -moz-border-radius: 62px; box-shadow: inset 0 -1px 0 #3333sf;/*设置图像阴影效果*/ -webkit-box-shadow: inset 0 -1px 0 #3333sf; -webkit-transition: 0.8s; -webkit-transition: -webkit-transform 0.8s ease-out; transition: transform 0.8s ease-out;/*变化时间设置为0.8秒(变化动作即为下面的图像旋转360读）*/ -moz-transition: -moz-transform 0.8s ease-out; } #ds-reset .ds-avatar img:hover, #ds-reset div:hover { /*设置鼠标悬浮在头像时的CSS样式*/ transform: rotateZ(360deg);/*图像旋转360度*/ -webkit-transform: rotateZ(360deg); -moz-transform: rotateZ(360deg); } **_config.yml** 配置文件设置属性配合ejs模板使用 # 自动旋转头像 Rotate: true 修改node_modules依赖，如修改依赖的highlight.js源码。 代码高亮漂亮的呈现代码很重要，在网页上使用Highlight.js 能够满足我的需求。 highlight.js 定制包装，可以下载仅包含所需语言的自定义捆绑包。Hexo 有 highlight.js 的依赖，但是表现不好。需要自定义样式。或者拓展 highlight 对象。 highlight.js 将在 pre code 标签内找到并突出显示代码；它会尝试自动检测语言。如果自动检测对您不起作用，则可以在class属性中指定语言： &lt;pre&gt;&lt;code class=&quot;html&quot;&gt;...&lt;/code&gt;&lt;/pre&gt; Hexo 代码高亮 &lt;link rel=&quot;stylesheet&quot; href=&quot;/path/to/styles/default.css&quot;&gt; &lt;script src=&quot;/path/to/highlight.pack.js&quot;&gt;&lt;/script&gt; &lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;一些其他简单的功能看板娘404公益Hexo yilia 主题添加 valine 评论系统 去除代码背景和边框 article-entry p code {background:#ddd;border:1px solid #ccc} 修改代码颜色 .article-entry pre code 悬浮变色 #header a:hover{color:#b0a0aa} 7 DNS绑定个人网站域名7.1 绑定个人网站域名 万网购买域名7.2 解析配置 7.3 CNAME登录GitHub，.github.io | settings | Custom domain | save 7.4 CNAME在 blog/source 目录下创建 CNAME 文件 $ echo &quot;rensifei.site&quot; &gt; $BLOG_FOLDER/source/CNAME 绑定域名 7.5 确认DNS记录配置正确 $ dig galaxias-sapphi-ren.github.io +nostats +nocomments +nocmd 8 continue如果还想折腾： 在Github上看issue或者提issue yilia/issues 去Hexo的官方插件页面找插件很多：Hexo插件 看看大神们的博客。","tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://galaxias-sapphi-ren.github.io/tags/Hexo/"},{"name":"GitHub Pages","slug":"GitHub-Pages","permalink":"https://galaxias-sapphi-ren.github.io/tags/GitHub-Pages/"}]},{"title":"在 mac 上使用 PlantUML 画 UML","date":"2018-05-03T01:00:00.000Z","path":"2018/05/PlantUML/","text":"前言 UML语言是一种面向对象的模型语言，通过UML语言的组合来表达某些事物之间的逻辑关系。是一种为面向对象开发系统的产品进行说明、可视化、和编制文档的标准语言。 PlantUML是一个开源项目，支持使用简单直观的语言快速绘制：时序图、用例图、类图、活动图、组件图、状态图、对象图、部署图、定时图、甘特图、思维导图 、数学公式等。 PlantUML有比较详细的guide文档，也可以适配集成IDEA intelliJ、Sublime Text、Maven和JQuery等。生成PNG、SVG或LaTeX格式的图片。 本文说明PlantUML使用相关内容。 参考资料 w3cschool UML plantuml.git 官网示例 第一章：安装 Graphviz 开源的图片渲染库 brew install graphviz java 1.1 Sublime Text3 sublime_diagram_plugin:sublime插件 在Sublime中使用 &quot;⌘ m&quot; -&gt; 导出图片1.2 IDEA intelliJ IDEA intelliJ Plugin Version 在IDEA中使用 &quot;⌘ N&quot; -&gt; &quot;PlantUML File&quot; 1.3 SpringBoot集成plantUMLpom.xml中添加如下依赖，更多关于PlantUML api的使用请参见具体的官方文档。参考资料2是一个简单的demo。 &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.plantuml&lt;/groupId&gt; &lt;artifactId&gt;plantuml&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt; &lt;/dependency&gt;1.4 本地的JavaEE容器启动plantUML.war下载Java J2EE WAR File plantuml.war 放在本地的Tomcat的webapps目录下，启动后访问 http://localost:8080/plantuml，就可以看到如下图所示画面，左侧编写PlantUML语言的代码，下面是效果图。 第二章：安装 2.1 基础语法基础语法 常用语法 定义 图像 A -&gt; B:text 实箭头 实线 A –&gt; B:text 虚箭头 虚线 -[#red]&gt;x /- &lt;&lt;–&gt; 颜色 丢失 半 细 双向箭头 … note left/right + end note 注释 无 hnote rnote 形状 形状 () 用例 椭圆形 startuml enduml 语法始终 无 start stop 流程开始结束 if (“condition 1”) then (true/yes/false/no) + else (false/no) + endif 条件语句 无 while(‘condition’) is (‘stop condition’) + endwhile 循环语句 无 :; 顺序流程 2.2 时序图 常用语法 定义 图像 actor 参与者 人 control entity database collections … 图形 A as B 重命名参与者 无 A as B 井99FF99 颜色 颜色 A order 2 自定义顺序 无 autonumber 对消息编号 编号 newpage 分页 分页 == Repetition == 分隔符 分割 …5 minutes latter… 延时 延时 activate deactivate 生命线的激活与撤销 时序线生命 over 覆盖 覆盖时序线 2.3 用例图 2.4 类图 2.5 活动图（流程图） 2.6 组件图 2.7 状态图 2.8 思维导图","tags":[{"name":"Plantuml","slug":"Plantuml","permalink":"https://galaxias-sapphi-ren.github.io/tags/Plantuml/"}]},{"title":"jmh - 微秒级方法层微基准测试","date":"2018-01-08T13:51:42.000Z","path":"2018/01/jmh/","text":"JMH is a Java harness for building, running, and analysing nano/micro/milli/macro benchmarks written in Java and other languages targetting the JVM. —— JMH If you cannot measure it, you cannot improve it. —— Lord Kelvin 前言 jmh（Java Microbenchmark Harness 2013）由 Oracle 实现 JIT 的开发人员开发的基准测试框架，作为Java9的一部分来发布。 jmh 在方法级层面上进行基准（性能）测试，精度可以精确到微秒级。同时像 junit 一样具有 idea 集成插件。为应用提供数据支持，是评价和比较方法好坏的基准。 Java 编程过程中，通常使用 jmh 对热点代码进行性能评估，或者对不同实现逻辑性能比较。是用来代替初级 System.currentTimeMillis() 更好的方法。jvm初始化或者JIT缓存热点代码，测试时需要对测试代码进行预热。jmh 会因为 JIT 的代码优化出现一些测试陷阱。 可以在 samples 上查看使用方法，教程。 1 hello benchmark 1.1 maven 依赖&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt; &lt;artifactId&gt;jmh-core&lt;/artifactId&gt; &lt;version&gt;${jmh.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt; &lt;artifactId&gt;jmh-generator-annprocess&lt;/artifactId&gt; &lt;version&gt;${jmh.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;!--编译，测试，运行--&gt; &lt;/dependency&gt; 1.2 简单的 sleep 性能测试实例（注解说明）// 类实例的可用范围 Benchmark：多线程共享实例 Thread：多线程不共享 Group：同组共享@Group @State(Scope.Thread) // 测量维度 Throughput：整体吞吐量 AverageTime：调用平均时间 SampleTime：随机取样 SingleShotTime：冷启动 All：所有模式都执行一次 @BenchmarkMode(Mode.AverageTime) // 测试结果的时间类型 @OutputTimeUnit(TimeUnit.MILLISECONDS) // 预热5次，每次3s @Warmup(iterations = 5, time = 3, timeUnit = TimeUnit.SECONDS) // 实际调用5次，每次3s @Measurement(iterations = 5, time = 3, timeUnit = TimeUnit.SECONDS) // 一个进程 @Fork(1) // 一个线程 @Threads(1) public class FirstBenchmark { //字段级注解，测试一个函数在不同的参数输入的情况下的性能 @Param(value = {&quot;400&quot;, &quot;500&quot;, &quot;600&quot;}) private String time; //方法级注解，测试前的初始化 @Setup public void init() { } //方法级注解，测试完成后的垃圾回收 Trial-Iteration-Invocation：每次调用Benchmark方法的之前/之后执行。 @TearDown(Level.Trial) public void check() { } //方法级注解，表示该方法是需要进行 benchmark 的对象 @Benchmark public int sleepAWhile() { try { Thread.sleep(Integer.parseInt(time)); } catch (InterruptedException e) { // ignore } return 0; } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(FirstBenchmark.class.getSimpleName()) .build(); new Runner(opt).run(); } } 1.3 运行结果Result &quot;per.rsf.study.jmh.FirstBenchmark.sleepAWhile&quot;: 603.117 ±(99.9%) 2.877 ms/op [Average] (min, avg, max) = (602.262, 603.117, 604.238), stdev = 0.747 CI (99.9%): [600.239, 605.994] (assumes normal distribution) Benchmark (time) Mode Cnt Score Error Units FirstBenchmark.sleepAWhile 400 avgt 5 402.859 ± 3.396 ms/op FirstBenchmark.sleepAWhile 500 avgt 5 502.924 ± 2.269 ms/op FirstBenchmark.sleepAWhile 600 avgt 5 603.117 ± 2.877 ms/op 2 trap测评程序随着迭代次数增多执行耗时变化的曲线，测评程序 预热 warmup 若干次后，性能最终趋于稳定。（JVM 初始化时的一些准备工作以及 JIT 优化是主要原因，但不是唯一原因） 3 examples3.1 比较 joda.DateTime 与 Calendar 性能Benchmark Mode Cnt Score Error Units DateBenchMark.runCalendar avgt 3 196.022 ± 65.980 ns/op DateBenchMark.runJoda avgt 3 52.651 ± 62.046 ns/op DateBenchMark.runSystem avgt 3 28.354 ± 1.515 ns/op 3.2 比较并行与串行性能Benchmark (length) Mode Cnt Score Error Units SecondBenchmark.multiThreadBench 10000 avgt 10 19.680 ± 8.778 us/op SecondBenchmark.multiThreadBench 100000 avgt 10 33.675 ± 3.710 us/op SecondBenchmark.multiThreadBench 1000000 avgt 10 119.929 ± 8.906 us/op SecondBenchmark.singleThreadBench 10000 avgt 10 3.206 ± 0.674 us/op SecondBenchmark.singleThreadBench 100000 avgt 10 37.824 ± 1.582 us/op SecondBenchmark.singleThreadBench 1000000 avgt 10 465.206 ± 28.376 us/op 3.3 比较字符串连接Benchmark(thrpt吞吐量) Mode Cnt Score Error Units StringBuilderBenchMark.testStringAdd thrpt 5 18700.777 ± 1333.327 ops/ms StringBuilderBenchMark.testStringBuilderAdd thrpt 5 65381.089 ± 4997.020 ops/ms 3.4 UUID&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.uuid&lt;/groupId&gt; &lt;artifactId&gt;java-uuid-generator&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt; private RandomBasedGenerator randomBasedGenerator; private RandomBasedGenerator jugRandomGenerator; private TimeBasedGenerator timeBasedGenerator; @Setup public void init() { randomBasedGenerator = Generators.randomBasedGenerator();//SecureRandom随机数 timeBasedGenerator = Generators.timeBasedGenerator(); jugRandomGenerator = Generators.randomBasedGenerator(new Random()); } @Benchmark public void UUIDRandomUUID(Blackhole bh) { //单线程、8线程最慢吞吐量1k/ms bh.consume(UUID.randomUUID());////SecureRandom随机数 } @Benchmark public void jugWithRandom(Blackhole bh) { //单线程最快吞吐量2w/ms，8线程吞吐量1.5k/ms bh.consume(jugRandomGenerator.generate()); } @Benchmark public void jugWithSecureRandom(Blackhole bh) { //单线程、8线程最慢吞吐量1k/ms bh.consume(randomBasedGenerator.generate()); } @Benchmark public void jugTime(Blackhole bh) { //8线程最快吞吐量1w/ms，单线程吞吐量1w/ms bh.consume(timeBasedGenerator.generate()); } //SecureRandom 通过获取操作系统的一些随机噪声来生成随机数的，性能不是很好（相对）","tags":[{"name":"Microbenchmark","slug":"Microbenchmark","permalink":"https://galaxias-sapphi-ren.github.io/tags/Microbenchmark/"},{"name":"jmh","slug":"jmh","permalink":"https://galaxias-sapphi-ren.github.io/tags/jmh/"},{"name":"java","slug":"java","permalink":"https://galaxias-sapphi-ren.github.io/tags/java/"}]},{"title":"熟能生巧","date":"2017-06-05T14:44:13.000Z","path":"2017/06/practice/","text":"康肃问曰：“汝亦知射乎?吾射不亦精乎?” 翁曰：“无他，但手熟尔。” 康肃忿然曰：“尔安敢轻吾射!” 因曰：“我亦无他，惟手熟尔。” —— from 《卖油翁》 前言 常用网址 Linux命令大全 LeetCode OSI7层架构 git指令大全 vim指令大全 HTTP请求交互","tags":[{"name":"Practice","slug":"Practice","permalink":"https://galaxias-sapphi-ren.github.io/tags/Practice/"}]},{"title":"当 Hexo 邂逅 MathJax","date":"2017-03-14T01:35:28.000Z","path":"2017/03/hexoMeetMathjax/","text":"Beautiful math in all browsers A JavaScript display engine for mathematics that works in all browsers.No more setup for readers. It just works. —— from mathjax 前言 有时候需要在文档中添加一些数学公式，不使用图片，可以用LaTeX渲染。 MathJax是一个JavaScript引擎，用来渲染数学公式。它可以工作于所有流行的浏览器上。 本文介绍如何在 github page 中使用MathJax，和MathJax的基本语法和demo，涉及到的所有数学符号公式代码，右键 - Show Math As - TeX Commands 有惊喜。 1 MathJax 简介 1.1 概述使用MathJax可以方便的在浏览器中显示数学公式，不需要使用图片。目前，MathJax可以解析Latex、MathML和ASCIIMathML的标记语言。 MathJax项目于2009年开始，发起人有American Mathematical Society, Design Science等. 1.2 特点 高质量的排版：使用CSS与网络字体或SVG，而不是位图图像或Flash。 模块化输入和输出：使用MathML，TeX和ASCIImath作为输入，生成HTML、CSS，SVG和MathML作为输出。 可访问和可重复使用：兼容屏幕阅读器，缩放。可复制到Office，LaTeX，wiki和其他软件。 2 github pages 和 hexo 配置在页面（放到页面模板的 head 标签，可能位于_include/themes/yourtheme/default.html）添加脚本 &lt;script src=&quot;//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;部分 hexo 配置文件中支持MathJax，直接开启 MathJax: true或者直接使用hexo-math插件 npm install hexo-math --save或者更换markdown引擎 github pages ： kramdown hexo ： hexo-renderer-pandoc 3 冲突Markdown 本身的特殊符号与 Latex 中的符号会出现冲突，导致数学公式无法正常渲染。 符号 markdown语法含义 latex语法含义 _ 斜体 下标 \\\\ 转义为\\ 换行 出于保护代码块、简单直接的方法，这里推荐修改markdown解析器。（hexo 渲染源码） 打开nodes_modules/marked/lib/marked.js 将 escape: /^\\\\([\\\\`*{}\\[\\]()# +\\-.!_&gt;])/,替换为 escape: /^\\\\([`*{}\\[\\]()# +\\-.!_&gt;])/,将 em: /^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,替换为 em:/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,最终 /** * Inline-Level Grammar */ var inline = { //escape: /^\\\\([//`*{}\\[\\]()#+\\-.!_&gt;])/, escape: /^\\\\([`*{}\\[\\]()#+\\-.!_&gt;])/, autolink: /^&lt;([^ &gt;]+(@|:\\/)[^ &gt;]+)&gt;/, url: noop, tag: /^&lt;!--[\\s\\S]*?--&gt;|^&lt;\\/?\\w+(?:&quot;[^&quot;]*&quot;|&#39;[^&#39;]*&#39;|[^&#39;&quot;&gt;])*?&gt;/, link: /^!?\\[(inside)\\]\\(href\\)/, reflink: /^!?\\[(inside)\\]\\s*\\[([^\\]]*)\\]/, nolink: /^!?\\[((?:\\[[^\\]]*\\]|[^\\[\\]])*)\\]/, strong: /^__([\\s\\S]+?)__(?!_)|^\\*\\*([\\s\\S]+?)\\*\\*(?!\\*)/, //em: /^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, em:/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, code: /^(`+)\\s*([\\s\\S]*?[^`])\\s*\\1(?!`)/, br: /^ {2,}\\n(?!\\s*$)/, del: noop, text: /^[\\s\\S]+?(?=[\\\\&lt;!\\[_*`]| {2,}\\n|$)/ };4 MathJax 语法4.1 公式inline 行级公式 $$，在行内显示。 质能方程 $E=mc^2$. display 独立公式 $$ $$，居中并放大显示。 $$E=mc^2$$ 4.2 希腊字母 名称 大写 Tex 小写 Tex alpha $A$ A $\\alpha$ \\alpha beta $B$ B $\\beta$ \\beta gamma $\\Gamma$ \\Gamma $\\gamma$ \\gamma delta $\\Delta$ \\Delta $\\delta$ \\delta epsilon $E$ E $\\epsilon $ \\epsilon zeta $Z$ Z $\\zeta$ \\zeta eta $H$ H $\\eta$ \\eta theta $\\Theta$ \\Theta $\\theta$ \\theta iota $I$ I $\\iota$ \\iota kappa $K$ K $\\kappa$ \\kappa lambda $\\Lambda$ \\Lambda $\\lambda$ \\lambda mu $M$ M $\\mu$ \\mu nu $N$ N $\\nu$ \\nu xi $\\Xi$ \\Xi $\\xi$ \\xi omicron $O$ O $\\omicron$ \\omicron pi $\\Pi$ \\Pi $\\pi$ \\pi rho $P$ P $\\rho$ \\rho sigma $\\Sigma$ \\Sigma $\\sigma$ \\sigma tau $T$ T $\\tau$ \\tau upsilon $\\Upsilon$ \\Upsilon $\\upsilon$ \\upsilon phi $\\Phi$ \\Phi $\\phi$ \\phi chi $X$ X $\\chi$ \\chi psi $\\Psi$ \\Psi $\\psi$ \\psi omega $\\Omega$ Omega $\\omega$ \\omega 4.3 字母修饰上标与下标 $$C_n^m = C_{n - 1}^{m - 1} + C_{n - 1}^{m}\\C_n^m = \\frac{m!}{n!}$$ $${x^5}^{x^{16}} \\times \\log_2 x$$ $$\\sum_{n=1}^\\infty \\frac{1}{n^2} \\to \\textstyle \\sum_{n=1}^\\infty \\frac{1}{n^2} \\to \\displaystyle \\sum_{n=1}^\\infty \\frac{1}{n^2}$$ 括号 $$\\left \\lbrace\\sum_{i=0}^n i^2 = \\frac{(n^2+n)(2n+1)}{6}\\right\\rbrace\\tag{1.2}\\\\langle x \\rangle\\\\lceil x \\rceil\\\\lfloor x \\rfloor$$ $$f\\left(\\left[\\frac{1+{x,y}}{(x/y+y/x)(u+1)}+a\\right]^{3/2}\\right)$$ 求和、极限与积分 $$\\begin{array}{cc}\\mathrm{Bad} &amp; \\mathrm{Better} \\\\hline \\\\int\\int_S f(x)\\,dy\\,dx &amp; \\iint_S f(x)\\,dy\\,dx \\\\int\\int\\int_V f(x)\\,dz\\,dy\\,dx &amp; \\iiint_V f(x)\\,dz\\,dy\\,dx\\end{array}tag{1.4}$$ $$\\begin{array}{cc}\\mathrm{Bad} &amp; \\mathrm{Better} \\\\hline \\e^{i\\frac{\\pi}2} \\quad e^{\\frac{i\\pi}2}&amp; e^{i\\pi/2} \\\\int_{-\\frac\\pi2}^\\frac\\pi2 \\sin x\\,dx &amp; \\int_{-\\pi/2}^{\\pi/2}\\sin x\\,dx \\\\end{array}$$ $$\\bbox[yellow,5px,border:2px solid red]{e^x=\\lim_{n\\to\\infty} \\left( 1+\\frac{x}{n} \\right)^n\\qquad (1.6)}$$ 分式与根式 $$\\underset{j=1}{\\overset{\\infty}{\\LARGE\\mathrm K}}\\frac{a_j}{b_j}=\\cfrac{a_1}{b_1+\\cfrac{a_2}{b_2+\\cfrac{a_3}{b_3+\\ddots}}}.$$ $$x = a_0 + \\frac{1^2}{a_1+} \\frac{2^2}{a_2+} \\frac{3^2}{a_3 +} \\frac{4^4}{a_4 +} \\cdots$$ $$\\begin{align}\\sqrt{37} &amp; = \\sqrt{\\frac{73^2-1}{12^2}} \\ &amp; = \\sqrt{\\frac{73^2}{12^2}\\cdot\\frac{73^2-1}{73^2}} \\ &amp; = \\sqrt{\\frac{73^2}{12^2}}\\sqrt{\\frac{73^2-1}{73^2}} \\ &amp; = \\frac{73}{12}\\sqrt{1 - \\frac{1}{73^2}} \\ &amp; \\approx \\frac{73}{12}\\left(1 - \\frac{1}{2\\cdot73^2}\\right)\\end{align}$$ 分组与空格 $${ab}{ab}\\;{ab}\\quad{ab}$$ 字体 tex 字体 tex 字体 \\rm 罗马体 \\it 意大利体 \\bf 黑体 \\cal 花体 \\\\tt 打字机字体 \\sf 等线体 $$\\mathrm{ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ}\\\\mathbf{ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ}\\\\mathit{ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ}\\\\mathcal{ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ}\\\\mathsf{ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ}\\\\mathtt{ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ}\\$$ 顶部符号 \\hat x \\quad \\overline {xyz} \\quad \\vec a \\quad \\overrightarrow {x} \\quad \\dot x \\quad \\ddot x$$\\hat x \\quad \\overline {xyz} \\quad \\vec a \\quad \\overrightarrow {x} \\quad \\dot x \\quad \\ddot x$$ \\overline \\quad \\underline \\quad \\widetilde \\quad \\widehat \\quad \\fbox \\quad \\underleftarrow \\quad \\underrightarrow \\quad \\underleftrightarrow \\quad \\overbrace \\quad \\underbrace \\quad \\underbrace{a\\cdot a\\cdots a}_{b\\text{ times}}$$\\overline A \\quad\\underline B \\quad\\widetilde C \\quad\\widehat D \\quad\\fbox E \\quad\\underleftarrow F \\quad\\underrightarrow G \\quad\\underleftrightarrow H\\\\overbrace{(n - 2) + \\overbrace{(n - 1) + n + (n + 1)} + (n + 2)}\\(n \\underbrace{- 2) + (n \\underbrace{- 1) + n + (n +} 1) + (n +} 2)\\\\underbrace{a\\cdot a\\cdots a}_{b\\text{ times}}$$ 4.3 运算符常用 显示 命令 $\\infty$ \\infty $\\cup$ \\cup $\\cap$ \\cap $\\subset$ \\subset $\\subseteq$ \\subseteq $\\supset$ \\supset $\\in$ \\in $\\notin$ \\notin $\\varnothing$ \\varnothing $\\forall$ \\forall $\\exists$ \\exists $\\lnot$ \\lnot $\\nabla$ \\nabla $\\partial$ \\partial 关系运算符 \\pm\\quad\\times\\quad\\div\\quad\\mid\\quad\\nmid\\quad\\cdot\\quad\\circ\\quad\\ast\\quad\\bigodot\\quad\\bigotimes\\quad\\bigoplus\\quad\\leq\\quad\\geq\\quad\\neq\\quad\\approx\\quad\\equiv\\quad\\sum\\quad\\prod\\quad\\coprod$$\\pm\\quad\\times\\quad\\div\\quad\\mid\\quad\\nmid\\quad\\cdot\\quad\\circ\\quad\\ast\\quad\\bigodot\\quad\\bigotimes\\quad\\bigoplus\\quad\\leq\\quad\\geq\\quad\\neq\\quad\\approx\\quad\\equiv\\quad\\sum\\quad\\prod\\quad\\coprod$$ 集合运算符 \\emptyset\\quad\\in\\quad\\notin\\quad\\subset\\quad\\supset\\quad\\subseteq\\quad\\supseteq\\quad\\bigcap\\quad\\bigcup\\quad\\bigvee\\quad\\bigwedge\\quad\\biguplus\\quad\\bigsqcup$$\\emptyset\\quad\\in\\quad\\notin\\quad\\subset\\quad\\supset\\quad\\subseteq\\quad\\supseteq\\quad\\bigcap\\quad\\bigcup\\quad\\bigvee\\quad\\bigwedge\\quad\\biguplus\\quad\\bigsqcup$$ 对数运算符 \\log\\quad\\lg\\quad\\ln$$\\log\\quad\\lg\\quad\\ln$$ 三角运算符 \\bot\\quad\\angle\\quad30^\\circ\\quad\\sin\\quad\\cos\\quad\\tan\\quad\\cot\\quad\\sec\\quad\\quad\\csc$$\\bot\\quad\\angle\\quad30^\\circ\\quad\\sin\\quad\\cos\\quad\\tan\\quad\\cot\\quad\\sec\\quad\\quad\\csc$$ 微积分运算符 \\prime\\quad\\int\\quad\\iint\\quad\\iiint\\quad\\iiiint\\quad\\oint\\quad\\lim_{x\\to 0}\\quad\\infty\\quad\\nabla$$\\prime\\quad\\int\\quad\\iint\\quad\\iiint\\quad\\iiiint\\quad\\oint\\quad\\lim_{x\\to 0}\\quad\\infty\\quad\\nabla$$ 逻辑运算符 \\because\\quad\\therefore\\quad\\forall\\quad\\exists\\quad\\not=\\quad\\not&gt;\\quad\\not\\subset$$\\because\\quad\\therefore\\quad\\forall\\quad\\exists\\quad\\not=\\quad\\not&gt;\\quad\\not\\subset$$ 4.4 表格$$\\begin{array}{c|lcr}n &amp; \\text{Left} &amp; \\text{Center} &amp; \\text{Right} \\\\hline1 &amp; 0.24 &amp; 1 &amp; 125 \\2 &amp; -1 &amp; 189 &amp; -8 \\3 &amp; -20 &amp; 2000 &amp; 1+10i \\\\end{array}$$ $$% outer vertical array of arrays\\begin{array}{c}% inner horizontal array of arrays\\begin{array}{cc}% inner array of minimum values\\begin{array}{c|cccc}\\text{min} &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\hline0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\1 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\2 &amp; 0 &amp; 1 &amp; 2 &amp; 2\\3 &amp; 0 &amp; 1 &amp; 2 &amp; 3\\end{array}&amp;% inner array of maximum values\\begin{array}{c|cccc}\\text{max}&amp;0&amp;1&amp;2&amp;3\\\\hline0 &amp; 0 &amp; 1 &amp; 2 &amp; 3\\1 &amp; 1 &amp; 1 &amp; 2 &amp; 3\\2 &amp; 2 &amp; 2 &amp; 2 &amp; 3\\3 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\end{array}\\end{array}\\% inner array of delta values\\begin{array}{c|cccc}\\Delta&amp;0&amp;1&amp;2&amp;3\\\\hline0 &amp; 0 &amp; 1 &amp; 2 &amp; 3\\1 &amp; 1 &amp; 0 &amp; 1 &amp; 2\\2 &amp; 2 &amp; 1 &amp; 0 &amp; 1\\3 &amp; 3 &amp; 2 &amp; 1 &amp; 0\\end{array}\\end{array}$$ 4.5 阵列$$\\begin{array}{c|lll}{↓}&amp;{a}&amp;{b}&amp;{c}\\\\hline{R_1}&amp;{c}&amp;{b}&amp;{a}\\{R_2}&amp;{b}&amp;{c}&amp;{c}\\\\end{array}$$ $$\\begin{array}{c|rrrr}&amp; x^3 &amp; x^2 &amp; x^1 &amp; x^0\\ &amp; 1 &amp; -6 &amp; 11 &amp; -6\\ {\\color{red}1} &amp; \\downarrow &amp; 1 &amp; -5 &amp; 6\\ \\hline &amp; 1 &amp; -5 &amp; 6 &amp; |\\phantom{-} {\\color{blue}0} \\end{array}$$ 4.6 矩阵$$\\begin{matrix}1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;1\\\\end{matrix}$$ 其中 pmatrix：小括号边框 bmatrix：中括号边框 Bmatrix：大括号边框 vmatrix：单竖线边框 Vmatrix：双竖线边框 省略元素 横省略号：\\cdots 竖省略号：\\vdots 斜省略号：\\ddots $$\\begin{bmatrix}{a_{11}}&amp;{a_{12}}&amp;{\\cdots}&amp;{a_{1n}}\\{a_{21}}&amp;{a_{22}}&amp;{\\cdots}&amp;{a_{2n}}\\{\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\{a_{m1}}&amp;{a_{m2}}&amp;{\\cdots}&amp;{a_{mn}}\\\\end{bmatrix}$$ $$ \\left[ \\begin{array}{cc|c} 1&amp;2&amp;3\\ 4&amp;5&amp;6 \\end{array} \\right]$$ 4.7 方程组$$\\left\\lbrace\\begin{array}{l}0 = c_x-a_{x0}-d_{x0}\\dfrac{(c_x-a_{x0})\\cdot d_{x0}}{|d_{x0}|^2} + c_x-a_{x1}-d_{x1}\\dfrac{(c_x-a_{x1})\\cdot d_{x1}}{|d_{x1}|^2} \\0 = c_y-a_{y0}-d_{y0}\\dfrac{(c_y-a_{y0})\\cdot d_{y0}}{|d_{y0}|^2} + c_y-a_{y1}-d_{y1}\\dfrac{(c_y-a_{y1})\\cdot d_{y1}}{|d_{y1}|^2} \\end{array} \\right.$$$$\\frac{\\partial u}{\\partial t}= h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} +\\frac{\\partial^2 u}{\\partial y^2} +\\frac{\\partial^2 u}{\\partial z^2}\\right)$$$$\\left \\lbrace\\begin{array}{c}a_1x+b_1y+c_1z=d_1 \\a_2x+b_2y+c_2z=d_2 \\a_3x+b_3y+c_3z=d_3x\\end{array}\\right.$$ $$f(n) =\\begin{cases}n/2, &amp; \\text{if n is even} \\3n+1, &amp; \\text{if n is odd} \\\\end{cases}$$ 5 MathJax 官方demo练习The Quadratic Formula$$x = \\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}$$Cauchy’s Integral Formula$$f(a) =\\frac{1}{2\\pi i} \\oint_\\lambda\\frac{f(z)}{z-a}dz$$Double angle formula for Cosines$$\\cos(\\theta+\\phi)=\\cos(\\theta)+\\cos(\\phi)+\\sin(\\theta)+sin(\\phi)$$Gauss’ Divergence Theorem$$\\int_d(\\nabla \\cdot F)dV = \\int_{\\partial D}F\\cdot ndS$$Curl of a Vector Field$$\\vec \\nabla \\times \\vec F = \\left(\\frac{\\partial F_z}{\\partial y}-\\frac{\\partial F_y}{\\partial z}\\right)i + \\left(\\frac{\\partial F_x}{\\partial z}-\\frac{\\partial F_z}{\\partial x}\\right)j + \\left(\\frac{\\partial F_y}{\\partial x}-\\frac{\\partial F_x}{\\partial y}\\right)k$$Standard Deviation$$\\theta = \\sqrt{\\frac{1}{n}\\sum_{i=1}^N(x_i-\\mu)^2}.$$Definition of Christoffel Symbols$$(\\nabla_XY)^k = X^i(\\nabla_iY)^k = X^i\\left(\\frac{\\partial Y^k}{\\partial X^i} + \\Gamma_{im}^kY^m\\right)$$ 6 MathJax 工具latex在线编辑工具 mathjax官方在线编辑demo","tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://galaxias-sapphi-ren.github.io/tags/Hexo/"},{"name":"MathJax","slug":"MathJax","permalink":"https://galaxias-sapphi-ren.github.io/tags/MathJax/"}]},{"title":"javac源码笔记与简单的编译原理","date":"2017-03-14T01:35:28.000Z","path":"2017/03/javac/","text":"Reads Java class and interface definitions and compiles them into bytecode and class files. —— java8 - javac 前言 java 程序的编译工作通常使用 IDE 或 Maven，Gradle 等工具完成，开发过程容易忽视java编译期隐藏的细节，深入理解 javac、编译等相关概念。 javac 是 JDK 的Java语言前端编译器工具，将满足 Java 语言规范（JLS, Java Language Specification）的 .java 源文件编译成为满足JVM规范（JVMS, Java Virtual Machine Specification）的 .class 字节码文件。 学习 javac，可以更准确、直观地理解 Java 语言中深层知识。如：编译原理、插入式注解API JSR-296、语法糖等核心技术。理解如何生成字节码编译过程，便于理解JLS，JVMS，并发编程内存模型、java 关键字实现、字节码增强技术等。 一般而言，javac 的编译过程为：源代码 –(词法分析)–&gt; 符号Token流 –(语法分析)–&gt; 抽象语法树 –&gt; 填充符号表 –&gt; –(注解处理器)–&gt; 插入式注解语法树 -(语义分析)-&gt; 完整语法树 –(生成代码)–&gt; 字节码。是java的前端编译器。 javac由java语言编写，支持JSR 269（Pluggable Annotation Processing API）和JSR 199（the Java Compiler API），方便调试学习。 1 hello javac 1.1 javac 经典应用.java 源文件： public class HelloWorld { public static void main(String[] args) { System.out.println(&quot;Hello, World!&quot;); } } class SayHiWorld{ public static void main(String[] args) { System.out.println(&quot;Hi! World!&quot; + org.joda.time.DateTime.now().toString(&quot;E&quot;);); } } 编译为 .class 类文件： javac -help javac -cp &quot;lib/jodatime.jar&quot; -d target -target 1.8 HelloWorld.java 🗣 Tips : -d 指定了生成class文件的根目录，并且会根据class的包路径创建子目录。 -cp JRE搜索资源文件的路径指定，默认当前路径，只会影响当前进程，覆盖CLASSPATH。 1.2 javac 实例场景├── lib │ └── jodatime.jar ├── resources │ └── config.xml ├── src │ ├── HelloWorld.java │ └── service │ ├── WorldConfig.java │ ├── WorldService.java │ └── impl │ └── EarthServiceImpl.java └── target 自动化编译脚本 PROJECT_DIR=/Users/sapphire/Projects/java/basic # clean target directory rm -rf $PROJECT_DIR/target/* # prepare arg files find $PROJECT_DIR/src -name &quot;*.java&quot;&gt;$PROJECT_DIR/target/files.txt echo &quot;-d $PROJECT_DIR/target&quot; &gt;$PROJECT_DIR/target/options.txt # compile javac -cp &quot;$PROJECT_DIR/lib/*&quot; @$PROJECT_DIR/target/options.txt @$PROJECT_DIR/target/files.txt # copy resources to target cp -rf $PROJECT_DIR/resources/* $PROJECT_DIR/target # clean temp files rm -rf $PROJECT_DIR/target/options.txt $PROJECT_DIR/target/files.txt 1.3 编译 与 javac1.3.1 编译编译：将便于人编写、阅读、维护的高级计算机语言所写作的源代码程序，翻译为计算机能解读、运行的低阶机器语言的程序的过程。负责这一过程的处理的工具叫做编译器。 通俗理解，编译 = 分析 + 翻译 + 优化，把源代码转化为机器码的过程。 编译 描述 分析 语法、词法、语义 翻译 java语言规范 -&gt; jvm规范 优化 改善编码风格并提高效率 编译原理中，根据编译任务不同： 字节码不是机器能识别的语言，还需要 JVM 再将字节码转换成机器码。 编译期 任务 代表 前期编译器 .java -&gt; .class Sun Javac、Eclipse JDT 的增量式编译器 后端运行期编译器 .class -&gt; 机器码 HotSpot 的 C1、C2 编译器 静态前期编译器 .java -&gt; 机器码 GCJ、Excelsior JET 前端编译为字节码的好处： 解耦后端JVM编译，减少JVM工作，避免每次执行时词法、语法、语义分析。方便读取，执行速度比直接解析源代码（AOT）快。 字节码可以由Groovy，Clojure，Scala语言生成，供JVM调用。 字节码有版本信息，可以在编译过程抹平一些语言层面的变化。 字节码格式比源码紧凑、轻量，方便方便网络传输。嵌入设备不够资源跑起完整的编译器，只需嵌入一个小巧的JVM就可以编译源码。 1.3.2 前端编译 javacjavac 是java前端编译的一种编译器实现。 🗣 Tips : Javac对代码的运行效率几乎没有优化措施，性能的优化集中在后端的即时编译器中。javac编译器实现一些“语法糖”，例如foreach语法、注解等。字节码是对程序应该如何表现的描述，JVM对Program的行为和硬件有更多了解，JIT时对字节码进行任意优化。在很多情况下，编译时优化阻碍了JIT时更重要的优化。 《深入理解JAVA虚拟机》第十、十一章 编译运行期优化 1.3.3 反编译 javap 将字节码转化为看得懂字节码，synchronized底层依赖了ACC_SYNCHRONIZED标记和monitorenter、monitorexit两个指令来实现同步。 jad 不支持 Java 8 - lambda 表达式，字符串的 switch 是通过equals()和hashCode()实现的。 IDEA插件 jclasslib 字节码查看器 view | show bytecode with jclasslib。 1.3.4 后端编译 Just-In-Time Compiler本文关注javac的编译过程，对后端编译一笔带过。 传统 JVM 通过解释字节码将其翻译成对应的机器指令执行。为了解决效率问题，小部分热点代码消耗大部分的资源，引入 JIT 技术。 进行热点探测（Hot Spot Detection）识别热点代码（Hot Spot Code）翻译成机器码后缓存。HotSpot 使用基于计数器的热点探测（Counter Based Hot Spot Detection）设计方法计数器（方法、代码块）、回计数器（for/while）统计方法的执行次数，超过阀值就认为是热点方法，触发JIT编译。 HotSpot 内置 Client Compiler （C1 更好的编译速度）和Server Compiler（C2 更好的编译质量）两种JIT编译模式分层编译。 编译优化，如逃逸分析、 锁消除、 锁膨胀、 方法内联、 空值检查消除、 类型检测消除、 公共子表达式消除。 JVM 实际采用解释器和JIT混用模式 Java HotSpot(TM) 64-Bit Server VM (build 13+33, mixed mode, sharing) 2 javac 编译过程源码分析从 Sun Javac 的源码来看，编译main方法位于com.sun.tools.javac.Main // my code public static void main(String[] args) { Main m = new Main(&quot;fx_debug&quot;); m.compile(new String[]{&quot;/.../HelloWorld.java&quot;}); } // com.sun.tools.javac.Main public static void main(String[] args) throws Exception { System.exit(compile(args));//入口 } public Result compile(String[] args, String[] classNames, Context context, List&lt;JavaFileObject&gt; fileObjects, Iterable&lt;? extends Processor&gt; processors) { // ...检测javac行中命令参数不对，返回错误码 Result.CMDERR // ...得到编译文件集合 files = processArgs(CommandLine.parse(args), classNames); fileManager = context.get(JavaFileManager.class); //...实例编译器 JavaCompiler.instance(context).compile(fileObjects, classnames.toList(), processors); } //com.sun.tools.javac.main.JavaCompiler public void compile(List&lt;JavaFileObject&gt; sourceFileObjects, List&lt;String&gt; classnames, Iterable&lt;? extends Processor&gt; processors) { // 初始化插入式注解处理器 initProcessAnnotations(processors); delegateCompiler = // 2.注解处理执行 processAnnotations( // 1.2 输入到符号表 enterTrees(stopIfError(CompileState.PARSE, // 1.1 词法分析和语法分析 parseFiles(sourceFileObjects))), classnames); // 3.分析及字节码class文件生成 delegateCompiler.compile2(); 编译过程大致可以分为3个过程 分别对应Token流，语法树，注解语法树，字节码输出。 2.1 Parse and Enter两个重要的接口与实现 接口 作用 实现 com.sun.tools.javac.parser.Lexer 词法分析 com.sun.tools.javac.parser.JavacParser com.sun.tools.javac.parser.Parser 构建抽象语法树 com.sun.tools.javac.parser.Scanner 该阶段将源码文件解析构建抽象语法树( Abstract Syntax Tree，AST )。从功能上分为词法分析和语法分析，实际上同时进行。编译时，通过ParserFactory与ScannerFactory工厂类管理JavacParser与Scanner对象。JavacParser解析时，Scanner读取源文件字符流，逐个读入Token，构建抽象语法树。之后，编译器就基本不会再对源码文件进行操作，后续操作都建立在抽象语法树之上。（添加默认无参构造方法等） public List&lt;JCCompilationUnit&gt; parseFiles(Iterable&lt;JavaFileObject&gt; fileObjects) { if (shouldStop(CompileState.PARSE)) return List.nil(); // 语法树对象 ListBuffer&lt;JCCompilationUnit&gt; trees = new ListBuffer&lt;&gt;(); Set&lt;JavaFileObject&gt; filesSoFar = new HashSet&lt;JavaFileObject&gt;(); for (JavaFileObject fileObject : fileObjects) { if (!filesSoFar.contains(fileObject)) {//控制循环 filesSoFar.add(fileObject); trees.append(parse(fileObject)); } } return trees.toList(); } 2.1.1 词法分析将Java源代码按照Java关键字、自定义关键字、符号等按顺序分解为了可识别的Token流。 输入 输出 描述 源代码的字符流 标记（Token）集合 关键字、变量名、字面量、运算符 字符char是程序编写过程中的的最小元素，标记Token是编译过程的最小元素。 主要实现类 功能 com.sun.tools.javac.parser.JavacParser 规定哪些词符合Java语言规范，具体读取和归类不同词法的操作由scanner完成。 com.sun.tools.javac.parser.Scanner 负责逐个读取源代码的单个字符，然后解析符合Java语言规范的Token序列，调用一次nextToken()都构造一个Token com.sun.tools.javac.parser.Tokens$Token 规定了所有Java语言的合法关键词，包含了开始/结束位置，类型。 com.sun.tools.javac.parser.Tokens$TokenKind 描述一个Token的类型，如IDENTIFIER（自定义标识）、BOOLEAN、BREAK、BYTE、CASE。 com.sun.tools.javac.util.Names 用来存储和表示解析后的词法，每个字符集合都会是一个Name对象，所有的对象都存储在Name.Table内部类中。 com.sun.tools.javac.parser.KeyWords * 负责将字符集合对应到token集合中。JDK9后由Tokens完成 🗣 Tips : java命名规范指出声明变量的时候必须以字母、下划线或者美元符开头，包括字母、数字、下划线或者美元符。使JavacParser识别int y=x+1的Token流。 Tokens根据Token.name先转化成Name对象，建立Name和Token的对应关系，保存在key数组中。这个key数组只保存了在Token类中定义的所有Token到Name对象的关系，而其他所有字符集合Tokens都会将它对应到TokenKind.IDENTIFIER类型 Javac中每个与文件相关的实现类都直接或间接实现了JavaFileObject接口，这个接口专门为操作.java文件及.class文件而定义的。每个RegularFileObject类对象可以代表一个Java源文件。调用getCharContent()方法获取字符流输入。 关键代码nextToken的主要逻辑：处理特殊字符、标识符、16进制、数字、分隔符、斜杠开头、反斜杠开头、双引号开头、默认处理。 2.1.2 语法分析 输入 输出 描述 标记（Token）集合 抽象语法树（AST） 包、类型、运算符、修饰符、接口、返回值、代码注释 将Token流组建成更加结构化的语法树，描述程序代码语法结构，检查是否符合Java语言规范。每个语法树上的节点都是com.sun.tools.javac.tree.JCTree的一个实例，代表着程序代码中的一个语法结构（Construct），如包、类型、修饰符、运算符、接口、返回值甚至代码注释。 实现类 功能 com.sun.tools.javac.tree.TreeMaker 生成语法节点，根据Name对象构建一个语法节点 com.sun.tools.javac.tree.JCTree 生成的语法节点都会继承jctree和实现（如根节点JCCompilationUnit） com.sun.tools.javac.tree.JCTree#Tag enum类，区分语法树的类型。 com.sun.tools.javac.tree.JCTree#pos 源文件中位置 com.sun.tools.javac.tree.JCTree#type Java类型 🗣 Tips : JCCompilationUnit表示一个编译单元，一般是一个源文件（可以是多个类）内容对应一个编译单元，同时这也是顶层的树节点。包含包注解 List、包名 JCExpression、和树 List。 在遍历像抽象语法树这样由各种类的实例所组成的树形结构时，通常会借助Visitors访问者模式来完成。 2.1.3 填充符号表一个类中的符号变量，除了类本身定义，其他类定义。如调用其他类方法、变量，继承或实现父类和接口等。 调用其他类的符号变量时，就需要通过符号表来进行查找。 这些类的符号也需解析到符号表中。com.sun.tools.javac.comp.Enter按照递归向下的顺序解析语法树，将所有的符号都输入到符号表中。 输入 输出 描述 当前范围的定义域（definitions） 待处理列表，包含需要分析并生成类文件的树. 一组符号地址和符号信息构成的表格 符号表是由一组符号地址和符号信息构成的表格。在语义分析中，符号表所登记的内容将用于语义检查和产生中间代码。在目标生成阶段，当对符号名进行地址分配时，符号表是地址分配的依据。 实现类 功能 com.sun.tools.javac.comp.Enter 内容填充，符号表（Symbol Table）填充的出口是一个待处理列表，包含了每一个编译单元的抽象语法树的顶级节点以及 package-info.java 的顶级节点。 com.sun.tools.javac.comp.MemberEnter 使类变得完整，确定类的泛型参数、父类、接口，该类的所有符号输入到它所对应的scope VarSymbol 预定义符号的输入，对操作符的处理 2.2 Annotation ProcessingJDK 6 实现了插入式注解处理API（JSR-269）,位于javax.annotation.processing和javax.lang.model包。 通过声明一个注解，实现一个注解处理器。注册服务后 在编译期由com.sun.tools.javac.processing.JavacProcessingEnvironment类处理注解。读取、修改、添加抽象语法树中的任意元素。像反射一样访问类、字段、方法和注解等元素，创建新的源文件。每一个插入式注解处理器操作语法树，编译器将回到解析及填充符号表的过程循环。 减少编写配置文件的劳动量，提高代码可读性。 测试使用时，测试类和实现类写在不同子模块下！！！否则编译不通过！！！ 2.2.1 javac 命令编译过程 声明一个注解 创建一个注解处理器，注解处理器需实现 javax.annotation.processing.Processor 接口或继承 javax.annotation.processing.AbstractProcessor 类。重写process方法。 为注解处理器注册服务。在META-INF.services文件夹下创建 javax.annotation.processing.Processor文件。写入注解处理器的全称。 为了能够让项目能够通过编译，我们需要为Java编译器添加一个不进行注解处理的参数 &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;compilerArgument&gt;-proc:none&lt;/compilerArgument&gt; &lt;/configuration&gt; &lt;/plugin&gt; 也可使用 javac -processor指定注解处理器 2.2.2 编译器 API 实例过程使用 CompilationTask 的 setProcessors 方法可以传入注解处理器。 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); DiagnosticCollector&lt;JavaFileObject&gt; diagnostics = new DiagnosticCollector&lt;&gt;(); VisitProcessor processor = new VisitProcessor(); StandardJavaFileManager manager = compiler.getStandardFileManager(diagnostics, null, null); File file = new File(&quot;.../VisitProcessor.java&quot;); Iterable &lt; ? extends JavaFileObject&gt; sources = manager.getJavaFileObjectsFromFiles(Arrays.asList(file)); CompilationTask task = compiler.getTask(null, manager, diagnostics, Arrays.asList(&quot;-d&quot;, &quot;target/classes&quot;), null, sources); task.setProcessors(Arrays.asList(processor)); task.call(); manager.close(); 2.2.3 实例仿照findbugs实现一个简单的类编写规范检查 注解类 Check@Target({ElementType.TYPE}) @Retention(RetentionPolicy.SOURCE) public @interface Check {//标识一个类被 findbugs 检查 } 注解处理类 ClassChecker//以下两个注解可以重写 getSupportedAnnotationTypes 与 getSupportedSourceVersion 方法 @SupportedAnnotationTypes(&quot;per.rsf.jsr269.anno.Check&quot;) @SupportedSourceVersion(SourceVersion.RELEASE_8) public class ClassChecker extends AbstractProcessor { @Override public boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) { Set&lt;? extends Element&gt; elements = roundEnv.getRootElements(); ClassScanner scanner8 = new ClassScanner(); for (Element element : elements) { scanner8.scan(element); } return false;// 如果为true，则接下来的处理器不可处理该注解；如果为false，则接下来的处理器可以处理该处理器处理的注解。 } } class ClassScanner extends ElementScanner8&lt;Set&lt;? extends Element&gt;, Element&gt; { //字段 @Override public Set&lt;? extends Element&gt; visitVariable(VariableElement e, Element element) { // if e.getConstantValue() != null 访问静态常量 // if e.getEnclosingElement().getKind() == ElementKind.ENUM 访问枚举 // else 访问实例变量 String name = e.getSimpleName().toString(); // ... } //类 @Override public Set&lt;? extends Element&gt; visitType(TypeElement e, Element element) { // e.getQualifiedName() 访问全类名 // e.getSimpleName() 访问类名 // ... return super.visitType(e, element); } //方法 @Override public Set&lt;? extends Element&gt; visitExecutable(ExecutableElement e, Element element){ // e.getReturnType().getKind() == TypeKind.BOOLEAN 访问方法返回类型 // ... return super.visitExecutable(e, element); } } 注册服务在文件夹resources/META-INF/services下创建文件javax.annotation.processing.Processor，内容如下： per.rsf.jsr269.processor.ClassChecker 测试类@Check public class testCHECK { static int a; String UPPER; public boolean haveIS(){ return true; } } 结果将项目打成jar包使用 javac -cp /.../javac/target/javac.jar testCHECK.java 🗣 Tips : 模拟Lombok实现get set方法，依赖 com.sun.tools.javac.* 包 2.3 Analyse and Generate2.3.1 语义分析 输入 输出 描述 语法树、符号表 字节码文件 标注检查，数据及控制流分析 语法分析将源文件抽象成结构正确的抽象语法树，但无法保证符合逻辑的。 实现类 功能 com.sun.tools.javac.comp.Attr 标注检查：名称消解、变量使用声明、类型检查、常量折叠、推导泛型方法的参数类型 com.sun.tools.javac.comp.Flow 数据及控制流分析：局部变量在使用前是否被正确赋值、final变量不被重复修饰、确定方法返回值类型、方法的每条路径是否都有返回值、是否所有的受查异常都被正确处理 com.sun.tools.javac.comp.Check 用来辅助Attr类检查语法树中变量类型是否正确，如二元操作符两边的操作数的类型是否匹配，方法返回值是否和接收的引用值类型匹配 com.sun.tools.javac.comp.Resolve 检查变量，方法或者类的访问是否合法，变量是否是静态变量 com.sun.tools.javac.comp.ConstFold 将一个字符串常量中的多个字符合并成一个字符串 com.sun.tools.javac.comp.Infer 帮助推导泛型方法的参数类型 🗣 Tips : 常量折叠：a=1+2 -&gt; a=3 如果代码中没有提供任何构造函数，自动添加一个没有参数、访问权限与当前类一致的默认构造函数。如果提供了构造函数，则在代码生成阶段添加。 2.3.2 语法糖（Syntactic Sugar）Java中最常用的 语法糖 主要是前面提到过的泛型、变长参数、自动装箱/拆箱等。JVM运行时不支持这些语法，它们在编译阶段还原回简单的基础语法结构，这个过程称为解语法糖。解语法糖的过程由JavaCompiler#desugar()方法触发。 实现类 功能 com.sun.tools.javac.comp.TransTypes Generic Java to conventional Java com.sun.tools.javac.comp.Lower inner classes, class literals, assertions, foreach loops, etc. 2.3.3 字节码生成 输入 输出 描述 语法树、符号表 字节码文件 编译器添加和转换少量的代码，生成字节码文件。 把前面各个步骤所生成的信息转化成字节码，在收敛代码的过程中，将实例构造器方法和类重载构造器方法添加到语法树之中。 实现类 功能 com.sun.tools.javac.jvm.Gen 遍历语法树，生成JVM操作码序列结合 om.sun.tools.javac.jvm.Items 表示任何可寻址的操作项，这些操作项都可以作为一个单位出现在操作栈上，不同的Item对应不同JVM操作码 com.sun.tools.javac.jvm.Code 存储生成的字节码，并提供一些能够映射操作码的方法 com.sun.tools.javac.jvm.ClassWriter 输出字节码，生成最终的Class文件 2.3.3.1 clinit与init 方法编译器自动收集static代码块，收敛顺序为先父后子，先单后块，父接口随遇而安。final static 静态不可变常量提前被编译器放入常量池，无需初始化。 方法编译器自动收集非static代码块，收敛顺序为先父后子，先单后块最后构造函数。 方法（实例化阶段）永远在方法（类初始化阶段）执行后执行。🗣 Tips : clinit类构造器，在jvm进行类加载—验证—解析—初始化中的初始化阶段（类实例化 调用静态字段或方法）调用，对静态变量，静态代码块进行初始化。多线程时，clinit方法阻塞，一个类只会在一个JVM进程运行期间执行一次clinit方法。 init实例构造器，类实例化阶段（new 反射 克隆 反序列化），对非静态变量解析初始化。若实例时类没有初始化，先执行clinit方法。 static class Parent{ public int C=1;//init public static int A=1；//clinit static{ A=2；}//clinit static class Sub extends Parent{ public int C=2;//init public static int B=A//clinit } public static void main(String[]args){ System.out.println((new Sub).C);//2 System.out.println(Sub.B);//2 } } 3 javac API JDK 6 增加了规范 JSR-199 和 JSR-296，提供相关的 API 绿色标注的包是官方 API（Official API）， JSR-199 和 JSR-296. 黄色标注的包为（Supported API）. 紫色标注的包代码全部在 com.sun.tools.javac.* 包下，为内部 API（Internal API）和编译器的实现类。 类名 注释 javax.annotation.processing 注解处理 (JSR-296) javax.lang.model 注解处理和编译器 Tree API 使用的语言模型 (JSR-296) javax.lang.model.element 语言元素 javax.lang.model.type 类型 javax.lang.model.util 语言模型工具 javax.tools Java 编译器 API (JSR-199) com.sun.source.* 编译器 Tree API，提供 javac 工具使用的抽象语法树 AST 的只读访问 com.sun.tools.javac.* 内部 API 和编译器的实现类 3.1 Lombok实现 JSR269 插件化注解APILombok以及MapStruct都是通过在目标代码上标记注解，编译器能够根据注解生成对应的实现代码。比如Lombok在属性上标记@Getter，那么在这个Java Bean内就会生成对应属性的get方法。 本质上通过Java的一个标准API（Pluggable Annotation Processing API）实现，简称JSR269。定义了通用的插入式API用于创建标准的注解处理器。 3.1.1 JSR269运行机制4 javac 调试TODO 内容没有成功，也没有用到。 4.1 修改 idea.vmoptions-Dcompiler.process.debug.port=12346 4.2 配置远程debug 4.3 启用idea编译调试IDEA默认会禁用编译调试，这里需要开启一个开关，以此让IDEA在编译之前等待调试程序的链接。并且，这个配置在IDEA重启后会失效。 双击Shift，打开平常搜索类的界面，输入debug build process","tags":[{"name":"Javac","slug":"Javac","permalink":"https://galaxias-sapphi-ren.github.io/tags/Javac/"},{"name":"ToolKits","slug":"ToolKits","permalink":"https://galaxias-sapphi-ren.github.io/tags/ToolKits/"}]},{"title":"Machine Learning | 推荐系统","date":"2017-03-08T01:00:00.000Z","path":"2017/03/recsysGuide/","text":"2017年03月08日 - rensifei @Copyright Smart Home &amp; Roobo 推荐系统是一种信息过滤系统，用于预测用户对物品的“评分”或“偏好”。 推荐系统是一种有效代替 搜索算法 的方式，用于解决在 信息过载 环境下，根据用户的特征，为用户提供有用信息。 推荐系统 摘要 ‘惠生活’是到家服务的信息撮合综合平台，为用户提供到家服务与资讯，旨在解决用户需求和到家服务间的不对称问题。同时，平台和服务提供方发布海量的服务信息造成一定程度的信息过载。如何为用户提供准确而有价值的信息成为了具有应用价值的课题。本文从推荐系统的基本概念出发，收录不同要解决的问题的类型、算法、模型，为平台提供辅助服务和技术参考。 本文是推荐系统的学习文档，描述了我们使用推荐系统可能要解决的问题，算法分类，不对算法进行详细研究、混合和改进。目标是结合数据挖掘、深度学习提供相关推荐系统的解决方案或解决路径。‘关键字 推荐系统 数据挖掘 深度学习 第一章：推荐系统概述 1.1 推荐系统推荐系统是一种信息过滤系统，用于预测用户对物品的“评分”或“偏好”。 推荐系统是一种有效代替 搜索算法 的方式，用于解决在 信息过载 环境下，根据用户的特征，为用户提供有用信息。 推荐系统由三要素组成： 用户 候选对象。 包括：电影、音乐、新闻、书籍、学术论文、搜索查询、分众分类、以及其他产品。也有一些推荐系统专门为寻找专家、合作者、笑话、餐厅、美食、金融服务、生命保险、网络交友，以及Twitter页面设计。 推荐算法 推荐系统的通用模型为： 推荐系统的形式化定义为： 设 U 是所有用户（User）的集合，I 是所有推荐候选项目（item）的集合，如书籍、电影、餐馆。 设相似度函数 s 是用来计算项目 i 对用户 u 的可用度，即 s : I * U -&gt; R 其中 R 是一个全序排列集合。（例如：非负整数集合或者在一定范围内的实数集合） 因此，对于每个用户的效用最大物品公式为： 1.2 使用信息过滤解决信息过载问题 应用 描述 价值（公司／案例） 类目导航 用户主动按照类目逐层查找 雅虎、新浪、搜狐、网易门户 搜索 用户主动提供意图明确的查询 Google、百度 推荐 用户主动提供给用户一种选择 Netflix、今日头条 1.3 推荐系统的应用价值推荐的应用 音乐、电影的推荐 电子商务中的商品推荐 个性化阅读（新闻消息） 社交网络的好友推荐、朋友圈推荐 基于位置的服务推荐 … 推荐的价值 Netflix 2/3的电影是因为被推荐而观看的 Google News因为推荐提升了38%的点击 Amazon的销售中推荐比高达35% 1.4 推荐系统的评价标准 用户满意度(User Stisfaction)：调研及用户反馈，点击率、转化率等。 准确性(Accurcy)：precision/recall/F-score 覆盖率(Coverage)：照顾到尾部物品和用户 多样性(Diversity)：两两之间不相似 新颖性(Novelty)：没听过、没见过的物品 惊喜性(Serendipity)：如何评价 用户信任度(Trust)／可解释性(Explantion)：推荐理由 鲁棒性／健壮性(Robustness)：哈利波特现象，抗攻击、反作弊 实时性(Real-time/online)：新加入的物品，新的用户行为 商业目标(Business Target)：一个用户带来多少盈利 1.5 推荐系统的影响因素 因素 描述 用户交互界面(User Inerface) 用户对推荐系统的第一感知，如Twitter将favorite功能由star改为heart 数据(Date) 数据收集的有效性与全面性，数据处理的清理、挖掘 领域知识(Domain Knowedge) 产品的定位、具体推荐需求的理解 算法迭代(Algorithm) 锦上添花，量变引起质变 推荐系统的普遍观点为： 重要性UI&gt;数据&gt;算法 推荐系统中一味追求先进的算法算是个误区，通常论文研究类的推荐方法有的带有很多的假设限制，有的考虑工程实现问题较少，推荐系统需要大量的数据整理和转化，同时更需要考虑公司业务特性以及与现有系统的集成，方能形成推荐系统和业务之间的良性循环; 推荐系统离线测试很好 上线后要么没有严格的测试结果而只能凭感觉，要么实际效果差强人意，我想主要缘于离线测试比较理想，而在线AB冠军测试无论对于前端还是后台要求都很高，没有雄厚的研发实力难以实现; 推荐系统受到的外部干扰因素特别多(季节、流行因素等) 整个系统需要不断的迭代更新，没有一劳永逸的事情。 第二章：推荐算法 推荐算法 推荐算法本质上是基于特征向量空间和特征加权矩阵。 当特征向量的维度很大时，基于特征向量空间和特征加权矩阵的推荐算法计算复杂度将很大。常见的做法是采用降维技术，比如使用minhash(simhash),然后计算权值矩阵。另一种做法是先聚类，将N维的特征空间，转变成M维的特征空间(M&lt;N)。 2.1 推荐系统分类 2.2 个性化推荐系统概述 2.2.1 基于人口统计学的推荐机制（Demographic-based Recommendation）描述 是一种最易于实现的推荐方法，它只是简单的根据系统用户的基本信息发现用户的相关程度，然后将相似用户喜爱的其他物品推荐给当前用户。首先，系统对每个用户都有一个用户 Profile 的建模，其中包括用户的基本信息，例如用户的年龄，性别等等；然后，系统会根据用户的 Profile 计算用户的相似度，可以看到用户 A 的 Profile 和用户 C 一样，那么系统会认为用户 A 和 C 是相似用户，在推荐引擎中，可以称他们是“邻居”；最后，基于“邻居”用户群的喜好推荐给当前用户一些物品。 优点 不使用当前用户对物品的喜好历史数据，对于新用户没有“冷启动（Cold Start）”的问题。 这个方法不依赖于物品本身的数据，所以这个方法在不同物品的领域都可以使用，它是领域独立的（domain-independent）。 缺点 这种基于用户的基本信息对用户进行分类的方法过于粗糙，尤其是对品味要求较高的领域，比如图书，电影和音乐等领域，无法得到很好的推荐效果。 涉及信息敏感问题，如用户的年龄等。 2.2.2 基于内容的推荐（Content-based Recommendation）描述 其主要根据用户之前的喜好，推荐相似的物品。 基于内容的推荐是在推荐引擎出现之初应用最为广泛的推荐机制，它的核心思想是根据推荐物品或内容的元数据，发现物品或者内容的相关性，然后基于用户以往的喜好记录，推荐给用户相似的物品。这种推荐系统多用于一些资讯类的应用上，针对文章本身抽取一些tag作为该文章的关键词，继而可以通过这些tag来评价两篇文章的相似度。 基于内容的推荐是信息过滤技术的延续与发展，它是建立在项目的内容信息上作出推荐的，而不需要依据用户对项目的评价意见，更多地需要用机 器学习的方法从关于内容的特征描述的事例中得到用户的兴趣资料。在基于内容的推荐系统中，项目或对象是通过相关的特征的属性来定义，系统基于用户评价对象 的特征，学习用户的兴趣，考察用户资料与待预测项目的相匹配程度。用户的资料模型取决于所用学习方法，常用的有决策树、神经网络和基于向量的表示方法等。 基于内容的用户资料是需要有用户的历史数据，用户资料模型可能随着用户的偏好改变而发生变化。 案例 Pandora的音乐推荐就是个典型的基于内容的推荐系统，他们把音乐使用各种维度的属性进行描述，然后根据用户之前的兴趣爱好推荐相似属性风格的音乐。 优点 内容的推荐系统在文本内容的推荐方面优势明显 推荐效果简单直观，无需解释 针对性强，用户定制性好，适用于各种不同的用户 不需要别的领域知识 不存在冷启动和稀释性问题，能推荐新的或是不流行的事物 基于物品本身特征推荐，因此不存在过度推荐热门的问题 缺点 对被推荐项有一定要求 对象内容信息易于提取，能构成有意义的特征，否则很难保证推荐结果的相关性。（反例如音乐、视频、艺术品）豆瓣网采用人工维护tag的策略，依靠用户去维护内容的tag的准确性。 对关键词、词频等信息过分依赖，容易忽略适合的推荐而转而推荐预测值高的推荐。 无法挖掘用户潜在兴趣，推荐以历史数据为主。 2.2.3 协同过滤推荐（Collaborative Filtering Recommendation）描述 协同过滤是一种在推荐系统中广泛采用的推荐方法。这种算法基于一个“物以类聚，人以群分”的假设，喜欢相同物品的用户更有可能具有相同的兴趣。基于协同过滤的推荐系统一般应用于有用户评分的系统之中，通过分数去刻画用户对于物品的喜好。协同过滤被视为利用集体智慧的典范，不需要对项目进行特殊处理，而是通过用户建立物品与物品之间的联系。目前，协同过滤推荐系统被分化为两种类型：基于用户(User-based)的推荐和基于物品(Item-based)的推荐。 协同过滤是推荐系统中应用最早和最为成功的技术之一。它一般采用最近邻技术，利用用户的历史喜好信息计算用户之间的距离，然后 利用目标用户的最近邻居用户对商品评价的加权评价值来预测目标用户对特定商品的喜好程度，系统从而根据这一喜好程度来对目标用户进行推荐。协同过滤最大优点是对推荐对象没有特殊的要求，能处理非结构化的复杂对象，如音乐、电影。 优点 这种方法计算出来的推荐是开放的，可以共用他人的经验，很好的支持用户发现潜在的兴趣偏好 不需要别的领域知识 随着时间推移性能提高 推荐个性化，自动化程度高 能处理复杂的诶结构化对象 缺点 方法的核心是基于历史数据，所以对新物品和新用户都有“冷启动”的问题。 推荐的效果依赖于用户历史偏好数据的多少和准确性。 在大部分的实现中，用户历史偏好是用稀疏矩阵进行存储的，而稀疏矩阵上的计算有些明显的问题，包括可能少部分人的错误偏好会对推荐的准确度有很大的影响等等。 热门倾向性严重，很难推荐小众偏好。 2.2.3.1 基于用户(User-based)的协同过滤推荐 UserCF描述 (1)找到与目标用户兴趣相似的用户群; (2)找到这个集合中用户喜欢的，而目标用户没有听说过得商品推荐之; 基于用户的协同过滤推荐的基本原理是，根据所有用户对物品或者信息的偏好（评分），发现与当前用户口味和偏好相似的“邻居”用户群，在一般的应用中是采用计算“K-Nearest Neighboor”的算法；然后，基于这 K 个邻居的历史偏好信息，为当前用户进行推荐。 目前，数以百计的网站都采用了这种推荐系统，涉及到电影、音乐、书籍、交友、购物、文章等。 优点 推荐物品之间在内容上可能完全不相关，因此可以发现用户的潜在兴趣，并且针对每个用户生成其个性化的推荐结果。 缺点 一般的Web系统中，用户的增长速度都远远大于物品的增长速度，因此其计算量的增长巨大，系统性能容易成为瓶颈。因此在业界中单纯的使用基于用户的协同过滤系统较少。 2.2.3.2 基于物品(Item-based)的协同过滤推荐 ItemCF描述 基于物品的协同过滤和基于用户的协同过滤相似，它使用所有用户对物品或者信息的偏好（评分），发现物品和物品之间的相似度，然后根据用户的历史偏好信息，将类似的物品推荐给用户。基于物品的协同过滤可以看作是关联规则推荐的一种退化，但由于协同过滤更多考虑了用户的实际评分，并且只是计算相似度而非寻找频繁集，因此可以认为基于物品的协同过滤准确率较高并且覆盖率更高。 优点 准确性好，表现稳定可控，便于离线计算。 扩展性和算法性能好,由于项目的增长速度一般较为平缓，因此性能变化不大。 缺点 缺点就是无法提供个性化的推荐结果。 2.2.3.2 协同过滤算法的比较两种协同过滤，在基于用户和基于物品两个策略中应该如何选择呢？其实基于物品的协同过滤推荐机制是 Amazon 在基于用户的机制上改良的一种策略，因为在大部分的 Web 站点中，物品的个数是远远小于用户的数量的，而且物品的个数和相似度相对比较稳定；同时基于物品的机制比基于用户的实时性更好。但也不是所有的场景都是这样的情况，在一些新闻推荐系统中，也许物品，也就是新闻的个数可能大于用户的个数，而且新闻的更新程度也有很快，所以它的相似度依然不稳定。所以，推荐策略的选择其实也和具体的应用场景有很大的关系。 基于协同过滤的推荐机制是现今应用最为广泛的推荐机制， 2.2.4 基于关联规则的推荐（Association Rule-based Recommendation）描述 基于物品间的共现性挖掘频繁项。 基于关联规则的推荐更常见于电子商务系统中，并且也被证明行之有效。其实际的意义为购买了一些物品的用户更倾向于购买另一些物品。基于关联规则的推荐系统的首要目标是挖掘出关联规则，也就是那些同时被很多用户购买的物品集合，这些集合内的物品可以相互进行推荐。目前关联规则挖掘算法主要从Apriori和FP-Growth两个算法发展演变而来。 是以关联规则为基础，把已购商品作为规则头，规则体为推荐对象。关联规则挖掘可以发现不同商品在销售过程中的相关性，在零 售业中已经得到了成功的应用。管理规则就是在一个交易数据库中统计购买了商品集X的交易中有多大比例的交易同时购买了商品集Y，其直观的意义就是用户在购买某些商品的时候有多大倾向去购买另外一些商品。比如购买牛奶的同时很多人会同时购买面包。 优点 能发现新兴趣点 不需要别的领域知识 一般转化率较高 实现简单，通用性强，适合推荐和跟“已购买商品搭配的商品” 缺点 产品名同义性问题 个性化程度低 规则抽取难，耗时。计算量较大，但是可以离线计算，因此影响不大。 由于采用用户数据，不可避免的存在冷启动和稀疏性问题。 存在热门项目容易被过度推荐的问题。 辛普森悖论 2.2.5 基于效用的推荐（Utility-based Recommendation）描述 是建立在对用户使用项目的效用情况上计算的，其核心问题是怎么样为每一个用户去创建一个效用函数，因此，用户资料模型很大 程度上是由系统所采用的效用函数决定的。基于效用推荐的好处是它能把非产品的属性，如提供商的可靠性（Vendor Reliability）和产品的可得性（Product Availability）等考虑到效用计算中。 优点 无冷启动和稀释性问题 对用户偏好变化敏感 能考虑非产品特性 缺点 用户必须输入效用函数 推荐是静态的，灵活性差 属性重叠问题 2.2.6 基于知识的推荐（Knowledge-based Recommendation）描述 在某种程度是可以看成是一种推理（Inference）技术，它不是建立在用户需要和偏好基础上推荐的。基于知识的方法因 它们所用的功能知识不同而有明显区别。效用知识（Functional Knowledge）是一种关于一个项目如何满足某一特定用户的知识，因此能解释需要和推荐的关系，所以用户资料可以是任何能支持推理的知识结构，它可以 是用户已经规范化的查询，也可以是一个更详细的用户需要的表示。 优点 能把用户需求映射到产品上 能考虑非产品属性 缺点 知识难获得 推荐是静态的 算法一览","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://galaxias-sapphi-ren.github.io/tags/Machine-Learning/"}]},{"title":"Machine Learning | 扬帆起航神经网络与深度学习","date":"2017-02-21T01:00:00.000Z","path":"2017/02/NeuralNetworks/","text":"睡眼惺忪，阳光入帘，起床深呼吸，要不然，开始有智能的机器就要淘汰你了。 前言 智能是根据环境变化而做出相应变化的能力，从信息论的观点看就是减熵的能力。而人工智能（Artificial Intelligence）的研究目标是使机器像人一样智能，主要应用于自然语言处理、知识表现、推理、规划、感知、模式识别等。 机器学习（Machine Learning）是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。 深度学习（Deep Learning）是深层的机器学习（Deep ML）。其“深层”（Deep）的真正含义是通过“抽象概念”学习，将多层表达的特征提取器和识别器合在一起，算法加“深”。 神经网络（Neural Networks）属于ML的一种。而深层神经网络（Deep NN）也只是深层学习的一种。 本文分别从自然学习与机器学习的概念类比、python最简代码（核心算法）学习、为什么要进行深度学习、谷歌开放机器学习框架tensorflow神经网络官方playground实例，四个方面概述人工智能、机器学习、深度学习的内容和结构，并层层递进的阐释感知器、神经网络、循环神经网络、卷积神经网络等的概念与常用算法。 本文试图在脱离线性代数、统计学相关公式的情况下，从不同角度聚焦在人工智能领域的神经网络和深度学习相关内容。并且最终给出一般性算法选择路径。 2017年02月21日 - rensifei @Copyright Smart Home &amp; Roobo 导读吴军在《数学之美》中有一段描述，引做导读。 有不少专业术语乍一听很唬人，“人工神经网络”就属于这一类，至少我第一次听到这个词就被唬住了。你想啊，在大家的印象当中，人们对人脑的结构都还根本没有搞清楚，这就冒出来一个“人工的”神经网络，似乎是在用计算机来模拟人脑。想到人脑的结构那么复杂，大家的第一反应一定是人工神经网络肯定非常高深。如果我们有幸遇到一个好心同时又善于表达的科学家或教授，他愿意花一两个小时的时间，深入浅出地把人工神经网络的底细告诉你，你便会发现，“哦，原来是这么回事”。如果我们不幸遇到一个爱卖弄的人，他会很郑重地告诉你“我在使用人工神经网络”或者“我研究的课题是人工神经网络”，然后就没有下文了，如此，你除了对他肃然起敬外，不由得可能还会感到自卑。当然还有好心却不善于表达的人试图将这个概念给你讲清楚，但是他用了一些更难懂的名词，讲得云山雾罩，最后你发现听他讲了好几个小时，结果是更加糊涂了，你除了浪费时间外一无所获，于是你得出一个结论：反正我这辈子不需要搞懂它了。 大家可别以为我是在说笑话，这些都是我的亲身经历。首先，我没有遇到过一两小时给我讲懂的好心人，其次我遇到了一批在我前面卖弄的人，作为年轻人，总是希望把自己不明白的东西搞懂，于是我决定去旁听一门课。不过，我听了大约两三次便不再去了，因为除了浪费时间，似乎我并没得到什么收获。好在我自己做研究暂时用不到它，也就不再关心了。后来在美国读博士期间，我喜欢在睡觉前躺着看书，没事儿就捧着几本关于人工神经网络的教科书在床上看，居然也看懂了。然后再用它做了两三个项目，算是学会了。到这时回过头来再看“人工神经网络”，其实并不复杂，入门也不难，只是我走了弯路。 第一章：自然到机器的学习本章对比自然学习和机器学习的相关概念，尝试类比机器学习的内容，并强化对机器学习中神经网络的理解。机器学习地铁图、算法决策图等概述机器学习概念。 知识比对表如下： 自然名词 机器名词 作用 智能 人工智能 熵减，根据环境变化而做出相应变化，学习和预测 生物学习 机器学习 寻求从过去状态到未来状态的关联的过程 神经元 感知机 输入特征（向量），输出描述状态，用线性变换跟随着非线性变化，将输入空间投向另一个空间，是输出的决策单元 抽象层级 层 增加容纳变体的能力、鲁棒性 神经元的网状结构 神经网络（分类器） 学习和预测过去到未来的关联 1.1 从智能开始 1.1.2 智能 从信息论的观点看自然智能，从宇宙大爆炸开始，世界的状态向越不确定的状态转变，所蕴涵的信息越来越多。生命要在这个变化的世界中生存，它就需要知道如何根据环境变化做出相应的行动来避免毁灭。把不确定的环境转换成确定的行动。会将无序的事物重新整理到有序的状态。生物仅仅活着就需要减熵，否则就会被不确定性会消灭。 其中： 智能是可以根据环境变化而做出相应变化的能力(熵减的能力)，通过智能，智能体学习和预测信息，减少信息状态的不确定性。 熵是用来衡量我们对事物在跨时间后能产生不同状态的混乱度。越确定(deterministic)的事件的熵越低，越随机(probabilistic)的事件的熵越高。 自然的智能存储于遗传物质中，通过螺旋结构合成蛋白质，根据化学信号和电信号执行功能。生物通过繁殖和变异学习自然智能。 1.1.2 人工智能（Artificial Intelligence） 随着信息量的增加，智能无法解决大信息量的问题，人类开始尝试使机器产生智能，人工智能是指由人工制造出来的系统所表现出来的智能。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基于仿生学、认知心理学，以及基于概率论和经济学的算法等等也在逐步探索当中。而机器学习是解决人工智能的主要途径，主要用于解决决策所需要的数据量超过我们有限大脑的处理能力的问题。 人工智能是多科学的交叉，但又不被任何一个学科完全包含。 从智能的定义直接扩展的话，人工智能是非自然选择形成的一种减熵的能力。 1.2 什么是学习 1.2.1 生物学习 人可以通过经验学习，比方说“朝霞不出门，晚霞行千里”，就是通过经验得来的知识。所以学习的对象是‘经验’，准确说是先验知识，广义说是数据。 随着信息增加，不确定性增高。学习是从信息中找回物理关系，回卷信息，降低不确定性的过程。被找回的物理关系叫做知识。 1.2.2 机器学习 机器学习主要是研究如何使计算机从给定的数据中学习规律，即从观测数据(样本)中寻找规律，并利用学习到的规律(模型)对未知或无法观测的数据进行预测。目前，主流的机器学习算法是基于统计的方法，也叫统计机器学习。 简单来讲，只要表现出智能的程序（将无序数据转换为有用知识），且程序的参数是从数据中进行学习，就是机器学习。 1.2.2.1 概念维基百科 机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。 机器学习（1998 Tom Mitchell）对于一个程序，给它一个任务T和一个性能测量方法P，如果在经验E的影响下，P对T的测量结果得到了改进，那么就说该程序从E中学习。 1.2.2.2 学习阶段 LEARNING = REPRESENTATION + EVALUATION + OPTIMIZATION REPRESENTATION（表现）：表示信息的状态（假设空间）及特征（分类器） EVALUATION（评价）：区分正确的信息状态和好的特征（评价函数或目标函数） OPTIMIZATION（优化）：迭代快速的学习（算法优化） 1.2.2.3 数学解释学习一个映射函数f : x → y，将输入变量x映射为输出变量y。一般我们可以假设映射函数为y = f(x, θ)。其中θ 即为函数的参数。参数可以通过学习算法进行学习。 我们还要建立一些准则来衡量决策函数的好坏。在很多机器学习算法中， 一般是定义一个损失函数 L(y, f(x, a))然后在所有的训练样本上来评价决策函数的风险。 用对参数求经验风险来逐渐逼近理想的期望风险的最小值，就是我们常说的经验风险最小化原则(Empirical Risk Minimization)。这样，我们的目标就是变成了找到一个参数a使得经验风险最小。 1.2.2.2 结构 1.2.2.3 学习地铁图 1.2.2.3 分类及算法机器学习分类包括： 监督性学习（Supervised Learning）， 概念：有监督学习是利用一组已知输入 x 和输出 y 的数据来学习模型的参数，使 ]得模型预测的输出标记和真实标记尽可能的一致。 用途：根据函数的输出是连续的值还是离散的值可以分为回归（Recregression）和分类（Classication）。目前最广泛被使用的分类器有人工神经网络、支持向量机、最近邻居法、高斯混合模型、朴素贝叶斯方法、决策树和径向基函数分类。 非监督学习（Unsupervised Learning） 概念：无监督学习是用来学习的数据不包 含输出目标，需要学习算法自动学习到一些有价值的信息。 用途：主要用于数据聚类（Clustering），在人工神经网络中，自我组织映射（SOM）和适应性共振理论（ART）则是最常用的非监督式学习。 强化学习（Reinforcement Learning） 概念：强化学习强调如何基于环境做出一系列的动作，以取得最大化的累积收益。每做出一个动作，并不一定立刻得到收益。增强学习和有监督 学习的不同在于增强学习不需要显式地以输入/输出对的方式给出训练样本，是一种在线的学习机制。 用途：主要应用于机器人决策中的回报函数和连续决策。 迁移学习（Transfer Learning）。 概念：把已学训练好的模型参数迁移到新的模型来帮助新模型训练数据集。 机器学习常用算法有： 算法一览 机器学习中算法决策图解 算法索引 正则化算法（Regularization Algorithms） 概念：它是另一种方法（通常是回归方法）的拓展，这种方法会基于模型复杂性对其进行惩罚，它喜欢相对简单能够更好的泛化的模型。 案例：岭回归（Ridge Regression）、最小绝对收缩与选择算子（LASSO）、GLASSO、弹性网络（Elastic Net）、最小角回归（Least-Angle Regression） 优点：其惩罚会减少过拟合，总会有解决方法 缺点：惩罚会造成欠拟合，很难校准 集成算法（Ensemble Algorithms） 概念：集成方法是由多个较弱的模型集成模型组，其中的模型可以单独进行训练，并且它们的预测能以某种方式结合起来去做出一个总体预测。 案例：Boosting、Bootstrapped Aggregation（Bagging）、AdaBoost、层叠泛化（Stacked Generalization）（blending）、梯度推进机（Gradient Boosting Machines，GBM）、梯度提升回归树（Gradient Boosted Regression Trees，GBRT）、随机森林（Random Forest） 优点：当先最先进的预测几乎都使用了算法集成。它比使用单个模型预测出来的结果要精确的多 缺点：需要大量的维护工作 决策树算法（Decision Tree Algorithm） 概念：决策树学习使用一个决策树作为一个预测模型，它将对一个 item（表征在分支上）观察所得映射成关于该 item 的目标值的结论（表征在叶子中）。树模型中的目标是可变的，可以采一组有限值，被称为分类树；在这些树结构中，叶子表示类标签，分支表示表征这些类标签的连接的特征。 案例：分类和回归树（Classification and Regression Tree，CART）、Iterative Dichotomiser 3（ID3）、C4.5 和 C5.0（一种强大方法的两个不同版本） 优点：计算量简单，可解释性强，比较适合处理有缺失属性值的样本，能够处理不相关的特征 缺点：容易过拟合（后续出现了随机森林，减小了过拟合现象），可能或陷于局部最小值中，没有在线学习，单颗决策树分类能力弱，并且对连续值变量难以处理。 回归（Regression） 概念：回归是用于估计两种变量之间关系的统计过程。当用于分析因变量和一个 多个自变量之间的关系时，该算法能提供很多建模和分析多个变量的技巧。具体一点说，回归分析可以帮助我们理解当任意一个自变量变化，另一个自变量不变时，因变量变化的典型值。最常见的是，回归分析能在给定自变量的条件下估计出因变量的条件期望。 案例：普通最小二乘回归（Ordinary Least Squares Regression，OLSR）、线性回归（Linear Regression）、逻辑回归（Logistic Regression）、逐步回归（Stepwise Regression）、多元自适应回归样条（Multivariate Adaptive Regression Splines，MARS）、本地散点平滑估计（Locally Estimated Scatterplot Smoothing，LOESS） 优点：直接、快速，知名度高 缺点：要求严格的假设，需要处理异常值 人工神经网络（Artificial Neural Network） 概念：人工神经网络是受生物神经网络启发而构建的算法模型。它是一种模式匹配，常被用于回归和分类问题，但拥有庞大的子域，由数百种算法和各类问题的变体组成。 案例：感知器、反向传播、Hopfield 网络、径向基函数网络（Radial Basis Function Network，RBFN） 优点：在语音、语义、视觉、各类游戏（如围棋）的任务中表现极好。算法可以快速调整，适应新的问题。 缺点：需要大量数据进行训练。训练要求很高的硬件配置。模型处于「黑箱状态」，难以理解内部机制。元参数（Metaparameter）与网络拓扑选择困难。 深度学习（Deep Learning） 概念：深度学习是人工神经网络的最新分支，它受益于当代硬件的快速发展。众多研究者目前的方向主要集中于构建更大、更复杂的神经网络，目前有许多方法正在聚焦半监督学习问题，其中用于训练的大数据集只包含很少的标记。 案例：深玻耳兹曼机（Deep Boltzmann Machine，DBM）、Deep Belief Networks（DBN）、卷积神经网络（CNN）、Stacked Auto-Encoders 优缺点：同神经网络 支持向量机（Support Vector Machine） 概念：给定一组训练事例，其中每个事例都属于两个类别中的一个，支持向量机（SVM）训练算法可以在被输入新的事例后将其分类到两个类别中的一个，使自身成为非概率二进制线性分类器。SVM 模型将训练事例表示为空间中的点，它们被映射到一幅图中，由一条明确的、尽可能宽的间隔分开以区分两个类别。随后，新的示例会被映射到同一空间中，并基于它们落在间隔的哪一侧来预测它属于的类别。 优点：在非线性可分问题上表现优秀。 缺点：非常难以训练。很难解释。 降维算法（Dimensionality Reduction Algorithms） 概念：和集簇方法类似，降维追求并利用数据的内在结构，目的在于使用较少的信息总结或描述数据。这一算法可用于可视化高维数据或简化接下来可用于监督学习中的数据。许多这样的方法可针对分类和回归的使用进行调整。 案例：主成分分析（Principal Component Analysis (PCA)）、主成分回归（Principal Component Regression (PCR)）、偏最小二乘回归（Partial Least Squares Regression (PLSR)）、Sammon 映射（Sammon Mapping）、多维尺度变换（Multidimensional Scaling (MDS)）、投影寻踪（Projection Pursuit）、线性判别分析（Linear Discriminant Analysis (LDA)）、混合判别分析（Mixture Discriminant Analysis (MDA)）、二次判别分析（Quadratic Discriminant Analysis (QDA)）、灵活判别分析（Flexible Discriminant Analysis (FDA)） 优点：可处理大规模数据集。无需在数据上进行假设。 缺点： 难以搞定非线性数据。难以理解结果的意义。 聚类算法（Clustering Algorithms） 概念：聚类算法是指对一组目标进行分类，属于同一组（亦即一个类，cluster）的目标被划分在一组中，与其他组目标相比，同一组目标更加彼此相似（在某种意义上）。 案例：K-均值（k-Means）、k-Medians 算法、Expectation Maximi 封层 ation (EM)、最大期望算法（EM）、分层集群（Hierarchical Clstering） 优点：让数据变得有意义 缺点：结果难以解读，针对不寻常的数据组，结果可能无用。 基于实例的算法（Instance-based Algorithms） 概念：基于实例的算法（有时也称为基于记忆的学习）是这样学习算法，不是明确归纳，而是将新的问题例子与训练过程中见过的例子进行对比，这些见过的例子就在存储器中。之所以叫基于实例的算法是因为它直接从训练实例中建构出假设。这意味这，假设的复杂度能随着数据的增长而变化：最糟的情况是，假设是一个训练项目列表，分类一个单独新实例计算复杂度为 O（n） 案例：K 最近邻（k-Nearest Neighbor (kNN)）、学习向量量化（Learning Vector Quantization (LVQ)）、自组织映射（Self-Organizing Map (SOM)）、局部加权学习（Locally Weighted Learning (LWL)） 优点：算法简单、结果易于解读 缺点：内存使用非常高。计算成本高。不可能用于高维特征空间。 贝叶斯算法（Bayesian Algorithms） 概念：贝叶斯方法是指明确应用了贝叶斯定理来解决如分类和回归等问题的方法。 案例：朴素贝叶斯（Naive Bayes）、高斯朴素贝叶斯（Gaussian Naive Bayes）、多项式朴素贝叶斯（Multinomial Naive Bayes）、平均一致依赖估计器（Averaged One-Dependence Estimators (AODE)）、贝叶斯信念网络（Bayesian Belief Network (BBN)）、贝叶斯网络（Bayesian Network (BN)） 优点：快速、易于训练、给出了它们所需的资源能带来良好的表现 缺点：如果输入变量是相关的，则会出现问题 关联规则学习算法（Association Rule Learning Algorithms）0008– 概念：关联规则学习方法能够提取出对数据中的变量之间的关系的最佳解释。比如说一家超市的销售数据中存在规则 {洋葱，土豆}=&gt; {汉堡}，那说明当一位客户同时购买了洋葱和土豆的时候，他很有可能还会购买汉堡肉。 案例：Apriori 算法（Apriori algorithm）、Eclat 算法（Eclat algorithm）、FP-growth 图模型（Graphical Models） 概念：图模型或概率图模型（PGM/probabilistic graphical model）是一种概率模型，一个图（graph）可以通过其表示随机变量之间的条件依赖结构（conditional dependence structure）。 案例：贝叶斯网络（Bayesian network）、马尔可夫随机域（Markov random field）、链图（Chain Graphs）、祖先图（Ancestral graph） 优点：模型清晰，能被直观地理解 缺点：确定其依赖的拓扑很困难，有时候也很模糊 常用算法边界预测对比 1.2.3 定理 1.2.3.1 没有免费午餐定理没有免费午餐定理(No Free Lunch Theorem，NFL) 是由Wolpert和Macerday在最优化理论中提出的。没有免费午餐定理证明：对于基于迭代的最优化算法，不存在某种算法对所有问题（有限的搜索空间内）都有效。如果一个算法对某些问题有效，那么它一定在另外一些问题上比纯随机搜索算法更差。也就是说，不能脱离具体问题来谈论算法的优劣，任何算法都有局限性。必须要“具体问题具体分析”。没有免费午餐定理对于机器学习算法也同样适用。不存在一种机器学习算法适合于任何领域或任务。如果有人宣称自己的模型在所有问题上都好于其他模型，那么他肯定是在吹牛。 1.2.3.2 丑小鸭定理丑小鸭定理（Ugly Duckling）1960年代，美籍日本学者渡边慧提出了丑的鼻祖之一。 小鸭定理：“丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大”。这个定理初看好像不符合常识，但是仔细思考后是非常有道理的。因为世界上不存在相似性的客观标准，一切相似性的标准都是主观的。如果以体型大小的角度来看，丑小鸭和白天鹅的区别大于两只白天鹅的区别；但是如果以基因的角度来看，丑小鸭与它父母的差别要小于他父母和其他白天鹅之间的差别。 1.2.4 学习网站 清晰的查询出相关算法的知识拓扑图。 metacademy.org 1.3 神经元与感知机神经元是构成神经网络的基础单元，先归纳一下神经元模型。 1.3.1 神经元 神经元通过电信号和化学信号传递兴奋或者抑制。 其行为可以解释为： 其中：x是输入电信号（向量），y是输出电信号（output），x，y的个数是突触的个数（维度），W是各个神经元连接强弱，a()是化学传递（激活函数，非线性能力）。大量神经元就可学习过去到未来的关联。 1.3.2 MP模型 总结神经元特点 每个神经元都是一个多输入单输出的信息处理单元 神经元输入分兴奋性输入和抑制性输入两种类型 神经元具有空间整合特性和阈值特性 神经元输入与输出间有固定的时滞，主要取决于突触延搁 心理学家Mcculloch和数理逻辑学家Pitts合作提出的M-P模型。相比于神经元，MP模型忽略时间整合作用、不应期等复杂因素，并把神经元的突触时延和强度当成常数。 其中，激活函数（activation function）加入非线性因素的，因为线性模型的表达能力不够。例如，在实现分类器功能时，参数与权重的点积是线性的，在做分类运算时只能在数据轴上画一条直线，而在让该点积经过激活函数 y = f(a) 处理后，加入了非线性因素，使直线变成曲线，这时分类器的表达能力更好。 1.3.2.1 激活函数如果没有激活函数，网络仅能够表达线性映射，即便有再多的隐藏层，整个网络跟单层神经网络也是等价的。因此也可以认为，只有加入了激活函数之后，深度神经网络才具备了分层的非线性映射的学习能力。 常用的神经元非线性激发函数有阈值型、分段线性型、Sigmoid函数型（简称S型）和双曲正切型 其中sigmoid函数曲线错误，详细神经网络激活函数见1.3.4. 1.3.3 感知机（Perceptron） 1.3.3.1 概念感知机（perceptron）是二分类的线性分类模型，属于监督学习算法。输入为实例的特征向量，输出为实例的类别。感知机是神经网络和支持向量机的基础。 1957年美国学者Rosenblatt提出了一类具有自学习能力的感知器模型，它是一个具有单层计算单元的前向神经网络，其神经元为线性阈值单元，称为单层感知器。也就是说: 神经元之间的连接权值wi是可变的，这种可变性就保证了感知器具有学习能力。1959 年Rosenblatt提出了感知器模型中连接权值参数的学习算法。算法的思想是首先把连接权值和阈值初始化为较小的非零随机数，然后把有n个连接权值的输入送入网络，经加权运算处理，得到的输出如果与所期望的输出有较大的差别，就对连接权值参数按照某种算法进行自动调整，经过多次反复，直到所得到的输出与所期望的输出间的差别满足要求为止。 1.3.3.2 分类已知存在感知机 f(x) = sign ( w * x + b )w是权重weight，b是偏置bias，sign是符号函数 f(x)= +1 if x &gt;= 0 −1 else目标：找到一个最佳的满足 w * x + b = 0 的 w 和 b 值，即分离超平面（separating hyperplane）将样本分为正样本和负样本。 问题转换为优化问题：最小化损失函数 误分类点(x0, y0)到超平面 w * x + b = 0 的距离为 ( w * x0 + b ) / ( w^2 + 1 )^1/2 # 把( w^2 + 1 )^1/2 定义为 1/||w||，||w||为L2范式，满足高斯分布且有 −y0 * ( w * x0 + b) &gt; 0 # 若(x0, y0)为正样本，y0为正，误分类后 w * x0 + b 为负，−y0 * ( w * x0 + b) 为正 # 若(x0, y0)为负样本，y0为负，误分类后 w * x0 + b 为正，−y0 * ( w * x0 + b) 为正所有点到超平面的总距离为 −1/||w|| * ∑ yi * | w * x0 + b |定义损失函数 L(x, b) = −∑ yi * ( w * x0 + b )则 (1) 初始化w0,b0，权值可以初始化为0或一个很小的随机数 (2) 在训练数据集中选取（x_i, y_i） (3) 如果 yi * (w * xi + b) ≤ 0 # η为学习率（0&lt;η&lt;1） w = w + η * y_i * x_i b = b + η * y_i (4) 转至（2）,直至训练集中没有误分类点其中，损失函数详见1.3.5。 1.3.4 激活函数 性质 可微性： 当优化方法是基于梯度的时候，这个性质是必须的。 单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数。 输出值的范围： 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate。 流行激活函数对比 Sigmoid函数：曾经是最常用的激活函数, 但现在一般只用在输出层, 中间层很少使用。 缺点1: 两头平坦。梯度小, 在后向传播 (BP) 中, 逐层梯度乘以整个网络最终输出的梯度之后, 达到输入层时, 导致反传回去的梯度被消减掉，最终导致没有梯度信号更新权重。权值的改动小, 学习速度慢。 缺点2：输出值域不对称，不是以零为中心的。[0,1], 只有正数, 没有负数。在梯度下降过程中的动力学角度来讲，这会导致一个潜在问题：如果数据流经神经元的时数据总是正的，那么在反向传播时，权重的梯度也将全部变为正的，或者全部变为负的，对于权重的梯度更新来说，导致一个不好的锯齿状梯度。 tanh函数：曾经是最常用的激活函数, 中间层较少使用, 但比Sigmoid效果好。 优点: 输出值域对称。[-1,1] 缺点: 两头依旧过于平坦 ReLU (Rectified Linear Unit) 优点1：不存在饱和(saturate)区域 优点2：收敛速度比sigmoid/tannh函数快 优点3：计算高效简单，没有引入计算复杂高的操作 缺点1：Dead Area: ReLU 函数单元在训练过程中比较脆弱，神经元死亡, 输出为0, 权重不更新 Leaky ReLU 优点：解决 ReLU 死亡问题，没有 Dead Area. Parametric ReLU：负数部分的斜率是从数据当中学习得到的，而不是预先定义的。 Randomized ReLU：负值部分的斜率值在给定范围内是随机选取的，而在测试时，参数值会被确定下来。 Maxout：maxout 是 ReLU 或 Leaky ReLU 的更一般形式 优点：非线性但不具有饱和性，不会死掉 缺点：训练的参数是原本的两倍 1.3.5 损失函数 损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。 前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的ΦΦ是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是L1，也可以是L2，或者其他的正则函数。整个式子表示的意思是找到使目标函数最小时的θθ值。 log对数损失函数（逻辑回归） 有逻辑回归的损失函数不是平方损失。平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到，逻辑回归假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数，接着取对数求极值等等。逻辑回归没有求似然函数的极值，而把极大化当做是一种思想，进而推导出它的经验风险函数为：最小化负的似然函数（即max F(y, f(x)) —-&gt; min -F(y, f(x)))。从损失函数的视角来看，它就成了log损失函数了。 利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说什么样的参数才能使我们观测到目前这组数据的概率最大 平方损失函数（最小二乘法, Ordinary Least Squares ） 最小二乘法是线性回归的一种，OLS将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（中心极限定理）。最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。换言之，OLS是基于距离的，而这个距离就是我们用的最多的欧几里得距离。 指数损失函数（Adaboost） 学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。 Hinge损失函数（SVM） 0-1损失函数 绝对值损失函数 分类问题的损失函数，从信息论的角度看，等价于训练出来的模型（分布）与真实模型（分布）之间的交叉熵（两者相差一个只和样本数据量有关的倍数N），而这个交叉熵的大小，衡量了训练模型与真实模型之间的差距，交叉熵越小，两者越接近，从而说明模型越准确。 1.4 抽象层级与层把相同结构的神经单元组合在一起，构成神经网络的层: 输入层 输入向量 中间层 (隐含层) 输出层 输出向量, 用于预测, 分类以及回归 抽象层级越高，层越多。 2012年多伦多大学的Krizhevsky等人构造了一个超大型卷积神经网络，有9层，共65万个神经元，6千万个参数。网络的输入是图片，输出是1000个类，比如小虫、美洲豹、救生船等等。这个模型的训练需要海量图片，它的分类准确率也完爆先前所有分类器。纽约大学的Zeiler和Fergusi把这个网络中某些神经元挑出来，把在其上响应特别大的那些输入图像放在一起，看它们有什么共同点。他们发现中间层的神经元响应了某些十分抽象的特征。 第一层神经元主要负责识别颜色和简单纹理 第二层的一些神经元可以识别更加细化的纹理，比如布纹、刻度、叶纹。 第三层的一些神经元负责感受黑夜里的黄色烛光、鸡蛋黄、高光。 第四层的一些神经元负责识别萌狗的脸、七星瓢虫和一堆圆形物体的存在。 第五层的一些神经元可以识别出花、圆形屋顶、键盘、鸟、黑眼圈动物。 1.4.1 层的基本变换 通过表达式：y⃗ =a(W⋅x⃗ +b)得知，x的输入空间转换为y的输出空间，其中W进行升维降维、放大缩小、旋转。b进行平移，a对空间进行弯曲。 1.5 神经网络 ANN 1.5.1 理解神经网络是最具代表性的机器学习的算法，同时也是深度学习的基础。 这是最常见的多层前馈神经网络（multi-layer feedforward neural networks）。不难看出，神经网络的学习其实就是调整各神经元之间的连接权（connection weight）以及各神经元的阈值。 由图可知，我们可以拖通过 增加节点数 : 增加维度，即增加线性转换能力。 增加层数 : 增加激活函数的次数，即增加非线性转换次数。 将原始输入空间投向线性可分/稀疏的空间去分类/回归。 1.5.2 概念 维基百科：‘神经网络’（Neural Network）是一种模仿生物神经网络的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应系统。现代神经网络是一种非线性统计性数据建模工具。典型的神经网络具有以下三个部分: 结构 （Architecture) 激励函数（Activity Rule) 学习规则（Learning Rule） 人工神经网络模型主要考虑网络连接的拓扑结构、神经元的特征、学习规则等。目前，已有近 40 种神经网络模型。 前馈神经网络:也经常称为多层感知器(Multilayer Perceptron， MLP)。 反馈神经网络:网络内神经元间有反馈，可以用一个无向的完备图表示。这种神经网络的信息处理是状态的变换，可以用动力学系统理论处理。 神经网络 - demo 1.5.3 误差逆传播算法（BackPropagation BP） 感知机的学习过程在线性不可分时会发生振荡（fluctuation），难以稳定。对于多层感知器中的隐层，因为无法直接得到其输出值，不能直接使用损失。这时，就需要将损失从顶层反向传播（Back Propagate）到隐层，来完成参数估计的目标。BP是迄今最成功的神经网络学习算法，现实任务中使用神经网络大多是使用BP。一般而言，BP神经网络是指用BP算法训练的多层前馈神经网络，但BP算法也能训练其他类型的神经网络，如递归神经网络。 步骤 先将输入实例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果 计算输出层误差，计算输出层神经元梯度项，再将误差逆向传播至隐层神经元 最后根据隐层神经元的误差对连接权和阈值进行调整 该迭代过程循环进行，直到达到某些同志条件为止。例如训练误差已经达到一个很小的值。 思考多层感知器存在的最大的问题就是，它是一个全连接的网络，因此在输入比较大的时候，权值会特别多。比如一个有1000个节点的隐层，连接到一个1000×1000的图像上，那么就需要 10^9 个权值参数（外加1000个偏置参数）！这个问题，一方面限制了每层能够容纳的最大神经元数目，另一方面也限制了多层感知器的层数即深度。多层感知器的另一个问题是梯度发散。一般情况下，我们需要把输入归一化，而每个神经元的输出在激活函数的作用下也是归一化的；另外，有效的参数其绝对值也一般是小于1的；这样，在BP过程中，多个小于1的数连乘，得到的会是更小的值。也就是说，在深度增加的情况下，从后传播到前边的残差会越来越小，甚至对更新权值起不到帮助，从而失去训练效果，使得前边层的参数趋于随机化（补充一下，其实随机参数也是能一定程度上捕捉到图像边缘的）。 1.5.4 其他神经网络 RBF（Radial Basis Function）网络 单隐层前馈神经网络，它使用径向基函数作为隐层神经元的激活函数。输出层则直接使用隐层神经元的线性组合。 ART（Adaptive Resonance Theory，自适应谐振理论）网络 竞争型学习的重要代表。该网络由四部份组成：比较层、识别层、识别阈值、重置模块。比较层就是输入层，只负责把样本传递给识别层。识别层也即输出层，但识别层的每个神经元对应一个模式类，而且神经元的数目可以在训练过程中动态增加以增加新的模式类。ART能有效缓解竞争型学习中的可塑性-稳定性窘境（stability-plasticity dilemma），ART具备可塑性和稳定性，因此能进行增量学习（incremental learning）和在线学习（online learning）。 SOM（Self-Organizing Map，自组织映射）网络 又称为自组织特征映射网络或Kohonen网络。同样是一种竞争学习型无监督神经网络，只有输入层和输出层两层，输出层以矩阵形式排列。与样本距离最近的输出层神经元获胜，称为最佳匹配单元（best matching unit）。最佳匹配单元和邻近神经元的权向量会被调整，使得下次遇到相似的样本时距离更小。如此迭代，直至收敛。 级联相关（Cascade-Correlation）网络 典型的结构自适应网络，这类网络不仅通过训练来学习合适的连接权和阈值等参数，还会在训练过程中找到最符合数据特点的网络结构。 递归神经网络（recurrent neural networks，简称RNN） 允许网络中出现环形结构，即一些神经元的输出可以反馈回来当输入信号，从而能够处理与时间有关的动态变化。Elman网络是最常用的递归神经网络之一，只有一个隐层，并且隐层神经元的输出会被反馈，在下一时刻与输入层神经元的输入信号一起作为隐层神经元的新输入。隐层神经元一般采用Sigmoid函数作为激活函数，并用BP算法训练整个网络。 第二章：python实现最简神经网络用python实现，BP反向传播算法，单层神经网络，双重神经网络。 X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ]) y = np.array([[0,1,1,0]]).T syn0 = 2*np.random.random((3,4)) - 1 syn1 = 2*np.random.random((4,1)) - 1 for j in xrange(60000): l1 = 1/(1+np.exp(-(np.dot(X,syn0)))) l2 = 1/(1+np.exp(-(np.dot(l1,syn1)))) l2_delta = (y - l2)*(l2*(1-l2)) l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1)) syn1 += l1.T.dot(l2_delta) syn0 += X.T.dot(l1_delta)2.1 一个简洁的神经网络给定三列输入，试着去预测对应的一列输出。我们可以通过简单测量输入与输出值的数据来解决这一问题。这样一来，我们可以发现最左边的一列输入值和输出值是完美匹配/完全相关的。直观意义上来讲，反向传播算法便是通过这种方式来衡量数据间统计关系进而得到模型的。 input oytput 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 2.2 两层神经网络import numpy as np # sigmoid function 非线性映射 def nonlin(x,deriv=False): # 用输出值便可以得到其导数值 if(deriv==True): return x*(1-x) return 1/(1+np.exp(-x)) # input dataset X = np.array([ [0,0,1], [0,1,1], [1,0,1], [1,1,1] ]) # output dataset y = np.array([[0,0,1,1]]).T # “.T” 为转置函数 # seed random numbers to make calculation # deterministic (just a good practice) np.random.seed(1) # initialize weights randomly with mean 0 syn0 = 2*np.random.random((3,1)) - 1 # 神经网络权重矩阵的初始化操作 for iter in xrange(10000): # 训练 # forward propagation l0 = X l1 = nonlin(np.dot(l0,syn0)) # 前向预测阶段 # how much did we miss? 误差 l1_error = y - l1 # multiply how much we missed by the # slope of the sigmoid at the values in l1 l1_delta = l1_error * nonlin(l1,True) # update weights syn0 += np.dot(l0.T,l1_delta) print &quot;Output After Training:&quot; print l1 结果为 Output After Training: [[ 0.00966449] [ 0.00786506] [ 0.99358898] [ 0.99211957]]变量说明 变量 定义说明 X 输入数据集，形式为矩阵，每 1 行代表 1 个训练样本。 y 输出数据集，形式为矩阵，每 1 行代表 1 个训练样本。 l0 网络第 1 层，即网络输入层。 l1 网络第 2 层，常称作隐藏层。 syn0 第一层权值，突触 0 ，连接 l0 层与 l1 层。 2.3 复杂神经网络给定前两列输入，尝试去预测输出列】，这两列与输出不存在任何关联，可以视为一种“非线性”模式，单个输入与输出间不存在一个一对一的关系。而输入的组合与输出间存在着一对一的关系，在这里也就是列 1 和列 2 的组合。我们需要额外增加一个网络层。第一层对输入进行组合，然后以第一层的输出作为输入，通过第二层的映射得到最终的输出结果。 input | | | Hidden Weight | | | | output—|—|—|—|—|—|—|—|—0 | 0 | 1 | 0.1 | 0.2 | 0.5 | 0.2 | 00 | 1 | 1 | 0.2 | 0.6 | 0.7 | 0.1 | 11 | 0 | 1 | 0.3 | 0.2 | 0.3 | 0.9 | 11 | 1 | 1 | 0.2 | 0.1 | 0.3 | 0.8 | 0 import numpy as np def nonlin(x,deriv=False): if(deriv==True): return x*(1-x) return 1/(1+np.exp(-x)) X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]]) y = np.array([[0], [1], [1], [0]]) np.random.seed(1) # randomly initialize our weights with mean 0 syn0 = 2*np.random.random((3,4)) - 1 syn1 = 2*np.random.random((4,1)) - 1 for j in xrange(60000): # Feed forward through layers 0, 1, and 2 l0 = X l1 = nonlin(np.dot(l0,syn0)) l2 = nonlin(np.dot(l1,syn1)) # how much did we miss the target value? l2_error = y - l2 if (j% 10000) == 0: print &quot;Error:&quot; + str(np.mean(np.abs(l2_error))) # in what direction is the target value? # were we really sure? if so, don&#39;t change too much. l2_delta = l2_error*nonlin(l2,deriv=True) # how much did each l1 value contribute to the l2 error (according to the weights)? l1_error = l2_delta.dot(syn1.T) # 置信度加权”，构建 l1 层相应的误差 # in what direction is the target l1? # were we really sure? if so, don&#39;t change too much. l1_delta = l1_error * nonlin(l1,deriv=True) syn1 += l1.T.dot(l2_delta) syn0 += l0.T.dot(l1_delta)变量说明 变量 定义说明 X 输入数据集，形式为矩阵，每 1 行代表 1 个训练样本。 y 输出数据集，形式为矩阵，每 1 行代表 1 个训练样本。 l0 网络第 1 层，即网络输入层。 l1 网络第 2 层，常称作隐藏层。 l2 假定为网络最后一层，随着训练进行，其输出应该逐渐接近正确结果 syn0 第一层权值，突触 0 ，连接 l0 层与 l1 层。 syn1 第二层权值，突触 1 ，连接 l1 层与 l2 层。 l2_error 该值说明了神经网络预测时“丢失”的数目。 l2_delta 该值为经确信度加权后的神经网络的误差，除了确信误差很小时，它近似等于预测误差。 l1_error 该值为 l2_delta 经 syn1 加权后的结果，从而能够计算得到中间层/隐层的误差。 l1_delta 该值为经确信度加权后的神经网络 l1 层的误差，除了确信误差很小时，它近似等于 l1_error 。 第三章：深度学习3.1 理解 深度网络（DNN）: 学习的是函数 卷积神经网络（CNN）: 学习的是特征 循环神经网络（RNN）: 学习的是程序 神经网络使用并行的先验知识使得模型可用线性回归，数据样本学习要求大。而深度学习比浅层神经网络更高效，因为迭代组成的先验知识使得样本可用于帮助训练其他共用同样底层结构的样本。 多层神经网络的限制 面对大数据时，需要人为提取原始数据的特征作为输入，这个问题前面的知友提到过@杨延生。必须忽略不相关的变量，同时保留有用的信息。这个尺度很难掌握，多层神经网络会把蹲在屋顶的Kitty和骑在猫奴头上的Kitty识别为不同的猫咪，又会把二哈和狼归类为同一种动物。前者是对不相关变量过于敏感，后者则因无法提取有实际意义的特征。 想要更精确的近似复杂的函数，必须增加隐藏层的层数，这就产生了梯度扩散问题。所谓“强弩之末势不能穿鲁缟“。 无法处理时间序列数据（比如音频），因为多层神经网络不含时间参数。随着人工智能需求的提升，我们想要做复杂的图像识别，做自然语言处理，做语义分析翻译，等等。多层神经网络显然力不从心。 那么深度模型是如何解决以上三个问题的。 深度学习自动选择原始数据的特征。举一个图像的例子，将像素值矩阵输入深度网络，网络第一层表征物体的位置、边缘、亮度等初级视觉信息。第二层将边缘整合表征物体的轮廓……之后的层会表征更加抽象的信息，如猫或狗这样的抽象概念。所有特征完全在网络中自动呈现，并非出自人工设计。更重要的一点是这种随着层的深入，从具象到抽象的层级式表征跟大脑的工作原理吻合，视网膜接收图像从LGN到视皮层、颞叶皮层再到海马走的是同样的路数！ 深度网络的学习算法。一种方法是改变网络的组织结构，比如用卷积神经网络代替全连接（full connectivity）网络，训练算法仍依据Backpropagating gradients的基本原理。另一种则是彻底改变训练算法，我尝试过的算法有Hessian-free optimization[3]，recursive least-squares(RLS)等。 使用带反馈和时间参数的Recurrent neural network处理时间序列数据。从某种意义上讲，Recurrent neural network可以在时间维度上展开成深度网络，可以有效处理音频信息，或者用来模拟动力系统。 深度学习是一种参数多，模型复杂度高，容量大的模型。，通过多个隐层，将低层特征转换为高层特征，用于完成更复杂的学习任务。 3.2 概念多层神经网络与universal approximation theorem（泛逼近性原理）相伴而生。该理论指出，单隐藏层（hidden layer）非线性前馈神经网络，可以在实数空间近似任何连续函数 “深度学习”是为了让层数较多的多层神经网络可以训练，能够work而演化出来的一系列的新的结构和新的方法。新的网络结构中最著名的就是CNN，它解决了传统较深的网络参数太多，很难训练的问题，使用了“局部感受野”和“权植共享”的概念，大大减少了网络参数的数量。关键是这种结构确实很符合视觉类任务在人脑上的工作原理。新的结构还包括了：LSTM，ResNet等。新的方法就多了：新的激活函数：ReLU，新的权重初始化方法（逐层初始化，XAVIER等），新的损失函数，新的防止过拟合方法（Dropout, BN等）。这些方面主要都是为了解决传统的多层神经网络的一些不足：梯度消失，过拟合等。 3.3 训练方式 无监督逐层训练（unsupervised layer-wise training）：每次训练一层隐结点，把上一层隐结点的输出当作输入来训练，本层隐结点训练好后，输出再作为下一层的输入来训练，这称为预训练（pre-training）。全部预训练完成后，再对整个网络进行微调（fine-tuning）训练。一个典型例子就是深度信念网络（deep belief network，简称DBN）。这种做法其实可以视为把大量的参数进行分组，先找出每组较好的设置，再基于这些局部最优的结果来训练全局最优。 权共享（weight sharing）：令同一层神经元使用完全相同的连接权，典型的例子是卷积神经网络（Convolutional Neural Network，简称CNN）。这样做可以大大减少需要训练的参数数目。 3.4 递归神经网络递归神经网络（RNN）是两种人工神经网络的总称。一种是时间递归神经网络（recurrent neural network），另一种是结构递归神经网络（recursive neural network）。主要处理序列数据（诸如文本、语言）。 一般而言，RNN指时间递归神经网络（recurrent neural network），也叫循环递归网络。 RNN不仅仅能够处理序列输出, 也能得到序列输出, 这里序列指的是向量的序列 RNN学习出来的是程序, 不是函数 每个正方形代表一个向量，箭头代表函数（比如矩阵乘法）。输入向量是红色，输出向量是蓝色，绿色向量装的是RNN的状态。上图从左至右依次为： 非RNN的普通过程，从固定尺寸的输入到固定尺寸的输出（比如图像分类）。 输出是序列（例如图像标注：输入是一张图像，输出是单词的序列）。 输入是序列（例如情绪分析：输入是一个句子，输出是对句子属于正面还是负面情绪的分类）。 输入输出都是序列（比如机器翻译：RNN输入一个英文句子输出一个法文句子）。 同步的输入输出序列（比如视频分类中，我们将对视频的每一帧都打标签） 3.4.1 记忆抽象 若RNN是一个类，存在API只包含一个step方法：则step方法接收输入向量x，返回输出向量y。然而这个输出向量的内容不仅被输入数据影响，而且会收到整个历史输入的影响。 rnn = RNN() y = rnn.step(x) # x is an input vector, y is the RNN&#39;s output vector每当step方法被调用的时候，RNN的内部状态就被更新。在最简单情况下，该内部装着仅包含一个内部隐向量h。下面是一个普通RNN的step方法的实现： class RNN: # ... def step(self, x): # update the hidden state self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x)) # compute the output vector y = np.dot(self.W_hy, self.h) return y以上代码说明了普通RNN的前向传播。 更深层网络。 y1 = rnn1.step(x) y = rnn2.step(y1)3.5 卷积神经网络卷积神经网络 cnn - example 卷积神经网络(Convolutional Neural Network, CNN)是深度学习技术中极具代表的网络结构之一，主要处理图像处理，避免对图像复杂的前期预处理过程（提取人工特征等），可以直接输入原始图像。 由来：神经元网络的直接升级版 相关：Yann LeCun和他的LeNet 影响：在图像、语音领域不断突破，复兴了神经元网络并进入“深度学习”时代 卷积神经网络沿用了普通的神经元网络即多层感知器的结构，是一个前馈网络。应用于图像领域。 3.5.1 网络结构 输入图像I。为了减小复杂度，一般使用灰度图像。当然，也可以使用RGB彩色图像，此时输入图像有三张，分别为RGB分量。输入图像一般需要归一化，如果使用sigmoid激活函数，则归一化到[0, 1]，如果使用tanh激活函数，则归一化到[-1, 1]。 多个卷积（C）-下采样（S）层。将上一层的输出与本层权重W做卷积得到各个C层，然后下采样得到各个S层。怎么做以及为什么，下面会具体分析。这些层的输出称为Feature Map。 光栅化（X）。是为了与传统的多层感知器全连接。即将上一层的所有Feature Map的每个像素依次展开，排成一列。 传统的多层感知器（N&amp;O）。最后的分类器一般使用Softmax，如果是二分类，当然也可以使用LR。 常用架构模式为： INPUT -&gt; [[CONV] * N -&gt; POOL?] * M -&gt; [FC] * K也就是N个卷积层叠加，然后(可选)叠加一个Pooling层，重复这个结构M次，最后叠加K个全连接层。 对于图 网络结构为： INPUT -&gt; CONV -&gt; POOL -&gt; CONV -&gt; POOL -&gt; FC -&gt; FC 3.5.1 API及出发点 将输入3D体积转换为具有一些可能具有参数的可微函数的输出3D体积。 局部感受野。 形象地说，就是模仿你的眼睛，想想看，你在看东西的时候，目光是聚焦在一个相对很小的局部的吧？严格一些说，普通的多层感知器中，隐层节点会全连接到一个图像的每个像素点上，而在卷积神经网络中，每个隐层节点只连接到图像某个足够小局部的像素点上，从而大大减少需要训练的权值参数。举个栗子，依旧是1000×1000的图像，使用10×10的感受野，那么每个神经元只需要100个权值参数；不幸的是，由于需要将输入图像扫描一遍，共需要991×991个神经元！参数数目减少了一个数量级，不过还是太多。 权值共享 形象地说，就如同你的某个神经中枢中的神经细胞，它们的结构、功能是相同的，甚至是可以互相替代的。也就是，在卷积神经网中，同一个卷积核内，所有的神经元的权值是相同的，从而大大减少需要训练的参数。继续上一个栗子，虽然需要991×991个神经元，但是它们的权值是共享的呀，所以还是只需要100个权值参数，以及1个偏置参数。从MLP的 10^9 到这里的100，就是这么狠！作为补充，在CNN中的每个隐藏，一般会有多个卷积核。 池化 形象地说，你先随便看向远方，然后闭上眼睛，你仍然记得看到了些什么，但是你能完全回忆起你刚刚看到的每一个细节吗？同样，在卷积神经网络中，没有必要一定就要对原图像做处理，而是可以使用某种“压缩”方法，这就是池化，也就是每次将原图像卷积后，都通过一个下采样的过程，来减小图像的规模。以最大池化（Max Pooling）为例，1000×1000的图像经过10×10的卷积核卷积后，得到的是991×991的特征图，然后使用2×2的池化规模，即每4个点组成的小方块中，取最大的一个作为输出，最终得到的是496×496大小的特征图。 3.5.2 局部连接与权值共享 局部连接 1000 × 1000的输入图像，若下一个隐藏层的神经元数目为10^6个 全连接：1000 × 1000 × 10^6 = 10^12个权值参数 局部连接：隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8 权值共享 在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数。但是，这样仅提取了图像的一种特征，如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像的不同映射下的特征，称之为Feature Map。如果有100个卷积核，最终的权值参数也仅为100 × 100 = 10^4个而已。 3.5.3 卷积 卷积层的作用是提取图像的各种特征 卷积核尺寸: DHW, 卷积核的深度和输入图像是一致的 卷积滑动参数: stride/padding 每个卷积核带有一个bias require(&#39;nn&#39;) img = torch.rand(3,5,5) #输入x: 深度为3, 高和宽均为5 conv = nn.SpatialConvolution(3,2,3,3,2,2,1,1) #参数分别表示输入深度(3),卷积核个数(2),卷积核的尺寸(3*3), h方向的stride(2),w方向的stride(2), h方向的padding大小(1),w方向的padding大小(1)(padding:补0或补重复数) img_out=conv:forward(img) #Forward计算 假设有一个5 5的图像，使用一个3 3的filter进行卷积，想得到一个3 * 3的Feature Map 3.5.4 池化（Pooling） 池化层的作用是对原始特征信号进行抽象，从而大幅度减少训练参数，另外还可以减轻模型过拟合的程度。 改变图像尺寸的操作, 可以逐层的把图像尺寸一点点降下来, 减少维度 max pool / average pool 3.6 Long Short Term 网络（LSTM）几乎所有的令人振奋的关于 RNN 的结果都是通过 LSTM 达到的。LSTM 由 Hochreiter &amp; Schmidhuber (1997) 提出，并在近期被 Alex Graves 进行了改良和推广。 LSTM 可以学习长期依赖信息，避免长期依赖问题。LSTM 的关键就是细胞状态，水平线在图上方贯穿运行。细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传保持不变会很容易。 其中，每一条黑线传输着一整个向量，从一个节点的输出到其他节点的输入。粉色的圈代表 pointwise 的操作，诸如向量的和，而黄色的矩阵就是学习到的神经网络层。合在一起的线表示向量的连接，分开的线表示内容被复制，然后分发到不同的位置。 3.6.1 逐步理解 案例：基于已经看到的词预测下一个词。细胞状态可能包含当前‘主语’的类别，因此正确的‘代词’可以被选择出来。 第一步：确定是否更新。通过’忘记门层’完成。该门会读取h(t-1)和xt，输出一个在 0 到 1 之间的数值给每个在细胞状态C(t-1)中的数字。1 表示“完全保留”，0 表示“完全舍弃”。当我们看到新的‘代词’，我们希望忘记旧的‘代词’。 第二步：确定更新信息。首先，sigmoid层称 “输入门层”决定什么值我们将要更新。其次，tanh层创建一个新的候选值向量，会被加入到状态中。我们希望增加新的代词的类别到细胞状态中，来替代旧的需要忘记的代词。 第三步：更新细胞状态。更新旧细胞状态，把旧状态与ft相乘，丢弃掉我们确定需要丢弃的信息。接着加上新的候选值，根据每个状态的程度进行变化。丢弃旧代词的类别信息并添加新的信息的地方。 第四步：输出信息。首先，运行sigmoid层来确定细胞状态的哪个部分将输出出去。接着，把细胞状态通过tanh进行处理（得到一个在 -1 到 1 之间的值）并将它和sigmoid门的输出相乘，输出确定输出的那部分。代词需要输出与一个动词相关的信息。例如，可能输出是否代词是单数还是负数，这样如果是动词的话，我们也知道动词需要进行的词形变化。 第四章：playground实例谷歌 打开网页后，总体来说，蓝色代表正值，黄色代表负值。拿分类任务来分析。 数据 在二维平面内，若干点被标记成了两种颜色。黄色，蓝色，表示想要区分的两类。你可以把平面内的任意点标记成任意颜色。网页给你提供了4种规律。神经网络会根据你给的数据训练，再分类相同规律的点。 输入 在二维平面内，你想给网络多少关于“点”的信息。从颜色就可以看出来，x1左边是负，右边是正，x1表示此点的横坐标值。同理，x2表示此点的纵坐标值。x1~2是关于横坐标值的“抛物线”信息。你也可以给更多关于这个点的信息。给的越多，越容易被分开。 连接线 表示权重，蓝色表示用神经元的原始输出，黄色表示用负输出。深浅表示权重的绝对值大小。鼠标放在线上可以看到具体值。也可以更改。 输出 黄色背景颜色都被归为黄点类，蓝色背景颜色都被归为蓝点类。深浅表示可能性的强弱。 第五章：如何选择合适的算法第一步：问题分类 根据输入数据分类 如果我们的数据有标签，这就是一个监督学习问题 如果数据没有标签而且我们想找出数据的内在结构，那这就是无监督学习 如果我们想通过与环境交互来优化目标函数，这是强化学习 根据输出结果分类 如果模型输出结果是一个数值，这是回归问题 如果输出结果是一个类别，这是分类问题 如果输出结果是一组输入数据，那这是聚类问题 分类（classification）：当使用数据来预测类别时，监督学习也被叫做分类。比如将含有「猫」或「狗」的图片识别出来，分类为「猫」或「狗」，这就是二分类问题（two-class or binomial classification）。当存在更多类别时（例如预测下一届诺贝尔物理学家的获得者是谁），这就是所谓的多分类问题（multi-class classification）。 回归（regression）：当要预测数值时（比如预测股价），监督学习也被称为回归。 聚类（clustering）：聚类或聚类分析（cluster analysis）是无监督学习中最常见的方法之一。聚类是将一组对象以某种方式分组，使得同一组中的数据比不同组的数据有更多的相似性。 异常检测（Anomaly detection）：有时我们需要找出数据点中的异常点。例如，在欺诈检测中，任何极不寻常的信用卡消费都是可疑的；欺诈具有大量不同的形式，而训练样本又非常少，使得我们不可能完全了解欺诈活动应该是什么样。异常检测所采取的方法就是了解正常情况下的表现行为（使用非欺诈交易的历史数据），并识别出显著不同的表现行为。 第二步：寻找算法 分类： 支持向量机（SVM）可用于找到尽可能宽的分类的边界。当两个分类不能被清楚地分开时，该算法会找到其所能找到的最佳边界。其真正的亮点在于处理特征密集的数据，比如文本或者基因组（特征数量&gt; 100）。在这些情况下，除了仅需要适量的记忆外，支持向量机（SVM）能够比其它大多数算法更快且更少过拟合地进行分类。 人工神经网络是涵盖二分类、多分类和回归问题的脑启发式学习算法。它们有无限的种类，包括感知器和深度学习。它们需要很长时间来训练，但已知其在多种应用领域都实现了当前最佳的表现。 logistic 回归：即便名字中有着「回归」，但 logistic 回归实际上是一种可用于二分类和多分类问题的强大工具。它快速且简单。事实上，它使用「S」形曲线而非直线，所以它自然适合用于数据分组。logistic 回归可以给出线性分类边界，所以如果你要使用它，你一定要确保你能接受线性的近似。 决策树和随机森林：决策森林（decision forests）（回归、二分类、多分类），决策丛林（decision jungles）（二分类和多分类）和提升决策树（boosted decision trees）（回归和二分类）都基于决策树。这是一个基本的机器学习概念。决策树有许多不同的变体，但它们都在做同样的事情—将特征空间（feature space）细分为具有大致相同标签的区域。这些区域可以是一致的类别或者恒定值，具体取决于你进行的是分类还是回归。 回归： 线性回归是将一条线（或平面、或超平面）拟合到一个数据集上。这是一种主要的工具，简单且快速，但对于一些问题而言，它可能过于简单。 贝叶斯线性回归有着非常理想的特性：它可以避免过拟合。贝叶斯方法通过事先对答案的可能分布做出一些假设来做到这一点。这种方法的另一个副产品是它们具有非常少的参数。 提升决策树回归（Boosted decision tree regression）：如上所述，提升决策树（回归和二分类）均基于决策树，并通过将特征空间细分为具有大致相同标签的区域发挥效用。提升决策树通过限制其可以细分的次数以及每个区域中所允许的最少数据点来避免过拟合。该算法会构造一个树的序列，其中每棵树都会学习弥补之前的树留下来的误差。这能得到一个会使用大量的内存的非常精确的学习器。 聚类： 层次聚类（Hierarchical Clustering）的目标是构建聚类的层次结构，它有两种形式。聚集聚类（agglomerative clustering）是一种「自下而上」的方法，其中每个观察（observation）在其自己的聚类中开始，随着其在层次中向上移动，成对的聚类会进行融合。分裂聚类（divisive clustering）则是一种「自上而下」的方法，其中所有的观察都从一个聚类开始，并且会随观察向下的层次移动而递归式地分裂。整体而言，这里的融合和分裂是以一种激进的方式确定的。层次聚类的结果通常表示成树状图（dendrogram）的形式。 k-均值聚类（k-means clustering）的目标是将 n 组观测值分为 k 个聚类，其中每个观测值都属于其接近的那个均值的聚类——这些均值被用作这些聚类的原型。这会将数据空间分割成 Voronoi 单元。 异常检测： k 最近邻（k-nearest neighbors / k-NN）是用于分类和回归的非参数方法。在这两种情况下，输入都是由特征空间中与 k 最接近的训练样本组成的。在 k-NN 分类中，输出是一个类成员。对象通过其 k 最近邻的多数投票来分类，其中对象被分配给 k 最近邻中最常见的类（k 为一正整数，通常较小）。在 k-NN 回归中，输出为对象的属性值。该值为其 k 最近邻值的平均值。 单类支持向量机（One-class SVM）：使用了非线性支持向量机的一个巧妙的扩展，单类支持向量机可以描绘一个严格概述整个数据集的边界。远在边界之外的任何新数据点都是非正常的，值得注意。 第三步：实现算法问题通常存在多种候选算法，选择算法应反复试验。 原型开发最好分两步完成。 最小特征工程快速实现。该阶段，主要目标是大概了解哪个算法表现得更好。将列表减少至几个候选算法。 建立机器学习流程，使用一组经过仔细选择的评估标准来比较每个算法在数据集上的表现。该阶段，只处理小部分算法，把注意力放在：特征工程。 如下是深度学习的实现步骤： 数据扩增 水平翻转 随机剪裁 颜色抖动 预处理 去均值与规范化 主成分分析白化（数据先经过去均值，然后计算出（能刻画数据内部相关结果的）协方差矩阵） 参数初始化 全零初始化：若初始权值相同，神经元就不具有非对称性（asymmetry）。 小随机数初始化：在网络的回传过程中，小值权重会减弱“梯度信号” 方差校准：确保了网络中神经元在最初时有着大致相同的输出分布，以及收敛速度的提升。 np.random.randn(n) * sqrt(2.0/n) # 推荐，方差为2.0/n 训练 滤波器与池化 学习率 参数微调 正则化 L2正则化：惩罚目标函数中所有参数的平方。对权重向量的加强惩罚(heavily penalizing peaky weight vectors)和对权重向量的发散(diffuse weight vectors)。 L1正则化：将权重向量中的每个权重参数累加后加入目标函数中。带有L1正则化的神经元最终会将输入的数据中的重要输入元素得到保留，其余会变成或接近00。 最大模限制(max norm constraints)：让每个神经元的权重向量有一个绝对上限(upper bound)的约束，使用投影梯度下降(projected gradient descent)来执行这个约束。 Dropout：对整个神经网络进行抽样，并基于输入数据仅仅更新抽样网络的参数。 第四步：特征工程特征工程却更像是一门艺术。 主要问题在于我们试图分类的数据在特征空间的描述极少。利如，用像素的灰度值来预测图片通常是不佳的选择；相反，我们需要找到能提高信噪比的数据变换。如果没有这些数据转换，我们的任务可能无法解决。利如，在方向梯度直方图（HOG）出现之前，复杂的视觉任务（像行人检测或面部检测）都是很难做到的。 常见的选取数据特征的方法：（大多数特征的有效性需靠实验评估） 主成分分析（PCA）：一种线性降维方法，可以找出包含信息量较高的特征主成分，可以解释数据中的大多数方差。 尺度不变特征变换（SIFT）：计算机视觉领域中的一种有专利的算法，用以检测和描述图片的局部特征。它有一个开源的替代方法 ORB（Oriented FAST and rotated BRIEF）。 加速稳健特征（SURF）：SIFT 的更稳健版本，有专利。方向梯度直方图（HOG）：一种特征描述方法，在计算机视觉中用于计数一张图像中局部部分的梯度方向的 occurrence。 更多算法请参考 或者通过交叉验证误差最大的候选特征，前向或反向搜索获取期望数量的特征。 第五步：优化算法 5.1 调整超参 优化算法超参数。例如，主成分分析中的主成分个数，k 近邻算法的参数 k，或者是神经网络中的层数和学习速率。最好的方法是使用交叉验证来选择。 新数据与当初预训练模型的数据相似时， 若数据少就训练一个线性分类器，作为预训练模型的顶层特征抽取部分。 若数据时就使用一个较小的学习率，对预训练模型的多个顶层进行微调。 如果数据与当初训练模型的数据相差大，但数据多。那么网络的大多数层的参数都应该基于新的数据做微调，同时用一个较小的学习率以提升性能。 如果数据与当初训练模型的数据相差大，且数据少，那就很难。因为数据量的限制，还不如单独训练一个线性模型，因为数据就与原本训练深层模型的不同，如若从顶层开始用自己差异大的数据（预训练模型得到的参数体现的是原始数据的特征）来训练，不见得会有多么好，反倒不如训练一个支持向量机模型替换深层模型中的某些层。 5.2 优化方法 一阶梯度法 手动指定学习速率：SGD, Momentum, Nesterov Momentum 自动调节学习速率AdaGrad, RMSProp, Adam 二阶梯度法","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://galaxias-sapphi-ren.github.io/tags/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://galaxias-sapphi-ren.github.io/tags/Deep-Learning/"},{"name":"Neural Networks","slug":"Neural-Networks","permalink":"https://galaxias-sapphi-ren.github.io/tags/Neural-Networks/"}]},{"title":"Machine Learning | 今日头条又推荐美女图片了，扒扒它的技术架构吧","date":"2017-02-15T01:00:00.000Z","path":"2017/02/recsystechToutiao/","text":"信了推荐算法的邪，入了深度学习的坑。 2017年02月15日 - rensifei @Copyright Smart Home &amp; Roobo 今日头条推荐系统算法技术架构 - 机器学习预研 摘要 “今日头条”是一款基于数据挖掘技术的个性化推荐引擎产品，它为用户推荐有价值的、个性化的信息，提供连接人与信息的新型服务，是国内移动互联网领域成长最快的产品之一。“今日头条”于2012年8月上线，截至2016年9月底，“今日头条”累计激活用户数已达5.8亿，日活跃用户超过6300万。 “今日头条”没有采编人员，不生产内容，没有立场和价值观，运转核心是一套由代码搭建而成的算法。“今日头条”搭建的算法模型会记录用户在今日头条上的每一次行为，基于此计算出用户的喜好，推送他最有可能感兴趣的内容。 本文根据“今日头条”副总裁杨震原的历次演讲及“今日头条“官网http://www.toutiao.com/about/解构“今日头条”推荐系统算法和主要技术环节。 参考资料 2015年8月29日，“七牛·数据时代峰会”上海国际时尚中心杨震原演讲 《传媒评论》2015年10月刊，“今日头条”的技术逻辑：网络爬虫+矩阵筛选王成军（南京大学新闻传播学院助理研究员，奥美数据科学实验室主任，计算传播学中心研究） 2015年11月19日，CSDN年度技术盛宴 “SDCC 2015中国软件开发者嘉年华”在北京召开，杨震原发表题为《大数据的挑战，开发者如何应对》的演讲及采访。 2016年2月2日，数据挖掘系列篇（9）：今日头条的个性化推荐 2016年4月20日，今日头条核心算法负责人杨震原，MindStore分享 2016年8月8日，今日头条产品总监杨震原解密今日头条算法推荐原理 2017年2月16日，淘宝搜索/推荐系统背后深度强化学习与自适应在线学习的实践之路 第一章：推荐冷启动 cold start 1.1 概念个性化推荐是需要依赖用户的历史行为才能预测用户的兴趣，因此大量的用户行为数据是用户的重要组成部分和先决条件。那么对于在开始阶段就像要一个个性化推荐系统的网站或应用来说，如何在没有用户历史数据的情况下设计个性化推荐并且让用户对推荐结果满意从而使用推荐系统，就是冷启动问题。 1.2 解决方案当新用户加入时，一般需要给用户一个初始兴趣值。比较常见的做法，比如quora，zhihu，pinterest是让人手选感兴趣的话题。另外一个做法是给一些初始歌曲或者电影让人选喜欢或者不喜欢，然后生成一个初始值。无论哪一个做法，用户的行为数据都不足以产生高质量的推荐。而今日头条则选择了另一种解决方案——通过对用户微博账号的分析建立一个“兴趣图谱”。 1.3 技术路径 微博ID接入今日头条后，对兴趣作出分析，建立初始的DNA数据。 抽取一部分用户，让用户可以自主选择新闻tag分类进行订阅，对比自动推荐的人均阅读篇数和留存情况，进行模型效果比较和优化 根据初始的兴趣模型从三个维度呈现内容。 第一个是“推荐”，即会从抓取到的每条信息（包括图片信息）中提取几十个到几百个高维特征，并进行降维、相似计算、聚类、分类等处理，然后根据用户的兴趣模型进行推荐的内容，每天会采用Visual-based抓取技术处理超过100万个网页, 以保证内容来源足够准确。 第二个是“热门”，即互联网和社交网站上出现最多的内容 第三个是好友动态中，可查看好友的评论、转发、收藏动作。 内容评论依照用户的社交关系、评论人的影响力等条件进行排序。 第二章：用户模型 懂算法的人让UGC内容提供者、原创者受益。 5亿用户，月平均增长1000万。 2.1 用户特征阅读姓名，年龄，地域，职业，用户搜索关键词等 2.2 用户行为用户通过“顶”、“踩”、转发、收藏等操作，用户行为数据会实时性地被传送到后台，在用户每次操作后的30秒内，系统就会对用户模型进行更新。 第三章：数据挖掘 数据挖掘是今日头条最核心的技术，本章论述‘今日头条’如何进行推荐内容的挖掘。 3.1 数据网络爬虫今日头条服务器1000台左右，通过代码实现的爬虫功能，在其他传媒的网站和门户上抓取各种信息。如果在网站上抓取到纸媒的内容，优先从纸媒门户上抓取信息。如“网易新闻”、“新浪新闻”、“凤凰新闻”、“浙江新闻”等等。 3.2 分类算法归类抓取信息后，对有价值的信息通过算法进行分析归类。‘今日头条’的核心技术是实体词抽取。对抓取文章进行以下分类分析。 文章实体词抽取，‘词嵌入’方法，做向量化的分析 引入隐含狄利克雷分布简称LDA(Latent Dirichlet allocation)，将文档集中每篇文档的主题按照概率分布的形式给出，进行topic分析。 3.3 分类算法测试现象 定制新闻以泛热点新闻为基础数据来完成的事实，这就出现一个问题，即当一个人关注的新闻不是热点时，系统得不到相关的热点，就会在该新闻当中寻找其他信息进行再匹配，这样匹配出的新闻在现有信息的基础上最大程度吻合了用户的兴趣，但未必会推送当天最热点的新闻。要想达到这种长尾理论所设想的定制服务，关键是对新闻的细分。只有将不同主题细分成各种子主题，再细分下设内容，才能达到真正的私人定制。要做到这一点，实际已经脱离了机械，而在于人对于事物性质的认知与把握。正如法国社会学家福柯在《知识考古学》当中的观点，分类，是一事物区别于其他事物的根本。而分类，归根结底是人的主观能动性的体现；当系统中累计的用户行为越多，这种分类越准确，自动化的私人定制也会越贴近用户需求。 为了测试分类是否准确，今日头条进行以下测试。 3.3.1 A/B测试 A/B测试 是一种把实验对象随机分组，把一个或者多个测试组的表现与对照相比较，进行测试的方式。 唯一变量 随机分布 流量分桶 3.3.2 双盲交叉验证 双盲交叉验证 在评估一项数据时，随机抽取一部分数据进行多人分别评估 3.4 人工运营 原创与转载内容的内容消重 标题和图片消重 相似主题消重 文章审核（标题问题、正文正文问题、推广、广告） 第四章：推荐算法 本章论述‘今日头条’如何通过算法，一边提取内容的特征，一边提取用户兴趣的特征，然后让内容与用户的兴趣匹配。 4.1 基本流程 构建基于内容的推荐的矩阵获得不同候选集 候选集过滤，融合 精细排序 选出用户当前可能最感兴趣的文章进行推荐。 4.2 基于内容的推荐获取的文章内容，是否值得推荐有以下考量： 根据以上信息，‘今日头条’使用以下算法构建算法矩阵： 相似文章主题相似性的推荐：通过获取与用户阅读过文章的相似文章来进行推荐。 基于相同城市的新闻：对于拥有相同地理信息的用户，会推荐与之相匹配的城市的热门文章。 基于文章关键词的推荐：对于每篇文章，提取关键词，作为描述文章内容的一种特征。然后与用户动作历史的文章关键词进行匹配推荐。 基于站内热门文章的普适性推荐：根据站内用户阅读习惯，找出热门文章，对所有没有阅读过该文章的用户进行推荐。 基于社交好友关系的阅读习惯推荐：根据用户的站外好友，获取站外好友转发评论或发表过的文章进行推荐。 基于用户长期兴趣关键词的推荐：通过比较用户短期和长期的阅读兴趣主题和关键词进行推荐。 基于相似用户阅读习惯的列表推荐：计算一定时期内的用户动作相似性，进行阅读内容的交叉性推荐。 基于站点分布来源的内容推荐：通过用户阅读的文章来源分布为用户计算出20个用户喜欢的新闻来源进行推荐。 根据基于内容的以上推荐矩阵获得候选集。 4.2 过滤，融合将以上推荐进行融合、过滤 过滤的目的是为了支持人工介入，比如，要过滤掉： 运营指定不能推的新闻 包含某关键字的新闻 融合 加权型：根据经验对不同的子方案赋予不同的权重，权重越高取的条数越多（按比例） 分级型：优先采用效果好的算法，当产生的候选集大小不足以满足目标值时，再使用效果次好的算法，依次类推（效果好坏的评价可以根据该子方案最终产生的推荐的点击率来算） 4.3 协同过滤基于物品的协同过滤算法（item-based collaborative filtering, ItemCF） 利用某兴趣相投、拥有共同经验之群体的喜好来推荐用户感兴趣的信息，个人通过合作的机制给予信息相当程度的回应（如评分）并记录下来以达到过滤的目的进而帮助别人筛选信息，回应不一定局限于特别感兴趣的，特别不感兴趣信息的纪录也相当重要。 一般是在海量的用户中发掘出一小部分和你品位比较类似的，在协同过滤中，这些用户成为邻居，然后根据他们喜欢的其他东西组织成一个排序的目录作为推荐给你。 今日头条中协同过滤算法是最重要的基于内容推荐的算法。 4.3.1 特征抽取 根据第二、三章论述，从用户、文章具有特征，‘今日头条’也同样参考环境特征。 用户特征分析：阅读姓名，年龄，地域，职业等 文章特征分析：名人，文章发布的时间，文章所属的地区，计算文章的分类、文章的关键词等 环境特征分析：早上看科技新，晚上看搞笑视频。网络环境，要有wifi的话，多推视频。 4.3.2 投票（LR逻辑回归） 算法为：最高分 = W1 候选1的投票率 + W2 候选2的投票率 + W3 * 候选3的投票率 + … 4.5 问题案例 第一讲系统工程和细节的交叉点，我们先说背景，今日内容推荐很重要的一部分就是针对一个你可能感兴趣的候选集进行惊喜的排序，这部分的一个核心就是进行了建模，把永辉的各种组合偏好记录下来。比如说uid—keyword就表达了某个用户的特点。我这里先不讨论各种模型的利弊，我们再往下来看如何解决特征爆炸的问题。机器学习的领域来讲，通常这样的问题解决的思路有很多种，比如说通过sample数据，比如说可以L1正则，稀疏化特征，第三特征过滤，第四hashtrick，第516bit的压缩。这里的方法特别多，我们再白讲一下特征的过滤怎么样来做，这个问题就变得非常明确的问题，我们有3T的uniqkey，我们现在的任务非常的明确我们需要去统计并过滤掉频次在8次以下的Key。采用方案是： 一个hash的结构，一个key要占用40bytes，40bytes会有指针的消耗和对企的问题。开地址的hash，我们是用开地址的hash，而不是冲突了之后放下一个，再冲突了再放下一个，我们最大的填充率按50％记，但key16bit，单机30g内存，冲突率和bloomcounter接近。大家可以想象，就是说这里需要注意一下，就是说sign5bit的数据和其他的不同，我去查一个东西的时候，就是一个表的指，之后我用第二个函数来算出去如果说找到冲突之后，以前是1，1就加到2，2就加到3，我们就用到一个hash用到非常小的一个结果而言，所以我们就要知道，这个hash的函数不同，所以它是一个有损的hash，这个有多大的好处呢？它是bloomcounter性能的6倍，因为它只需要一次访存，所以我们的性能就提升了6倍，这个事情就使得我们对模型训练的时间，提高到了原来的2倍，所以我们在万兆的网络连接上，20个小时都可以传完，是用到fiter的方法，我就希望用到很细节的方法来表达，这些都可以和工程相结合起来，找到结合点的时候就要把规矩和规模进行提升，这些提升所带来的效果是很大的。 理论的研究和实践的结合。对于一个LR model来讲，使用不同的学习率、不同正则项，收敛的效果是不同的。这当中是自带了效果，但是初始的学习率还是会带来很大的影响。除了weiglt的参数之外，我们还有学习率、L1等的超参数。手工调参是非常困难的问题。特征的类型我们是按照特定的规则来分有上百个，每个特征的类型都有正则率和特征的参数，这样我们就几百个参数，这个是没有办法调整的，所有这个事情是是不能够训练的，这是一个很痛苦的问题超参。解决方案是： 寻找过拟合和训练不足之间的最佳的平衡点，我训练是在一个训练集之中去做优化，我上线是在上线的集合之中来做，这两个数据集的分布是不同的，超参数就是去调这个东西，我训练不充分不好，我就是要做到在上线的情况下最优的超参数。我们把数据分为训练集验证集和测试集，我们在训练集之中去优化参数，我们可以做的事情是在验证集之中去优化超参数，目标是降低验证集的loss，这是更加的接近线上的分布，这是一个本质的方法我们可以找到最优点，同时这个方法是服务做好的。后面会稍微的说一下流程，大家可以看到，如此来在验证集上去优化参数，在ftrl下，超参是可以导的，这是最有意思的事情。这个l1正则项梯度，这个是可以求出来的，对l2的正则项也是可以求出来的，所以我们就有自动调参的流程，来算出更新，然后在验证集中去验证，就用到这些相应的方法，如何去把验证集去进行训练，这是有讲究的，如果验证集太近和太远都是不好的，这些都是细节的问题。也有新的问题，学习中的验证怎么样调？做这一块的人，最头痛的事情就是调参，但是我可以把几百个参数变成只有几个——参数可以调了，这个事情我们已经把它实现了并且在头条上全面的上线了，取得了什么效果呢？就是我们的离线评估UAC的面积，有2.2个绝对百分点的收益，在线的CTR有7.5个相对百分点的收益，这是非常重大的改进。 算法和产品、UI的结合。头条不仅仅有文章还有视频，视频的低质内容的控制是很重要的，我们有很多的办法去改进这个问题，有一些账号去评级，通过账号订阅的比例，效果都不好，之后我们用了一个办法，效果会大幅度的提升，说出来大家会觉得很简单，点赞。我们在视频播放的列表页放出了顶踩按钮，这样的使用就会大幅的提升，所以通过简单的加入顶踩的数据的统计，会对低质的打击效果明显提高。这就是一个很简单的，就是和产品结合，大家很多时候会举很多的例子，比如说以前肥皂盒的例子，技术的方案就是要解决问题你有简单的方法去解决问题这才是更有意义的创新。 第五章：分类任务总结 由第三章可以得知，‘今日头条’的分类算法的核心功能在于 数据挖掘，海量内容信息 关键词抽取技术，提取特征并测试 数据挖掘，搭建用户兴趣图谱，正负反馈 人工运营，消重、内容审核 而在任务‘今日头条’分类系统测试中，数据源由今日头条爬虫提供，无需经过步骤3，4。只需进行关键词抽取，提取特征。 本文没有从数据集Train和Test集的划分，过拟合，模型的选择，特征的抽取，正负样本的处理，采样方式（向上采样、向下采样），各种调参，特征的处理，y值处理，融合的方式等具体技术细节分析，只提供了‘今日头条’推荐系统的一般原理。","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://galaxias-sapphi-ren.github.io/tags/Machine-Learning/"}]},{"title":"我曾经跨过 npm 和 yeoman，也穿过人山人海","date":"2017-01-07T01:00:00.000Z","path":"2017/01/npmYeoman/","text":"npm 1 What is npm? 😚 1.1 share and reuse npm makes it easy for JavaScript developers to share and reuse code, and it makes it easy to update the code that you’re sharing. npm makes it easy for Javascript developers to share the code that they’ve created to solve particular problems, and for other developers to reuse that code in their own applications. 1.2 structure package or module files or not “package.json” : metadata 1.3 benefit bring in packages from people who have focused on particular problem areas reuse code across projects no wheels node package manager with registry 1.4 summary 👻 So that’s what npm is. It’s a way to reuse code from other developers, and also a way to share your code with them, and it makes it easy to manage the different versions of code. 1.5 install install Node.js and make sure node -v npm -vmaybe you’ll want to make sure it’s the latest version. npm install npm@latest -gor sometime Installing npm manually 1.6 permission fixed 👽 EER when install npm without sudo change the permission to npm’s default directory: npm config get prefix `// /Users/sapphire/.nvm/versions/node/v6.3.0` cd $(npm config get prefix)/ sudo chown -R $(whoami) $(npm config get prefix)/{lib/node_modules,bin,share} or change npm’s default dir ( lazy… 👉) 1.7 registry change npm registry if u have no vpn. 2 How to use npm? 😚 2.1 install packages mkdir and init npm : install and node it : npm install/uninstall &lt;package_name&gt; --save //update packege.json show package.json 🗣 Tips : add a repository during npm init， otherwise we can see two warnings from package.json file and Readme.md 2.2 package.json 2.2.1 requirements { &quot;name&quot;: &quot;my-awesome-package&quot;, //all lowercase,one word, no spaces &quot;version&quot;: &quot;1.0.0&quot; //follows semver spec } 2.2.2 quickly init npm init –yes name: defaults to author name unless in a git directory, in which case it will be the name of the repository version: always 1.0.0 main: always index.js scripts: by default creates a empty test script keywords: empty author: whatever you provided the CLI license: ISC repository: will pull in info from the current directory, if present bugs: will pull in info from the current directory, if present homepage: will pull in info from the current directory, if present 👉 set several config options for the init command npm set init.author.email &quot;578556078@qq.com&quot; npm set init.author.name &quot;sapphire&quot; npm set init.license &quot;MIT&quot;🗣 Tips : if there is no description field in the package.json, npm uses the first line of the README.md or README instead. 2.2.3 customize init see init-package-json-code, a node module to get node module started.i have practiced it at “/Users/sapphire/Projects/java/static/js/npm/day2”🗣 Tips : use the prompt function to customize the questions. module.exports = prompt(&quot;what&#39;s your favorite flavor of ice cream buddy?&quot;, &quot;I LIKE THEM ALL&quot;); 2.2.4 specifying packages dependencies //pro –save devDependencies //dev and test –save-div 2.3 update update the package u depend on so u can getany changes form code upstream npm outdated npm update 2.4 global install global or local npm ls npm ls -g npm ls -g --depth=0 2.5 publish You can publish any directory that has a package.json file npm publishthen GO here to find it. 2.6 version share with other and release at 1.0.0 3 How npm works? 😚 3.1 definitions of Packages and Modules Packages : readable with package.json a) a folder containing a program described by a package.json file b) a gzipped tarball containing (a) c) a url that resolves to (b) d) a @ that is published on the registry with (c) e) a @ that points to (d) f) a that has a latest tag satisfying (e) g) a git url that, when cloned, results in (a). Modules : requirable and runable A folder with a package.json file containing a main field. A folder with an index.js file in it. A JavaScript file.| dependency resolution 👍 npm can easily load both versions of the module in a way that they do not conflict with each other.👎 maven conflict between two versions dependency npm3 is differently than npm2, just know the command : npm dedupe //redirect module to the top level copy and removes all the nested copies. 4 What is Yeoman? 😚 4.1 kickstart scaffolding 🤓 Yeoman is a generic scaffolding system allowing the _creation of any kind of app_. It allows for rapidly getting started on new projects and streamlines the maintenance of existing projects. 4.2 forms language agnostic, generate projects in any language generators ecosystem to make decisions workflow with comprising tools and frameworks Here are some common use cases: Rapidly create a new project Create new sections of a project, like a new controller with unit tests Create modules or packages Bootstrapping new services Enforcing standards, best practices and style guides Promote new projects by letting users get started with a sample app 4.3 features 闪电般的初始化 项目开始阶段，可以基于现有的模板框架（例如：HTML5 Bolierplate、Twitter Bootstrap）进行项目初始化的快速构建。 了不起的构建流程 不仅仅包括JS、CSS代码的压缩、合并，还可以对图片和HTML文件进行优化，同时对CoffeScript和Compass的文件进行编译。 自动编译CoffeScript和Compass 通过LiveReload进程可以对源文件发生的改动自动编译，完成后刷新浏览器。 自动Lint代码 对于JS代码会自动进行JSLint测试，确保代码符合最佳编程实践。 内置的预览服务器 不再需要自己配置服务器了，使用内置的就可以快速预览。 惊人的图片优化 通过使用OptiPNG和JPEGTran来优化图片，减少下载损耗。 杀手级包管理 通过bower search jQuery，可以快速安装和更新相关的文件，不再需要打开浏览器自己搜索了。 PhantomJS单元测试 可以非常方便的使用PhantomJS进行单元测试，一切在项目初始的时候都准备好了。 4.4 tools the scaffolding tool (yo) the build tool (Gulp, Grunt etc) the package manager (like npm and Bower) 5 How to use Yeoman? 😚 prepare make sure ur evironment : Node.js、Ruby、Compass sudo gem update --system sudo gem install compass🗣 Tips : more Compass info. command curl -L get.yeoman.io | bash npm install -g yo grunt-cli bower npm install -g generator-webapp yo webapp yo webapp --help npm home generator-webapp yo angular:controller MyNewController yo doctor 5.1 Installing yo and some generators","tags":[{"name":"npm","slug":"npm","permalink":"https://galaxias-sapphi-ren.github.io/tags/npm/"},{"name":"Yeoman","slug":"Yeoman","permalink":"https://galaxias-sapphi-ren.github.io/tags/Yeoman/"}]},{"title":"学了 Markdown，丢了 Word","date":"2017-01-02T05:22:44.000Z","path":"2017/01/markdownGuide/","text":"Beautiful math in all browsers A JavaScript display engine for mathematics that works in all browsers.No more setup for readers. It just works. —— from mathjax 前言 markdown学习笔记，练练手 1 what’s markdown1.1 introduction 概念 Markdown 是一种 轻量级标记语言，创始人为John Gruber。他允许人们”使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML或HTML文档”。该语言吸收了很多 电子邮件 中已有的纯文本标记的特性。 1.2 importance 提高效率 改善体验 用途 方便需要输入大量文字，不喜欢使用鼠标快速写出文字排版的文档 比如：码农、博客写手、网站小编、出版业人士 2 grammar2.1 common tags\\ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号2.2 table Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 2.3 reference 怎样引导新手使用 Markdown Markdown 展示简书 Markdown语法 3 文章作者：袁晓辉 原文链接 为啥要学：酷炫风吸引的技术小白某次听讲座，看到前排的江浩博士拿出电脑记笔记，打开了一个一半是黑色，一般是白色的软件。在左边黑色的区域内打字，打字的过程中加几个简单的符号，所在行的文字立马变成了明快的彩色。更神奇的是，在右侧白色区域中呈现出大小标题十分清晰的结构化文字。当时心想，这也太酷炫了吧。 『啥时候我也要这么酷炫地记笔记！』 之后跟@果说的奇异果打听这是啥软件，他说，那就是之前给你推荐的Markdown语言啊。哦，Markdown，听起来好高端，是不是也像Python、C啥的，也是一种编程语言呢？一定也不太好学吧。 要学习新东西，总觉得需要克服重重困难并且付出巨大的努力才行，于是借口要准备答辩，时间不充裕，就没有马上学起。 今年1月6号，答辩完整理电脑里的文件，想起了记忆中那个图景。现在有时间了，没理由不学了，那就试试看吧。 于是在维基百科上了解了Markdown的理念和语法，装上了一个叫Mou编辑器。打开一看，对！要的就是这种酷炫的感觉！ 研究了一下才发现，Markdown的语法相当简单，一小会儿的功夫，常用的格式处理语法就都试了一遍。神奇的写作体验就此开始。之后的年终总结、演讲稿、生活随笔、论文思路都开始用Markdown来写了，真是爱不释手。 Markdown到底是个啥？Markdown是一种轻量级标记语言，创始人为John Gruber。它允许人们『使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML或HTML文档』 站在技术外行的角度简单理解，就是以最少的输入代价，呈现出结构化且富于表现力的文档。写着舒心，看着顺心。 我根据自己的体验总结了用该语言写作的几个好处： 结构写作：通过格式标记有助于理清思路 语法简单：简单的几个符号，试一次就可以记住 格式优雅：呈现出来的文字排版格式简洁好看 引用方便：插入超链接很方便，再也不担心找不到出处 写作专注：写作时关注内容即可，可开启过瘾的打字机声音 容易分享：可导出HTML和PDF文件，随处都可打开 与Txt和Word相比呢？大多数情况下，我们写东西要么用Word，要么用Txt记事本，跟Markdown相比，这两者的问题在哪呢？ Txt：没有格式，顺序写作，结构化不足，写出来所有格式都一样。 Word：有格式，但鼠标键盘点来点去容易为格式所累，无法专注于写作的内容本身。 而用Markdown来写东西，既有用Txt写作的简洁感，也有用Word刷格式后呈现的排版效果，而且是通过简洁的标记符号就产生了丰富的排版效果。这种感觉只有在上手用过一次以后才能了解奇妙之处。 我们常说，有什么样的思路，就会写出什么样的东西；但我后来发现，写作的呈现结果其实对写作思路的影响也很大： 如果写出的内容是清晰的结构化的，那么思路也会愈发清晰； 如果写出的内容是线性的非结构化的，那么思路很容易陷入某个细节中。 还记得思维导图吗？如果能够把脑海中的很多思绪用思维导图的方式梳理和串联起来，那么我们会发现思路在输出的过程中变清晰。 Markdown语法好记吗？它不是编程语言，很简单，一学就会，一用就灵。 常用的几个语法： 大标题小标题：几个#号几级标题。如一个井号是一级标题，四个井号是四级标题。 加粗和斜体：几对*号斜粗体。一对星号是斜体，两对星号是加粗。 引用别人的话：一个&gt;号变引用。即可呈现出灰色底色引用的效果。 引用链接：方括号里超链接。[需要引用的话][标识码]然后把标识码对应的链接附在文后：[标识码]：http://… 或者[需要引用的话]后面紧跟括号，括号里是对应的链接。 插入表格：|号表示分割线。表格从此想怎么画怎么画。 缩进黑点对齐：一个*号点缩进。呈现黑点引导的对齐效果。 缩进数字对齐：数字圆点数缩进。呈现数字引导的对齐效果。 插入高亮代码：三个`号插代码。插入一段高亮代码。 插入分隔线：三个*号分隔线。分隔线就是这么简单。 以上基本就是常用的语法了，可以在Markdown编辑器里试试看，半小时应该就能熟练掌握。 这些语法记不住咋办？记性不好如我者，时不时打开工具文档再看看呗，重复几次，肯定就没问题了。 用什么软件？Markdown是一种语言，要用Markdown语言写作，一般来说需要一个作为编辑器的软件。 如果上网方便想先试试的话，可以先不安装编辑器，直接试试 作业部落或简书的Web端，网址是Cmd Markdown 编辑阅读器，复制到浏览器中，打开即可上手来写了。 如果已经决定要长期使用，不妨在本地安装Markdown的编辑器， Mac系统推荐一个叫Mou的编辑器，亲测一个月，好使。Windows 系统推荐MarkdownPad或者MarkPad吧，没用过，但可以试试看。 如果决定全面Markdown，那么马克飞象这个软件推荐给印象笔记 的用户，可以直接写完以后同步到笔记中哦。 这些编辑器的首页应该都是详细的介绍和语法说明。心动不如行动啦。 用Markdown搞定微信公众号的排版如果你也有一个微信公众号，只要提前装好一个插件，那么用Markdown写作的文章可以直接粘在正文区，转换一下，即可呈现丰富的格式。从此告别公众号文章的low格式和模板格式时代。 用Markdown写作的作者们直接写好确认好格式，不用再经历小编们的一道修理，就可以以原汁原味的形态，优雅地呈现于读者面前了。小编们也可以从排版的痛苦中解放出来啦。 用Markdown来实现微信公众号的排版包括以下几步： 装chrome浏览器中安装Markdown here插件，需要翻墙； 把用Markdown写作的文章复制过来，粘在微信后台的文本框中； 按住Control+Alt+M，即可转换成最终呈现出来的文字格式； 可以进一步调整文字的颜色，插入图片等。 这样出来的文章，保准比之前看起来上了一个档次哦。 有了好用的工具，会不会爱上写作呢？要爱上写作，关键还是得写起来。 那么如何克服心理障碍开始写作呢？来自问自答几个问题。 想等到想得特别成熟才动笔开始写？放弃吧，不开始写作， 我们永远想不成熟的； 怕露怯，怕不完美？放弃吧，有谁是完美的呢？列一个出来？ 想到啥写啥不会太low吗？没有low，哪有high？大师都说了， 好文章是改出来的，我们首先也得有能改的东西啊。 千头万绪，没想清楚就写，会不会不太好？当脑海中信息太多 的时候，以写作的方式释放出来一些，让那些没有头绪的思想 呈现在纸上，我们才有可能理顺他们，才能给大脑留出足够的 空间关注最核心的问题吧。 好啦，开始带着Markdown的祝福，愉快地写起来吧。 跟我一样，你会爱上她的。","tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://galaxias-sapphi-ren.github.io/tags/Markdown/"},{"name":"Hexo","slug":"Hexo","permalink":"https://galaxias-sapphi-ren.github.io/tags/Hexo/"}]},{"title":"《流域》-- 幼年期个人诗词集","date":"2014-07-04T12:41:52.000Z","path":"2014/07/zone/","text":"青涩就是矫情。 前言 《流域》– 幼年期个人诗词集，日记节选。敢打敢拼，敢写敢浪！ 2014 遗迹备注：现在感觉还没盛极一世就断壁残垣啦。 我希望我所热爱的遗迹， 是我所认为美的归属， 是天空中摸不到的颜色， 是季节里慌张的落寂， 是岁月留给我最沉淀的薄漓。 我希望我以后遇到的一切： 苦难，艰险，慌乱，混沌，创伤，不知所措， 都在这悠扬的瓢泼的遗迹中， 变得超自然，最贴近，没有距离感。 三言备注：无言-。- 你选择了晨光，便在花瓣下被露水探望。 你选择了昏暗，便在沫影中被落叶剥开。 你选择了仰望，便在白羽上被彩虹簇拥。 早起歌备注：老师我现在还想去升国旗~！@ 墨夜听涩弦，皓月观希星。 蒙霜藏长风，添衣知冬临。 旧事如我忘，再言无新晴。 一笑泯恩苦，再笑碎琅玲。 拂手钻被去，深藏身与名。 明日人权日，早起升国旗。 2011 雨淋备注：傻逼忘带伞而已。 微冷的风，雨，甚至散发的花草孢子， 叮在皮肤上，治好了所有的不开心。 你就会赞叹自然的鬼斧神工，感悟世界的美不胜收。 这决然是一种契机，一种发生蜕变或者自我改良的契机。 路芽垂柳，石缝野花，八百年烦恼风，三千年不归雨， 矜持换新衣，娇艳正芳矣。 登楼备注：你麻痹谁写的感觉吊吊的 千江寒霜梦金鐏，彼岸秋殇失色容。 人笑我执无洒脱，笑者如我独登楼。 不知烦恼风吹栏，一曲英魂酒入喉。 拼词岂非言催泪，意向何须语汇流。 先遣三万花飞海，舞美罗旋蝶结衣。 后陈百行诗送客，雨落沿路空逆流。 泣君判我万万罪，吾郎才尽不哭酬。 2010 初见备注：刚来山大写的几句话，感觉山大很漂亮，是天空告诉我，把心情都放空~ 初见， 天空是辽阔的画布， 萃满了浅蓝。 飞机像一粒梭子， 拉起长线。 弥漫成一练哈达， 微笑着在天边嬉闹起波浪。 沉在四方的天边， 浮现出夕阳。 再见， 天空是淡雅的宣纸， 染上了橘红， 太阳像一颗珍珠， 牵上红丝。 散成漫天的桃花， 洗礼着这个悠扬的百年山大， 积淀在心中， 绽放出光芒。 牧伯流水 备注：最喜欢淡雅的文字，老子以前好脱俗~！@ 片段一： 月凝悬空，气宇粘稠，轻盈而下。仿佛年少心情，青涩未熟。 清帐雾漫，白花花的月光播种。似樱花楼兰台阶处。 因谁而去，如诉如慕？仿佛银光彩绸飘落，轻曲如红。 好像悄悄告诉我，你要我翻开洪荒万年你以笔间勾勒的心情。 而我要悄悄告诉你，流觞飞红，那定然是世上最美地线谱。 好像悄悄告诉我，你要我聆听你婆娑风韵的缠绵。 而我要悄悄告诉你，苍穹轻拢，那定然是世界上亘古流传的节奏。 好像悄悄告诉我，你要我忘记你倾诉时稚嫩而沧桑的面容。 而我要悄悄告诉你，烈火如歌，整个世界不过是你滴水石穿的坚持。 我该如何消受着绝世的萧霖，你该如何知道谁比你痴情？仿佛一切都已沉迷。 你仿佛是我的舞伴，而我却要看着你独自飘零。 片段二： 流觞是天籁，你眼似泉，汩汩轻柔。 上帝派下一管风，伴你飞舞。 你时而飞跃，时而俯冲， 时而分支，时而聚流。 月当空，佳阙南图树影斑斓， 你举杯，轻盈而上，漫卷云舒。 我追随，鞘剑长空，剑影萧肃。 你环我羊角浮萍而攒起，我伴你萧何传丹如凤行。 怎言？做一位骑士，观你似流星飞去。 马嘶鸣，山河崩摧千里； 重金铠，负你万水独行； 举草枪，杀尽天下奸佞； 手轻抚，爱马如痴醉饮。 远心录备注：记得文瀛十几里那架弹空的钢琴。 碧霜天 红叶林 风淡云轻 晓寒深处 苍柏黛眉心 苟为流水生死以 飞湍瀑流掖梨芯 琥珀窥千年 逝者往昔 蔼霞醉英豪 空寥寂 剪影流连过客 桂棹淡酒听琴音 长天色 射双雕 觅知音 品茗畅然独解 举觞堪年经？ 幽径多情霰琼花 可言天涯同飘零？ 龙城绮罗胭脂雪 弹指化白茵 铅华矣 后阙亭 老瑶琴。 退路备注：都是借口-。- 璀璨的生活常常因为退路而心有余悸。 退路是一种隐藏的懦弱，深藏在夏夜暖风的天真里面。 很多时候，退路都是每件事情背后必须的思量。 我们的每次悸动，每个留恋，每句珍重，都已经变成人生最隐晦的怀念。 这样的怀念或许要作为顿悟的缘，寄托的种。在心中滴入深深的细细的感动， 豆蔻般的情怀，没有这样失意落魄的理由，那么即使遭遇了风雨飘摇，也要勇敢的前进。 这一条路，昂首向前，不附议，不诽谤，恬然与忧伤携手，坚毅与酸楚同在，清新自然，踏浪而行。 2009 这里都是高中时期写的东西啦 姜维赋备注：到现在还是最喜欢这个写给姜维的歌~很怀念我们打三国副本刷专属的日子，姜维最帅最强最叼不解释。 雨 屋檐上 步法轻盈地飘逸 蹑足潜踪了 关于古刹间的好奇 像这样 布满了夜和晨 树 荒岭头 前所未有地沉迷 湮灭扭曲了 回旋恶龙上的宁静 像这样 囚禁了天和地 风 冰窗外 漫卷天涯地霸气 空气凝固了 吹乱发丝上的落魄 像这样 却只绝望了我 谁？ 注定着 乱舞叱诧地争斗 狼烟落幕了 散落空气中的血腥 像这样 失败没有资格哭泣 词牌名：新月 方归备注：我们是要离开家的雏燕，南去雏燕，辄五里，犹含清涟。记得一个易断鸾弦的故事。 尽长汀君颜，千秋醉引，依醉昆仑颠。 归来椽月，休相逢，凭栏复慭然。 南去雏燕，辄五里，犹含清涟。 怎名状？九曲银河老，韬月却惊寒。 千古浪屿烽烟。痴慢磨铁杵，难补圆缺。 清华池覆酒，颦欢颜，流莺逐岸云端。 鸾弦易断，待谁问，方归沧水？ 看东海朱丹小，流水雨潇潇。 词牌名：雨霖铃 旧景备注： 现在真的看不懂了-。- 雾岚故尘，醒木败芝，贵妃遗篇。 金铃夜景犹在，奈飘摇，三生离人。 戚雨沥沥碎衣，听月问红笺： 蛮荒路，千古枭屿，凭何绪浪封巅？ 多情自古引鸿躇，那管他，祁山江东旗乱！ 明朝战影飒爽，为佳人，伏尸百万。 星照孤身，却是万千醉影不堪。 看流梭彩璃十色，何时复晨辉。 词牌名：永遇乐 异时乐备注：真的永远不会忘记我们漫步在雨后花池的感觉~ 细柳扬鞭，触鸟漪沦，暗香促清鸣。 断魂声声，榭雨歌台，不见袖飘零。 窗边黯莠，远山扶桑，流沙相送十里。 深深叹，云梦水泽，异时纷飞世情。 千山逐岸，紫绡罗衣，落英满街亭。 彩屏栩栩，破蕊花逝，婆娑身前影。 月上婵娟，影照桂木，应是喋喋轻语。 待他时，扬身挫骨，便作前尘泥泞。 自编小说向备注：妈蛋这个片段到现在资历太浅都写不出来。现在提起扇贝就想吃！！！！！ ###焱阳浮水之浮水篇 火炎焱阳焰满天，水孚浮水冰消颜。 君莅断浪留情怜，妾倚汀亭荷连绵。 久渡梧桐葬雏鸢，长守缘木望旌帘。 莲华赴日露弥尖，弱体不堪烛摇曳。 鸳鸯戏水互倾曲，扇贝吐珠待君还。 ###焱阳浮水之焱阳篇 霸业鸿图溯流光，素子娇容倾国殇。 郎莅断浪破八荒。侬葬雏鸢哭儿郎。 柳欲抑而风不止，情欲扬而伊不在。 蓉丝连藕怜碎藕，清酒稠肠愁断肠。 醉酒云雾歌一曲。焱阳浮水游远方。 美人记 碎蒲丁矜珠香茗，颤茎扶屏，雏叶捧心，罗菂濯清， 今归蜻蜓，何处流莺？ 万翠浮华绝素裹，千红湮镜胜淋漓。 牵杯酩酊，拂羽叮咛。 望窸窣脂堆月颦，醉红尘国覆城倾。 归雨辞备注：就记得夕阳下汾河超赞的样子~！@ 这大概是高中日记本的题词吧？ 夏雨奏藏藕，翠萼淡潮嫣。 凝望濛雨泛重楼，飞涟破青莲。 夕阳涌红帘，红帘溢湖面， 一袭秋雨倏梧桐，叶叶落思桃花前。 算风流 人自羞。 觞角杯 杯杯碎罹忧。 百里榆堤长空濛，细数雨丝，何时覆扁舟？ 归鸿犹有赴日情，浪子那堪金曾换？ 或可倾一曲，寿醨填思源。 泣涕零，衬景如东流。盖复笑谈间。 烟雨霡霂辞莫念。 皓落赋备注：就记得月光穿透玻璃的寒霜，打在上课走神的脸上。 琳窗琅檐黛光绝，新霜顾旧颜。 廿年零落丝笼雀。百鸣成空碣。 琼叠彩溢，浆旋香凝，笑鼎泣姬妄痴言。 都难念，空杯待暖啸吟天，怎惊了天上仙？ 储君堪莫叹，褪华年孰与鸾同雀。 复念儿时岁，断弦水响相嬉喧。 踏草凌梢轻胜此，唯心量人间。 剑舞破蕊花不语， 月挂琉璃，泪悬珠珍，心坠寒晶， 一任乱絮嵌蝉冰，碎了流年。 夜风歌备注：盛世笙歌，皆作尘土！！！可惜最后还是没中高榜哈哈哈 彤柳飔风香一线，进宵楼阁无月， 星韵暗淡愈淡颜，尘雾黯羽云天。 几多欢喜驾鹤仙，茶凉纷飞雀。 此情绛雪雪消融，雪融映月月鸣颤。 总问月上婵娟； 同是流水沫欢庆，天上地下有何别。 掷轻思如飞箭，中高榜而月缺。 往事慢慢滴金石，又是云烟。 劝君莫舞——不见盛世笙歌，皆作尘土。 水漂备注：走，我们去打水漂~！@ 瓢泼，注定，失败。 渠成，成为，东流。 阴霾，使你我流浪， 流浪在雨中的徒劳，我仿佛是世界的水漂， 悄悄地飞溅起涟漪然后丢掉，而这世界的甘霖， 嘲弄你我的飘渺。 是否知道，是对谁的宣告。 落幕了，一切都会知晓。 衣袂轻撩，莫要忘记， 我是你手中的水漂。 丢掉丢掉，我是你手中的水漂。 2008 备注：现在对花瓣唯一感觉就是浏览花瓣网。 ##花瓣 一季花落 两靥春风 新的土层覆盖了旧的断面 新的流水冲掘出河床 新的话开在两岸上 时间把万物煮成雨水 浇灌了它们覆盖旧时的灿烂 被冲积在土壤里的 过去的花瓣 闻君落第备注：矫情。某人千万别考试考不好 鸿雁惊厥凌叶嘶， 驰风万丈痛生息。 谁堪覆水浊无忌， 天地竖子落灵夕。 词牌名：水调歌头 汾河长行备注：现在要告诉自己的是不要多管闲事哈哈哈哈哈。 清华枫叶静 拒霜秋鸟惊。 九州处处汀虹 娇阳白水粼。 桥畔红穗雏菊 桥垠金翅伊颜 说与众人听： 太白酒千杯 悠悠不醉膺。 休清愁 散雨霏 淡潇霖。 三生醉影 望秋水诗赋千津。 椿木蜉蝣难盟 蜉蜩鲲鹏不姻 转神是无形。 蝉翼薄纱衣 熠熠付炬心。 一颜备注：到现在都是心中战歌。 一醉方休， 一眸泪难留， 一举衣袖， 一点一滴一神秀。 一醉方休， 一生不还秋， 一战苍穹， 一君一帝一轻游。 小云月备注：看都没看跳过。 月华凝韵，紫带穿辰，举目若颦眉。 长风有恨树零落，明月无情影凋零。 小径潋滟韬光晦，何人惜顾地上情？ 镜花水月空相识，我知何物是我知？ 料得古今萧索意，落木飞红不知情。 九水滔天沾雾霭，如庭前曝流水； 八荒凌峰裹霜霞，如剑下破寒冰。 平生志，语人几人听？ 会当凌霄休花月，孑孑流瑟啖稠云。 晨曦备注：晨曦融化积雪。 雯岚雾霜窗纱镜，难滤艳阳吐信。 去日覆雪泪轻吟，寸寸滴碎锥心。 千般婉转似流莺，却难觅绿枝相逢迎。 水澹澹人间氤氲。 寒月寄思备注：年轻的时候真傻逼，看不下去了。 纸迷金醉，朝朝阙目。 芷芳兰幽，暮暮盈喉。 举头觅星寰，寂寞残酒。 方邀月，古往歌者似凝眸： 暗度烟光可歌寂，天荒东流可歌愁 一倾百年痴心水，映月无声空逆流 君可见八百里云梦泽，气撼岳阳楼 君可问两千年广陵散，血洒韩王阁 男儿立钧千斤鼎，看项羽战诸侯 丈夫握笔万里行，看房谋杜断数豪雄。 烟波九州御宇内，安敢同游否？ 欲仰促颦眉，知是心相谁 无题备注：写的好！短！ 若往昔 平铺三万里明媚 不能纵深入我心扉。 七夕备注：七夕又快到了，其实就想看看这个才整理的这些啦~ 仲夏的阳光琉璃 ，几缕思绪躲在风筝下 我在太阳附近，看着，在记忆的下游 如果碧潭再碧些，就可以照我忧伤的侧影 如果蚱蜢舟再蚱蜢些，我的忧伤就灭顶 早晨成时，大地未苏醒，有雀鸣，夏正年轻 孩童的笑声在水上飞，飞来蜻蜓，飞去蜻蜓 如果栖在我船尾，小舟该多轻，这双浆该扬起 谁是西施，谁是范蠡 那就划去太湖，划去洞庭 听唐朝的猿啼 划去潺潺的天河，看梦在神话里 牛郎织女在天河相拥 我看着蔚蓝的银河 从上个七夕，到下个七夕 元宵望月赋备注：感觉以前这小伙真牛逼！！牛逼！！！ 己丑新初，元宵佳节，秉承旧历，相邀故友。弹指幽兰，玉方巾帼红靥；舞剑狂沙，磐坚须眉蓝颜。声水芙蓉，喜忧天下之事；闻木紫烟，乐悲个家章篇。水木清华，呢喃生息。月稍扬，众仙驾雾咸集；步蹒跚，栏槛摇影皆去。正所谓,灯月星辉交碧映，树人风光满辉煌。融融趣味，浮华尽拳拳赤心；灿烂金光，缥渺于缕缕羌音。 复至汾河，妄首而观。车如流水马如龙，盏似琉璃锦似秀。银光漫烂，上凌星墟比一方，下临长水分庭抗。心若悬离，欲奋而起。赞高山流水，蜡象披帷社稷旺；叹悬壁垂天，苍穹旷芒九州兴。落明月，俯雕峰，越越然吞万里河山；瞰阑珊，引衣袂，飘飘乎畅千寻胸怀。因填长调“满江红”，词曰： 满江红.壮志踌 散缘流水，瓓轩处，烟歌天籟。畅胸襟，放浪天涯。满目馨香，十六劳苦一乐休，那管风花雪月他处！徒半生，多少功名醉，人悲路。香兰舞，百境妖娆，却迁落，睥睨痴山河。万里偕友举杯盏，壮志鸿踌应满壶，鼎立八方朝天阙。同一笑，幽梦复一曲，情万丈。 方是时，訇然天地骤裂，罗贯区明，彩带绸云，火光四溢。率土之滨礼炮漫卷晶琼，普天之下烟火缤纷虹霁。万翠成屏，羽化流梭扶摇起；千红化镜，碎面焕铠追星去。余与众友长立于天地，观淘天离火，感吾生之虚渡，叹人为之至此。星韵黯淡，彩光如曲，落霞飞仙，世间天堂。似龟寿麟瑞，龙翔凤翥。瑶池玉树，舞青带之玉颈；黄泉缘石，忘断魂之婆娑。骊翔当空，俊采星驰，雀栖桂兰，豪英归宗。大河两岸，无不慨叹。友遇怀而上九寨，一十六人会王阁，众仙过海见乾坤，广部天龙举豪情。背负雕栏，穹宇连韵而齐；指鄙白玉，四海视穷而下。举首而呼，长霓贯月，星河斗笠，幻化八般飘袖嫱媖随风舞；短松弥岗，霜雾缱绻，凝聚三世旖旎佳景伴缨浮。锋茫乍露，天下无双。于是开怀而欢，戏尽满怀多情岁，忆往昔袅袅共室句读于檐榻，伤不禁情。众喜而散，余独放逐于月光。 喜灭清凉，人易醉麻桑，洪荒长歌，天马夜骑，独望此月，若有所思。九万里风鹏正举，恐旦暮落而折翼。世事扰攘，何以比邻？夫天地之玉老乎?吾身死而长存，心死而缘灭。夫河泽之微虫乎？吾未去而遗世，抚体而不明。呜呼！一句阿弥，九品莲华，翼殄千转，百态轮回。古有云：朝闻夕死。而何以谓闻？物竟天荣，徘徊俱灭，吾生为人苦，为众生苦，何为其然也？暇梦吾之两世为人：一世曰呼不起，一世曰若此生，而又何算邪？吾之喜怒哀乐悲苦忧，吾之主客天文地理筹，又谓何哉？恐余未闻道而先逝翌日呼起而二世为人，已然卒没此生矣。又何辨形神气理焉？鄙陋浅闻，浮夸半生，崦嵫高耸，不如孤凤。未逢贵绅玉堂，幸免残陋之茔；未欲探枝蔽日，幸非浪羁轻徒。春啖幽紫苏，夏饮绵甘雨，秋啼独望月，冬咽风吹雪。寥寥不过半曲胡笳耳。排室人于吐息，捡挚真以微诚，凄凄断指可复数耳。又何念哉？ 痴情莫笑我，寄礼卷于雅兴，托昏戏以仁信，皆云烟之集散，恍天地之聚明。复念上古离人，有若精忠之幸骨，有若桃园之恩荣，有若陈情之赋表云云者，闻之而涕，涕之而起，恨断血长颅难相去，苦生死彭殇之不一，庸庸然，若惘然，岂不悲哉！ 吾尝幻之长天，降鹅毛以大雪，覆黄尘如麦芒，蜷月光于明镜。一树本曰菩提，承万斤之银网，雪皑皑，雾漫漫，天涯陌路寒霜相伴，皎月星盘，素裹天河，流光烂漫，如丝如缕，如缎如绸，山河锦锈，万世功澜。恶风轻袭，复吹皱一树枯荣。落英细听谁数，掩孤身于无物。山高水长如月，阑干落影若空，欣欣乎之无相。冷剑如鞭，耸然笞鞑，横枪无锋，复出长空，刚愎苍劲，穿九霄八千里云月上。余心跳如摚，举臂高喝，曲高和寡，悉于万象。 玉箫短语，虬龙呜鸣，夜景空在，孤影轻流，暮晚林息，涧溪清潭，鼎泉如菊，三尺书屋，一将残棋，书香翰墨，玉壶温茶，往返唐今芳华。人生憔悴情难当，笑莫断肠，笑莫断肠！他日但有锋茫曲，纵人老心荒平地起波浪。 月寒凄苦，人归情断藕。更得填“定风波”长调，聊以慰藉： 定风波.元宵月几曲烟光，醉洪波，金韵彤花如梭。红颜昙朵，月影星罗，数尽怜情人（儿）多。流岗粉绸飘落，昨日冰簟负难脱，非若！空趣不持，红缘易堕。不知幽月，几时缩？清华空寂，若酾洒，犹嫌一人烦琐。怎教揽月说，隐香云，却露姿色，潇洒熙和凤翎舞，笑伊！四目相顾，慕影谁错？ 牢裘既灭，风烟倶尽，得天时易老，请刮琼脂，寥寥千字余，求君一笑耳。对酒当歌，笑能解千愁，一杯黄沙解风流，苍穹何伴奏？","tags":[{"name":"Poem","slug":"Poem","permalink":"https://galaxias-sapphi-ren.github.io/tags/Poem/"}]}]