[{"title":"Machine Learning | 扬帆起航神经网络与深度学习","date":"2017-02-21T01:00:00.000Z","path":"2017/02/21/machine-learning-nn-dl/","text":"睡眼惺忪，阳光入帘，起床深呼吸，要不然，开始有智能的机器就要淘汰你了。 2017年02月21日 - 任思飞 @Copyright Smart Home &amp; Roobo 神经网络与深度学习概述 - 机器学习预研 摘要 智能是根据环境变化而做出相应变化的能力，从信息论的观点看就是减熵的能力。而人工智能（Artificial Intelligence）的研究目标是使机器像人一样智能，主要应用于自然语言处理、知识表现、推理、规划、感知、模式识别等。 机器学习（Machine Learning）是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。 深度学习（Deep Learning）是深层的机器学习（Deep ML）。其“深层”（Deep）的真正含义是通过“抽象概念”学习，将多层表达的特征提取器和识别器合在一起，算法加“深”。 神经网络（Neural Networks）属于ML的一种。而深层神经网络（Deep NN）也只是深层学习的一种。 本文分别从自然学习与机器学习的概念类比、python最简代码（核心算法）学习、为什么要进行深度学习、谷歌开放机器学习框架tensorflow神经网络官方playground实例，四个方面概述人工智能、机器学习、深度学习的内容和结构，并层层递进的阐释感知器、神经网络、循环神经网络、卷积神经网络等的概念与常用算法。 本文试图在脱离线性代数、统计学相关公式的情况下，从不同角度聚焦在人工智能领域的神经网络和深度学习相关内容。并且最终给出一般性算法选择路径。 关键字 神经网络 机器学习 深度学习 导读 吴军在《数学之美》中有一段描述，引做导读。 有不少专业术语乍一听很唬人，“人工神经网络”就属于这一类，至少我第一次听到这个词就被唬住了。你想啊，在大家的印象当中，人们对人脑的结构都还根本没有搞清楚，这就冒出来一个“人工的”神经网络，似乎是在用计算机来模拟人脑。想到人脑的结构那么复杂，大家的第一反应一定是人工神经网络肯定非常高深。如果我们有幸遇到一个好心同时又善于表达的科学家或教授，他愿意花一两个小时的时间，深入浅出地把人工神经网络的底细告诉你，你便会发现，“哦，原来是这么回事”。如果我们不幸遇到一个爱卖弄的人，他会很郑重地告诉你“我在使用人工神经网络”或者“我研究的课题是人工神经网络”，然后就没有下文了，如此，你除了对他肃然起敬外，不由得可能还会感到自卑。当然还有好心却不善于表达的人试图将这个概念给你讲清楚，但是他用了一些更难懂的名词，讲得云山雾罩，最后你发现听他讲了好几个小时，结果是更加糊涂了，你除了浪费时间外一无所获，于是你得出一个结论：反正我这辈子不需要搞懂它了。 大家可别以为我是在说笑话，这些都是我的亲身经历。首先，我没有遇到过一两小时给我讲懂的好心人，其次我遇到了一批在我前面卖弄的人，作为年轻人，总是希望把自己不明白的东西搞懂，于是我决定去旁听一门课。不过，我听了大约两三次便不再去了，因为除了浪费时间，似乎我并没得到什么收获。好在我自己做研究暂时用不到它，也就不再关心了。后来在美国读博士期间，我喜欢在睡觉前躺着看书，没事儿就捧着几本关于人工神经网络的教科书在床上看，居然也看懂了。然后再用它做了两三个项目，算是学会了。到这时回过头来再看“人工神经网络”，其实并不复杂，入门也不难，只是我走了弯路。 第一章：自然到机器的学习 本章对比自然学习和机器学习的相关概念，尝试类比机器学习的内容，并强化对机器学习中神经网络的理解。机器学习地铁图、算法决策图等概述机器学习概念。 知识比对表如下： 自然名词 机器名词 作用 智能 人工智能 熵减，根据环境变化而做出相应变化，学习和预测 生物学习 机器学习 寻求从过去状态到未来状态的关联的过程 神经元 感知机 输入特征（向量），输出描述状态，用线性变换跟随着非线性变化，将输入空间投向另一个空间，是输出的决策单元 抽象层级 层 增加容纳变体的能力、鲁棒性 神经元的网状结构 神经网络（分类器） 学习和预测过去到未来的关联 1.1 从智能开始 1.1.2 智能 从信息论的观点看自然智能，从宇宙大爆炸开始，世界的状态向越不确定的状态转变，所蕴涵的信息越来越多。生命要在这个变化的世界中生存，它就需要知道如何根据环境变化做出相应的行动来避免毁灭。把不确定的环境转换成确定的行动。会将无序的事物重新整理到有序的状态。生物仅仅活着就需要减熵，否则就会被不确定性会消灭。 其中： 智能是可以根据环境变化而做出相应变化的能力(熵减的能力)，通过智能，智能体学习和预测信息，减少信息状态的不确定性。 熵是用来衡量我们对事物在跨时间后能产生不同状态的混乱度。越确定(deterministic)的事件的熵越低，越随机(probabilistic)的事件的熵越高。 自然的智能存储于遗传物质中，通过螺旋结构合成蛋白质，根据化学信号和电信号执行功能。生物通过繁殖和变异学习自然智能。 1.1.2 人工智能（Artificial Intelligence） 随着信息量的增加，智能无法解决大信息量的问题，人类开始尝试使机器产生智能，人工智能是指由人工制造出来的系统所表现出来的智能。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基于仿生学、认知心理学，以及基于概率论和经济学的算法等等也在逐步探索当中。而机器学习是解决人工智能的主要途径，主要用于解决决策所需要的数据量超过我们有限大脑的处理能力的问题。 人工智能是多科学的交叉，但又不被任何一个学科完全包含。 从智能的定义直接扩展的话，人工智能是非自然选择形成的一种减熵的能力。 1.2 什么是学习 1.2.1 生物学习 人可以通过经验学习，比方说“朝霞不出门，晚霞行千里”，就是通过经验得来的知识。所以学习的对象是‘经验’，准确说是先验知识，广义说是数据。 随着信息增加，不确定性增高。学习是从信息中找回物理关系，回卷信息，降低不确定性的过程。被找回的物理关系叫做知识。 1.2.2 机器学习 机器学习主要是研究如何使计算机从给定的数据中学习规律，即从观测数据(样本)中寻找规律，并利用学习到的规律(模型)对未知或无法观测的数据进行预测。目前，主流的机器学习算法是基于统计的方法，也叫统计机器学习。 简单来讲，只要表现出智能的程序（将无序数据转换为有用知识），且程序的参数是从数据中进行学习，就是机器学习。 1.2.2.1 概念维基百科 机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。 机器学习（1998 Tom Mitchell）对于一个程序，给它一个任务T和一个性能测量方法P，如果在经验E的影响下，P对T的测量结果得到了改进，那么就说该程序从E中学习。 1.2.2.2 学习阶段LEARNING = REPRESENTATION + EVALUATION + OPTIMIZATION REPRESENTATION（表现）：表示信息的状态（假设空间）及特征（分类器） EVALUATION（评价）：区分正确的信息状态和好的特征（评价函数或目标函数） OPTIMIZATION（优化）：迭代快速的学习（算法优化） 1.2.2.3 数学解释学习一个映射函数f : x → y，将输入变量x映射为输出变量y。一般我们可以假设映射函数为y = f(x, θ)。其中θ 即为函数的参数。参数可以通过学习算法进行学习。 我们还要建立一些准则来衡量决策函数的好坏。在很多机器学习算法中， 一般是定义一个损失函数 L(y, f(x, a)) 然后在所有的训练样本上来评价决策函数的风险。 用对参数求经验风险来逐渐逼近理想的期望风险的最小值，就是我们常说的经验风险最小化原则(Empirical Risk Minimization)。这样，我们的目标就是变成了找到一个参数a使得经验风险最小。 1.2.2.2 结构 1.2.2.3 学习地铁图 1.2.2.3 分类及算法机器学习分类包括： 监督性学习（Supervised Learning）， 概念：有监督学习是利用一组已知输入 x 和输出 y 的数据来学习模型的参数，使 ]得模型预测的输出标记和真实标记尽可能的一致。 用途：根据函数的输出是连续的值还是离散的值可以分为回归（Recregression）和分类（Classication）。目前最广泛被使用的分类器有人工神经网络、支持向量机、最近邻居法、高斯混合模型、朴素贝叶斯方法、决策树和径向基函数分类。 非监督学习（Unsupervised Learning） 概念：无监督学习是用来学习的数据不包 含输出目标，需要学习算法自动学习到一些有价值的信息。 用途：主要用于数据聚类（Clustering），在人工神经网络中，自我组织映射（SOM）和适应性共振理论（ART）则是最常用的非监督式学习。 强化学习（Reinforcement Learning） 概念：强化学习强调如何基于环境做出一系列的动作，以取得最大化的累积收益。每做出一个动作，并不一定立刻得到收益。增强学习和有监督 学习的不同在于增强学习不需要显式地以输入/输出对的方式给出训练样本，是一种在线的学习机制。 用途：主要应用于机器人决策中的回报函数和连续决策。 迁移学习（Transfer Learning）。 概念：把已学训练好的模型参数迁移到新的模型来帮助新模型训练数据集。 机器学习常用算法有： 算法一览 机器学习中算法决策图解 算法索引 正则化算法（Regularization Algorithms） 概念：它是另一种方法（通常是回归方法）的拓展，这种方法会基于模型复杂性对其进行惩罚，它喜欢相对简单能够更好的泛化的模型。 案例：岭回归（Ridge Regression）、最小绝对收缩与选择算子（LASSO）、GLASSO、弹性网络（Elastic Net）、最小角回归（Least-Angle Regression） 优点：其惩罚会减少过拟合，总会有解决方法 缺点：惩罚会造成欠拟合，很难校准 集成算法（Ensemble Algorithms） 概念：集成方法是由多个较弱的模型集成模型组，其中的模型可以单独进行训练，并且它们的预测能以某种方式结合起来去做出一个总体预测。 案例：Boosting、Bootstrapped Aggregation（Bagging）、AdaBoost、层叠泛化（Stacked Generalization）（blending）、梯度推进机（Gradient Boosting Machines，GBM）、梯度提升回归树（Gradient Boosted Regression Trees，GBRT）、随机森林（Random Forest） 优点：当先最先进的预测几乎都使用了算法集成。它比使用单个模型预测出来的结果要精确的多 缺点：需要大量的维护工作 决策树算法（Decision Tree Algorithm） 概念：决策树学习使用一个决策树作为一个预测模型，它将对一个 item（表征在分支上）观察所得映射成关于该 item 的目标值的结论（表征在叶子中）。树模型中的目标是可变的，可以采一组有限值，被称为分类树；在这些树结构中，叶子表示类标签，分支表示表征这些类标签的连接的特征。 案例：分类和回归树（Classification and Regression Tree，CART）、Iterative Dichotomiser 3（ID3）、C4.5 和 C5.0（一种强大方法的两个不同版本） 优点：计算量简单，可解释性强，比较适合处理有缺失属性值的样本，能够处理不相关的特征 缺点：容易过拟合（后续出现了随机森林，减小了过拟合现象），可能或陷于局部最小值中，没有在线学习，单颗决策树分类能力弱，并且对连续值变量难以处理。 回归（Regression） 概念：回归是用于估计两种变量之间关系的统计过程。当用于分析因变量和一个 多个自变量之间的关系时，该算法能提供很多建模和分析多个变量的技巧。具体一点说，回归分析可以帮助我们理解当任意一个自变量变化，另一个自变量不变时，因变量变化的典型值。最常见的是，回归分析能在给定自变量的条件下估计出因变量的条件期望。 案例：普通最小二乘回归（Ordinary Least Squares Regression，OLSR）、线性回归（Linear Regression）、逻辑回归（Logistic Regression）、逐步回归（Stepwise Regression）、多元自适应回归样条（Multivariate Adaptive Regression Splines，MARS）、本地散点平滑估计（Locally Estimated Scatterplot Smoothing，LOESS） 优点：直接、快速，知名度高 缺点：要求严格的假设，需要处理异常值 人工神经网络（Artificial Neural Network） 概念：人工神经网络是受生物神经网络启发而构建的算法模型。它是一种模式匹配，常被用于回归和分类问题，但拥有庞大的子域，由数百种算法和各类问题的变体组成。 案例：感知器、反向传播、Hopfield 网络、径向基函数网络（Radial Basis Function Network，RBFN） 优点：在语音、语义、视觉、各类游戏（如围棋）的任务中表现极好。算法可以快速调整，适应新的问题。 缺点：需要大量数据进行训练。训练要求很高的硬件配置。模型处于「黑箱状态」，难以理解内部机制。元参数（Metaparameter）与网络拓扑选择困难。 深度学习（Deep Learning） 概念：深度学习是人工神经网络的最新分支，它受益于当代硬件的快速发展。众多研究者目前的方向主要集中于构建更大、更复杂的神经网络，目前有许多方法正在聚焦半监督学习问题，其中用于训练的大数据集只包含很少的标记。 案例：深玻耳兹曼机（Deep Boltzmann Machine，DBM）、Deep Belief Networks（DBN）、卷积神经网络（CNN）、Stacked Auto-Encoders 优缺点：同神经网络 支持向量机（Support Vector Machine） 概念：给定一组训练事例，其中每个事例都属于两个类别中的一个，支持向量机（SVM）训练算法可以在被输入新的事例后将其分类到两个类别中的一个，使自身成为非概率二进制线性分类器。SVM 模型将训练事例表示为空间中的点，它们被映射到一幅图中，由一条明确的、尽可能宽的间隔分开以区分两个类别。随后，新的示例会被映射到同一空间中，并基于它们落在间隔的哪一侧来预测它属于的类别。 优点：在非线性可分问题上表现优秀。 缺点：非常难以训练。很难解释。 降维算法（Dimensionality Reduction Algorithms） 概念：和集簇方法类似，降维追求并利用数据的内在结构，目的在于使用较少的信息总结或描述数据。这一算法可用于可视化高维数据或简化接下来可用于监督学习中的数据。许多这样的方法可针对分类和回归的使用进行调整。 案例：主成分分析（Principal Component Analysis (PCA)）、主成分回归（Principal Component Regression (PCR)）、偏最小二乘回归（Partial Least Squares Regression (PLSR)）、Sammon 映射（Sammon Mapping）、多维尺度变换（Multidimensional Scaling (MDS)）、投影寻踪（Projection Pursuit）、线性判别分析（Linear Discriminant Analysis (LDA)）、混合判别分析（Mixture Discriminant Analysis (MDA)）、二次判别分析（Quadratic Discriminant Analysis (QDA)）、灵活判别分析（Flexible Discriminant Analysis (FDA)） 优点：可处理大规模数据集。无需在数据上进行假设。 缺点： 难以搞定非线性数据。难以理解结果的意义。 聚类算法（Clustering Algorithms） 概念：聚类算法是指对一组目标进行分类，属于同一组（亦即一个类，cluster）的目标被划分在一组中，与其他组目标相比，同一组目标更加彼此相似（在某种意义上）。 案例：K-均值（k-Means）、k-Medians 算法、Expectation Maximi 封层 ation (EM)、最大期望算法（EM）、分层集群（Hierarchical Clstering） 优点：让数据变得有意义 缺点：结果难以解读，针对不寻常的数据组，结果可能无用。 基于实例的算法（Instance-based Algorithms） 概念：基于实例的算法（有时也称为基于记忆的学习）是这样学习算法，不是明确归纳，而是将新的问题例子与训练过程中见过的例子进行对比，这些见过的例子就在存储器中。之所以叫基于实例的算法是因为它直接从训练实例中建构出假设。这意味这，假设的复杂度能随着数据的增长而变化：最糟的情况是，假设是一个训练项目列表，分类一个单独新实例计算复杂度为 O（n） 案例：K 最近邻（k-Nearest Neighbor (kNN)）、学习向量量化（Learning Vector Quantization (LVQ)）、自组织映射（Self-Organizing Map (SOM)）、局部加权学习（Locally Weighted Learning (LWL)） 优点：算法简单、结果易于解读 缺点：内存使用非常高。计算成本高。不可能用于高维特征空间。 贝叶斯算法（Bayesian Algorithms） 概念：贝叶斯方法是指明确应用了贝叶斯定理来解决如分类和回归等问题的方法。 案例：朴素贝叶斯（Naive Bayes）、高斯朴素贝叶斯（Gaussian Naive Bayes）、多项式朴素贝叶斯（Multinomial Naive Bayes）、平均一致依赖估计器（Averaged One-Dependence Estimators (AODE)）、贝叶斯信念网络（Bayesian Belief Network (BBN)）、贝叶斯网络（Bayesian Network (BN)） 优点：快速、易于训练、给出了它们所需的资源能带来良好的表现 缺点：如果输入变量是相关的，则会出现问题 关联规则学习算法（Association Rule Learning Algorithms）0008– 概念：关联规则学习方法能够提取出对数据中的变量之间的关系的最佳解释。比如说一家超市的销售数据中存在规则 {洋葱，土豆}=&gt; {汉堡}，那说明当一位客户同时购买了洋葱和土豆的时候，他很有可能还会购买汉堡肉。 案例：Apriori 算法（Apriori algorithm）、Eclat 算法（Eclat algorithm）、FP-growth 图模型（Graphical Models） 概念：图模型或概率图模型（PGM/probabilistic graphical model）是一种概率模型，一个图（graph）可以通过其表示随机变量之间的条件依赖结构（conditional dependence structure）。 案例：贝叶斯网络（Bayesian network）、马尔可夫随机域（Markov random field）、链图（Chain Graphs）、祖先图（Ancestral graph） 优点：模型清晰，能被直观地理解 缺点：确定其依赖的拓扑很困难，有时候也很模糊 常用算法边界预测对比 1.2.3 定理 1.2.3.1 没有免费午餐定理没有免费午餐定理(No Free Lunch Theorem，NFL) 是由Wolpert和Macerday在最优化理论中提出的。没有免费午餐定理证明：对于基于迭代的最优化算法，不存在某种算法对所有问题（有限的搜索空间内）都有效。如果一个算法对某些问题有效，那么它一定在另外一些问题上比纯随机搜索算法更差。也就是说，不能脱离具体问题来谈论算法的优劣，任何算法都有局限性。必须要“具体问题具体分析”。没有免费午餐定理对于机器学习算法也同样适用。不存在一种机器学习算法适合于任何领域或任务。如果有人宣称自己的模型在所有问题上都好于其他模型，那么他肯定是在吹牛。 1.2.3.2 丑小鸭定理丑小鸭定理（Ugly Duckling）1960年代，美籍日本学者渡边慧提出了丑的鼻祖之一。 小鸭定理：“丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大”。这个定理初看好像不符合常识，但是仔细思考后是非常有道理的。因为世界上不存在相似性的客观标准，一切相似性的标准都是主观的。如果以体型大小的角度来看，丑小鸭和白天鹅的区别大于两只白天鹅的区别；但是如果以基因的角度来看，丑小鸭与它父母的差别要小于他父母和其他白天鹅之间的差别。 1.2.4 学习网站 清晰的查询出相关算法的知识拓扑图。 metacademy.org 1.3 神经元与感知机神经元是构成神经网络的基础单元，先归纳一下神经元模型。 1.3.1 神经元 神经元通过电信号和化学信号传递兴奋或者抑制。 其行为可以解释为： 其中：x是输入电信号（向量），y是输出电信号（output），x，y的个数是突触的个数（维度），W是各个神经元连接强弱，a()是化学传递（激活函数，非线性能力）。大量神经元就可学习过去到未来的关联。 1.3.2 MP模型 总结神经元特点 每个神经元都是一个多输入单输出的信息处理单元 神经元输入分兴奋性输入和抑制性输入两种类型 神经元具有空间整合特性和阈值特性 神经元输入与输出间有固定的时滞，主要取决于突触延搁 心理学家Mcculloch和数理逻辑学家Pitts合作提出的M-P模型。相比于神经元，MP模型忽略时间整合作用、不应期等复杂因素，并把神经元的突触时延和强度当成常数。 其中，激活函数（activation function）加入非线性因素的，因为线性模型的表达能力不够。例如，在实现分类器功能时，参数与权重的点积是线性的，在做分类运算时只能在数据轴上画一条直线，而在让该点积经过激活函数 y = f(a) 处理后，加入了非线性因素，使直线变成曲线，这时分类器的表达能力更好。 1.3.2.1 激活函数如果没有激活函数，网络仅能够表达线性映射，即便有再多的隐藏层，整个网络跟单层神经网络也是等价的。因此也可以认为，只有加入了激活函数之后，深度神经网络才具备了分层的非线性映射的学习能力。 常用的神经元非线性激发函数有阈值型、分段线性型、Sigmoid函数型（简称S型）和双曲正切型 其中sigmoid函数曲线错误，详细神经网络激活函数见1.3.4. 1.3.3 感知机（Perceptron） 1.3.3.1 概念感知机（perceptron）是二分类的线性分类模型，属于监督学习算法。输入为实例的特征向量，输出为实例的类别。感知机是神经网络和支持向量机的基础。 1957年美国学者Rosenblatt提出了一类具有自学习能力的感知器模型，它是一个具有单层计算单元的前向神经网络，其神经元为线性阈值单元，称为单层感知器。也就是说: 神经元之间的连接权值wi是可变的，这种可变性就保证了感知器具有学习能力。 1959 年Rosenblatt提出了感知器模型中连接权值参数的学习算法。算法的思想是首先把连接权值和阈值初始化为较小的非零随机数，然后把有n个连接权值的输入送入网络，经加权运算处理，得到的输出如果与所期望的输出有较大的差别，就对连接权值参数按照某种算法进行自动调整，经过多次反复，直到所得到的输出与所期望的输出间的差别满足要求为止。 1.3.3.2 分类已知存在感知机 f(x) = sign ( w * x + b ) w是权重weight，b是偏置bias，sign是符号函数 f(x)= +1 if x &gt;= 0 −1 else 目标：找到一个最佳的满足 w * x + b = 0 的 w 和 b 值，即分离超平面（separating hyperplane）将样本分为正样本和负样本。 问题转换为优化问题：最小化损失函数 误分类点(x0, y0)到超平面 w * x + b = 0 的距离为 ( w * x0 + b ) / ( w^2 + 1 )^1/2 # 把( w^2 + 1 )^1/2 定义为 1/||w||，||w||为L2范式，满足高斯分布 且有 −y0 * ( w * x0 + b) &gt; 0 # 若(x0, y0)为正样本，y0为正，误分类后 w * x0 + b 为负，−y0 * ( w * x0 + b) 为正 # 若(x0, y0)为负样本，y0为负，误分类后 w * x0 + b 为正，−y0 * ( w * x0 + b) 为正 所有点到超平面的总距离为 −1/||w|| * ∑ yi * | w * x0 + b | 定义损失函数 L(x, b) = −∑ yi * ( w * x0 + b ) 则 (1) 初始化w0,b0，权值可以初始化为0或一个很小的随机数 (2) 在训练数据集中选取（x_i, y_i） (3) 如果 yi * (w * xi + b) ≤ 0 # η为学习率（0&lt;η&lt;1） w = w + η * y_i * x_i b = b + η * y_i (4) 转至（2）,直至训练集中没有误分类点 其中，损失函数详见1.3.5。 1.3.4 激活函数 性质 可微性： 当优化方法是基于梯度的时候，这个性质是必须的。 单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数。 输出值的范围： 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate。 流行激活函数对比 Sigmoid函数：曾经是最常用的激活函数, 但现在一般只用在输出层, 中间层很少使用。 缺点1: 两头平坦。梯度小, 在后向传播 (BP) 中, 逐层梯度乘以整个网络最终输出的梯度之后, 达到输入层时, 导致反传回去的梯度被消减掉，最终导致没有梯度信号更新权重。权值的改动小, 学习速度慢。 缺点2：输出值域不对称，不是以零为中心的。[0,1], 只有正数, 没有负数。在梯度下降过程中的动力学角度来讲，这会导致一个潜在问题：如果数据流经神经元的时数据总是正的，那么在反向传播时，权重的梯度也将全部变为正的，或者全部变为负的，对于权重的梯度更新来说，导致一个不好的锯齿状梯度。 tanh函数：曾经是最常用的激活函数, 中间层较少使用, 但比Sigmoid效果好。 优点: 输出值域对称。[-1,1] 缺点: 两头依旧过于平坦 ReLU (Rectified Linear Unit) 优点1：不存在饱和(saturate)区域 优点2：收敛速度比sigmoid/tannh函数快 优点3：计算高效简单，没有引入计算复杂高的操作 缺点1：Dead Area: ReLU 函数单元在训练过程中比较脆弱，神经元死亡, 输出为0, 权重不更新 Leaky ReLU 优点：解决 ReLU 死亡问题，没有 Dead Area. Parametric ReLU：负数部分的斜率是从数据当中学习得到的，而不是预先定义的。 Randomized ReLU：负值部分的斜率值在给定范围内是随机选取的，而在测试时，参数值会被确定下来。 Maxout：maxout 是 ReLU 或 Leaky ReLU 的更一般形式 优点：非线性但不具有饱和性，不会死掉 缺点：训练的参数是原本的两倍 1.3.5 损失函数 损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。 前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的ΦΦ是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是L1，也可以是L2，或者其他的正则函数。整个式子表示的意思是找到使目标函数最小时的θθ值。 log对数损失函数（逻辑回归） 有逻辑回归的损失函数不是平方损失。平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到，逻辑回归假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数，接着取对数求极值等等。逻辑回归没有求似然函数的极值，而把极大化当做是一种思想，进而推导出它的经验风险函数为：最小化负的似然函数（即max F(y, f(x)) —-&gt; min -F(y, f(x)))。从损失函数的视角来看，它就成了log损失函数了。 利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说什么样的参数才能使我们观测到目前这组数据的概率最大 平方损失函数（最小二乘法, Ordinary Least Squares ） 最小二乘法是线性回归的一种，OLS将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（中心极限定理）。最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。换言之，OLS是基于距离的，而这个距离就是我们用的最多的欧几里得距离。 指数损失函数（Adaboost） 学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。 Hinge损失函数（SVM） 0-1损失函数 绝对值损失函数 分类问题的损失函数，从信息论的角度看，等价于训练出来的模型（分布）与真实模型（分布）之间的交叉熵（两者相差一个只和样本数据量有关的倍数N），而这个交叉熵的大小，衡量了训练模型与真实模型之间的差距，交叉熵越小，两者越接近，从而说明模型越准确。 1.4 抽象层级与层把相同结构的神经单元组合在一起，构成神经网络的层: 输入层 输入向量 中间层 (隐含层) 输出层 输出向量, 用于预测, 分类以及回归 抽象层级越高，层越多。 2012年多伦多大学的Krizhevsky等人构造了一个超大型卷积神经网络，有9层，共65万个神经元，6千万个参数。网络的输入是图片，输出是1000个类，比如小虫、美洲豹、救生船等等。这个模型的训练需要海量图片，它的分类准确率也完爆先前所有分类器。纽约大学的Zeiler和Fergusi把这个网络中某些神经元挑出来，把在其上响应特别大的那些输入图像放在一起，看它们有什么共同点。他们发现中间层的神经元响应了某些十分抽象的特征。 第一层神经元主要负责识别颜色和简单纹理 第二层的一些神经元可以识别更加细化的纹理，比如布纹、刻度、叶纹。 第三层的一些神经元负责感受黑夜里的黄色烛光、鸡蛋黄、高光。 第四层的一些神经元负责识别萌狗的脸、七星瓢虫和一堆圆形物体的存在。 第五层的一些神经元可以识别出花、圆形屋顶、键盘、鸟、黑眼圈动物。 1.4.1 层的基本变换 通过表达式：y⃗ =a(W⋅x⃗ +b)得知，x的输入空间转换为y的输出空间，其中W进行升维降维、放大缩小、旋转。b进行平移，a对空间进行弯曲。 1.5 神经网络 ANN 1.5.1 理解神经网络是最具代表性的机器学习的算法，同时也是深度学习的基础。 这是最常见的多层前馈神经网络（multi-layer feedforward neural networks）。不难看出，神经网络的学习其实就是调整各神经元之间的连接权（connection weight）以及各神经元的阈值。 由图可知，我们可以拖通过 增加节点数 : 增加维度，即增加线性转换能力。 增加层数 : 增加激活函数的次数，即增加非线性转换次数。 将原始输入空间投向线性可分/稀疏的空间去分类/回归。 1.5.2 概念 维基百科：‘神经网络’（Neural Network）是一种模仿生物神经网络的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应系统。现代神经网络是一种非线性统计性数据建模工具。典型的神经网络具有以下三个部分: 结构 （Architecture) 激励函数（Activity Rule) 学习规则（Learning Rule） 人工神经网络模型主要考虑网络连接的拓扑结构、神经元的特征、学习规则等。目前，已有近 40 种神经网络模型。 前馈神经网络:也经常称为多层感知器(Multilayer Perceptron， MLP)。 反馈神经网络:网络内神经元间有反馈，可以用一个无向的完备图表示。这种神经网络的信息处理是状态的变换，可以用动力学系统理论处理。 神经网络 - demo 1.5.3 误差逆传播算法（BackPropagation BP） 感知机的学习过程在线性不可分时会发生振荡（fluctuation），难以稳定。对于多层感知器中的隐层，因为无法直接得到其输出值，不能直接使用损失。这时，就需要将损失从顶层反向传播（Back Propagate）到隐层，来完成参数估计的目标。BP是迄今最成功的神经网络学习算法，现实任务中使用神经网络大多是使用BP。一般而言，BP神经网络是指用BP算法训练的多层前馈神经网络，但BP算法也能训练其他类型的神经网络，如递归神经网络。 步骤 先将输入实例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果 计算输出层误差，计算输出层神经元梯度项，再将误差逆向传播至隐层神经元 最后根据隐层神经元的误差对连接权和阈值进行调整 该迭代过程循环进行，直到达到某些同志条件为止。例如训练误差已经达到一个很小的值。 思考多层感知器存在的最大的问题就是，它是一个全连接的网络，因此在输入比较大的时候，权值会特别多。比如一个有1000个节点的隐层，连接到一个1000×1000的图像上，那么就需要 10^9 个权值参数（外加1000个偏置参数）！这个问题，一方面限制了每层能够容纳的最大神经元数目，另一方面也限制了多层感知器的层数即深度。多层感知器的另一个问题是梯度发散。一般情况下，我们需要把输入归一化，而每个神经元的输出在激活函数的作用下也是归一化的；另外，有效的参数其绝对值也一般是小于1的；这样，在BP过程中，多个小于1的数连乘，得到的会是更小的值。也就是说，在深度增加的情况下，从后传播到前边的残差会越来越小，甚至对更新权值起不到帮助，从而失去训练效果，使得前边层的参数趋于随机化（补充一下，其实随机参数也是能一定程度上捕捉到图像边缘的）。 1.5.4 其他神经网络 RBF（Radial Basis Function）网络 单隐层前馈神经网络，它使用径向基函数作为隐层神经元的激活函数。输出层则直接使用隐层神经元的线性组合。 ART（Adaptive Resonance Theory，自适应谐振理论）网络 竞争型学习的重要代表。该网络由四部份组成：比较层、识别层、识别阈值、重置模块。比较层就是输入层，只负责把样本传递给识别层。识别层也即输出层，但识别层的每个神经元对应一个模式类，而且神经元的数目可以在训练过程中动态增加以增加新的模式类。ART能有效缓解竞争型学习中的可塑性-稳定性窘境（stability-plasticity dilemma），ART具备可塑性和稳定性，因此能进行增量学习（incremental learning）和在线学习（online learning）。 SOM（Self-Organizing Map，自组织映射）网络 又称为自组织特征映射网络或Kohonen网络。同样是一种竞争学习型无监督神经网络，只有输入层和输出层两层，输出层以矩阵形式排列。与样本距离最近的输出层神经元获胜，称为最佳匹配单元（best matching unit）。最佳匹配单元和邻近神经元的权向量会被调整，使得下次遇到相似的样本时距离更小。如此迭代，直至收敛。 级联相关（Cascade-Correlation）网络 典型的结构自适应网络，这类网络不仅通过训练来学习合适的连接权和阈值等参数，还会在训练过程中找到最符合数据特点的网络结构。 递归神经网络（recurrent neural networks，简称RNN） 允许网络中出现环形结构，即一些神经元的输出可以反馈回来当输入信号，从而能够处理与时间有关的动态变化。Elman网络是最常用的递归神经网络之一，只有一个隐层，并且隐层神经元的输出会被反馈，在下一时刻与输入层神经元的输入信号一起作为隐层神经元的新输入。隐层神经元一般采用Sigmoid函数作为激活函数，并用BP算法训练整个网络。 第二章：python实现最简神经网络 用python实现，BP反向传播算法，单层神经网络，双重神经网络。 X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ]) y = np.array([[0,1,1,0]]).T syn0 = 2*np.random.random((3,4)) - 1 syn1 = 2*np.random.random((4,1)) - 1 for j in xrange(60000): l1 = 1/(1+np.exp(-(np.dot(X,syn0)))) l2 = 1/(1+np.exp(-(np.dot(l1,syn1)))) l2_delta = (y - l2)*(l2*(1-l2)) l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1)) syn1 += l1.T.dot(l2_delta) syn0 += X.T.dot(l1_delta) 2.1 一个简洁的神经网络给定三列输入，试着去预测对应的一列输出。我们可以通过简单测量输入与输出值的数据来解决这一问题。这样一来，我们可以发现最左边的一列输入值和输出值是完美匹配/完全相关的。直观意义上来讲，反向传播算法便是通过这种方式来衡量数据间统计关系进而得到模型的。 input oytput 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 2.2 两层神经网络import numpy as np # sigmoid function 非线性映射 def nonlin(x,deriv=False): # 用输出值便可以得到其导数值 if(deriv==True): return x*(1-x) return 1/(1+np.exp(-x)) # input dataset X = np.array([ [0,0,1], [0,1,1], [1,0,1], [1,1,1] ]) # output dataset y = np.array([[0,0,1,1]]).T # “.T” 为转置函数 # seed random numbers to make calculation # deterministic (just a good practice) np.random.seed(1) # initialize weights randomly with mean 0 syn0 = 2*np.random.random((3,1)) - 1 # 神经网络权重矩阵的初始化操作 for iter in xrange(10000): # 训练 # forward propagation l0 = X l1 = nonlin(np.dot(l0,syn0)) # 前向预测阶段 # how much did we miss? 误差 l1_error = y - l1 # multiply how much we missed by the # slope of the sigmoid at the values in l1 l1_delta = l1_error * nonlin(l1,True) # update weights syn0 += np.dot(l0.T,l1_delta) print &quot;Output After Training:&quot; print l1 结果为 Output After Training: [[ 0.00966449] [ 0.00786506] [ 0.99358898] [ 0.99211957]] 变量说明 变量 定义说明 X 输入数据集，形式为矩阵，每 1 行代表 1 个训练样本。 y 输出数据集，形式为矩阵，每 1 行代表 1 个训练样本。 l0 网络第 1 层，即网络输入层。 l1 网络第 2 层，常称作隐藏层。 syn0 第一层权值，突触 0 ，连接 l0 层与 l1 层。 2.3 复杂神经网络给定前两列输入，尝试去预测输出列】，这两列与输出不存在任何关联，可以视为一种“非线性”模式，单个输入与输出间不存在一个一对一的关系。而输入的组合与输出间存在着一对一的关系，在这里也就是列 1 和列 2 的组合。我们需要额外增加一个网络层。第一层对输入进行组合，然后以第一层的输出作为输入，通过第二层的映射得到最终的输出结果。 input Hidden Weight output 0 0 1 0.1 0.2 0.5 0.2 0 0 1 1 0.2 0.6 0.7 0.1 1 1 0 1 0.3 0.2 0.3 0.9 1 1 1 1 0.2 0.1 0.3 0.8 0 import numpy as np def nonlin(x,deriv=False): if(deriv==True): return x*(1-x) return 1/(1+np.exp(-x)) X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]]) y = np.array([[0], [1], [1], [0]]) np.random.seed(1) # randomly initialize our weights with mean 0 syn0 = 2*np.random.random((3,4)) - 1 syn1 = 2*np.random.random((4,1)) - 1 for j in xrange(60000): # Feed forward through layers 0, 1, and 2 l0 = X l1 = nonlin(np.dot(l0,syn0)) l2 = nonlin(np.dot(l1,syn1)) # how much did we miss the target value? l2_error = y - l2 if (j% 10000) == 0: print &quot;Error:&quot; + str(np.mean(np.abs(l2_error))) # in what direction is the target value? # were we really sure? if so, don&apos;t change too much. l2_delta = l2_error*nonlin(l2,deriv=True) # how much did each l1 value contribute to the l2 error (according to the weights)? l1_error = l2_delta.dot(syn1.T) # 置信度加权”，构建 l1 层相应的误差 # in what direction is the target l1? # were we really sure? if so, don&apos;t change too much. l1_delta = l1_error * nonlin(l1,deriv=True) syn1 += l1.T.dot(l2_delta) syn0 += l0.T.dot(l1_delta) 变量说明 变量 定义说明 X 输入数据集，形式为矩阵，每 1 行代表 1 个训练样本。 y 输出数据集，形式为矩阵，每 1 行代表 1 个训练样本。 l0 网络第 1 层，即网络输入层。 l1 网络第 2 层，常称作隐藏层。 l2 假定为网络最后一层，随着训练进行，其输出应该逐渐接近正确结果 syn0 第一层权值，突触 0 ，连接 l0 层与 l1 层。 syn1 第二层权值，突触 1 ，连接 l1 层与 l2 层。 l2_error 该值说明了神经网络预测时“丢失”的数目。 l2_delta 该值为经确信度加权后的神经网络的误差，除了确信误差很小时，它近似等于预测误差。 l1_error 该值为 l2_delta 经 syn1 加权后的结果，从而能够计算得到中间层/隐层的误差。 l1_delta 该值为经确信度加权后的神经网络 l1 层的误差，除了确信误差很小时，它近似等于 l1_error 。 第三章：深度学习 3.1 理解 深度网络（DNN）: 学习的是函数 卷积神经网络（CNN）: 学习的是特征 循环神经网络（RNN）: 学习的是程序 神经网络使用并行的先验知识使得模型可用线性回归，数据样本学习要求大。而深度学习比浅层神经网络更高效，因为迭代组成的先验知识使得样本可用于帮助训练其他共用同样底层结构的样本。 多层神经网络的限制 面对大数据时，需要人为提取原始数据的特征作为输入，这个问题前面的知友提到过@杨延生。必须忽略不相关的变量，同时保留有用的信息。这个尺度很难掌握，多层神经网络会把蹲在屋顶的Kitty和骑在猫奴头上的Kitty识别为不同的猫咪，又会把二哈和狼归类为同一种动物。前者是对不相关变量过于敏感，后者则因无法提取有实际意义的特征。 想要更精确的近似复杂的函数，必须增加隐藏层的层数，这就产生了梯度扩散问题。所谓“强弩之末势不能穿鲁缟“。 无法处理时间序列数据（比如音频），因为多层神经网络不含时间参数。随着人工智能需求的提升，我们想要做复杂的图像识别，做自然语言处理，做语义分析翻译，等等。多层神经网络显然力不从心。 那么深度模型是如何解决以上三个问题的。 深度学习自动选择原始数据的特征。举一个图像的例子，将像素值矩阵输入深度网络，网络第一层表征物体的位置、边缘、亮度等初级视觉信息。第二层将边缘整合表征物体的轮廓……之后的层会表征更加抽象的信息，如猫或狗这样的抽象概念。所有特征完全在网络中自动呈现，并非出自人工设计。更重要的一点是这种随着层的深入，从具象到抽象的层级式表征跟大脑的工作原理吻合，视网膜接收图像从LGN到视皮层、颞叶皮层再到海马走的是同样的路数！ 深度网络的学习算法。一种方法是改变网络的组织结构，比如用卷积神经网络代替全连接（full connectivity）网络，训练算法仍依据Backpropagating gradients的基本原理。另一种则是彻底改变训练算法，我尝试过的算法有Hessian-free optimization[3]，recursive least-squares(RLS)等。 使用带反馈和时间参数的Recurrent neural network处理时间序列数据。从某种意义上讲，Recurrent neural network可以在时间维度上展开成深度网络，可以有效处理音频信息，或者用来模拟动力系统。 深度学习是一种参数多，模型复杂度高，容量大的模型。，通过多个隐层，将低层特征转换为高层特征，用于完成更复杂的学习任务。 3.2 概念多层神经网络与universal approximation theorem（泛逼近性原理）相伴而生。该理论指出，单隐藏层（hidden layer）非线性前馈神经网络，可以在实数空间近似任何连续函数 “深度学习”是为了让层数较多的多层神经网络可以训练，能够work而演化出来的一系列的新的结构和新的方法。新的网络结构中最著名的就是CNN，它解决了传统较深的网络参数太多，很难训练的问题，使用了“局部感受野”和“权植共享”的概念，大大减少了网络参数的数量。关键是这种结构确实很符合视觉类任务在人脑上的工作原理。新的结构还包括了：LSTM，ResNet等。新的方法就多了：新的激活函数：ReLU，新的权重初始化方法（逐层初始化，XAVIER等），新的损失函数，新的防止过拟合方法（Dropout, BN等）。这些方面主要都是为了解决传统的多层神经网络的一些不足：梯度消失，过拟合等。 3.3 训练方式 无监督逐层训练（unsupervised layer-wise training）：每次训练一层隐结点，把上一层隐结点的输出当作输入来训练，本层隐结点训练好后，输出再作为下一层的输入来训练，这称为预训练（pre-training）。全部预训练完成后，再对整个网络进行微调（fine-tuning）训练。一个典型例子就是深度信念网络（deep belief network，简称DBN）。这种做法其实可以视为把大量的参数进行分组，先找出每组较好的设置，再基于这些局部最优的结果来训练全局最优。 权共享（weight sharing）：令同一层神经元使用完全相同的连接权，典型的例子是卷积神经网络（Convolutional Neural Network，简称CNN）。这样做可以大大减少需要训练的参数数目。 3.4 递归神经网络递归神经网络（RNN）是两种人工神经网络的总称。一种是时间递归神经网络（recurrent neural network），另一种是结构递归神经网络（recursive neural network）。主要处理序列数据（诸如文本、语言）。 一般而言，RNN指时间递归神经网络（recurrent neural network），也叫循环递归网络。 RNN不仅仅能够处理序列输出, 也能得到序列输出, 这里序列指的是向量的序列 RNN学习出来的是程序, 不是函数 每个正方形代表一个向量，箭头代表函数（比如矩阵乘法）。输入向量是红色，输出向量是蓝色，绿色向量装的是RNN的状态。上图从左至右依次为： 非RNN的普通过程，从固定尺寸的输入到固定尺寸的输出（比如图像分类）。 输出是序列（例如图像标注：输入是一张图像，输出是单词的序列）。 输入是序列（例如情绪分析：输入是一个句子，输出是对句子属于正面还是负面情绪的分类）。 输入输出都是序列（比如机器翻译：RNN输入一个英文句子输出一个法文句子）。 同步的输入输出序列（比如视频分类中，我们将对视频的每一帧都打标签） 3.4.1 记忆抽象 若RNN是一个类，存在API只包含一个step方法：则step方法接收输入向量x，返回输出向量y。然而这个输出向量的内容不仅被输入数据影响，而且会收到整个历史输入的影响。 rnn = RNN() y = rnn.step(x) # x is an input vector, y is the RNN&apos;s output vector 每当step方法被调用的时候，RNN的内部状态就被更新。在最简单情况下，该内部装着仅包含一个内部隐向量h。下面是一个普通RNN的step方法的实现： class RNN: # ... def step(self, x): # update the hidden state self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x)) # compute the output vector y = np.dot(self.W_hy, self.h) return y 以上代码说明了普通RNN的前向传播。 更深层网络。 y1 = rnn1.step(x) y = rnn2.step(y1) 3.5 卷积神经网络卷积神经网络 cnn - example 卷积神经网络(Convolutional Neural Network, CNN)是深度学习技术中极具代表的网络结构之一，主要处理图像处理，避免对图像复杂的前期预处理过程（提取人工特征等），可以直接输入原始图像。 由来：神经元网络的直接升级版 相关：Yann LeCun和他的LeNet 影响：在图像、语音领域不断突破，复兴了神经元网络并进入“深度学习”时代 卷积神经网络沿用了普通的神经元网络即多层感知器的结构，是一个前馈网络。应用于图像领域。 3.5.1 网络结构 输入图像I。为了减小复杂度，一般使用灰度图像。当然，也可以使用RGB彩色图像，此时输入图像有三张，分别为RGB分量。输入图像一般需要归一化，如果使用sigmoid激活函数，则归一化到[0, 1]，如果使用tanh激活函数，则归一化到[-1, 1]。 多个卷积（C）-下采样（S）层。将上一层的输出与本层权重W做卷积得到各个C层，然后下采样得到各个S层。怎么做以及为什么，下面会具体分析。这些层的输出称为Feature Map。 光栅化（X）。是为了与传统的多层感知器全连接。即将上一层的所有Feature Map的每个像素依次展开，排成一列。 传统的多层感知器（N&amp;O）。最后的分类器一般使用Softmax，如果是二分类，当然也可以使用LR。 常用架构模式为： INPUT -&gt; [[CONV] * N -&gt; POOL?] * M -&gt; [FC] * K 也就是N个卷积层叠加，然后(可选)叠加一个Pooling层，重复这个结构M次，最后叠加K个全连接层。 对于图 网络结构为： INPUT -&gt; CONV -&gt; POOL -&gt; CONV -&gt; POOL -&gt; FC -&gt; FC 3.5.1 API及出发点 将输入3D体积转换为具有一些可能具有参数的可微函数的输出3D体积。 局部感受野。 形象地说，就是模仿你的眼睛，想想看，你在看东西的时候，目光是聚焦在一个相对很小的局部的吧？严格一些说，普通的多层感知器中，隐层节点会全连接到一个图像的每个像素点上，而在卷积神经网络中，每个隐层节点只连接到图像某个足够小局部的像素点上，从而大大减少需要训练的权值参数。举个栗子，依旧是1000×1000的图像，使用10×10的感受野，那么每个神经元只需要100个权值参数；不幸的是，由于需要将输入图像扫描一遍，共需要991×991个神经元！参数数目减少了一个数量级，不过还是太多。 权值共享 形象地说，就如同你的某个神经中枢中的神经细胞，它们的结构、功能是相同的，甚至是可以互相替代的。也就是，在卷积神经网中，同一个卷积核内，所有的神经元的权值是相同的，从而大大减少需要训练的参数。继续上一个栗子，虽然需要991×991个神经元，但是它们的权值是共享的呀，所以还是只需要100个权值参数，以及1个偏置参数。从MLP的 10^9 到这里的100，就是这么狠！作为补充，在CNN中的每个隐藏，一般会有多个卷积核。 池化 形象地说，你先随便看向远方，然后闭上眼睛，你仍然记得看到了些什么，但是你能完全回忆起你刚刚看到的每一个细节吗？同样，在卷积神经网络中，没有必要一定就要对原图像做处理，而是可以使用某种“压缩”方法，这就是池化，也就是每次将原图像卷积后，都通过一个下采样的过程，来减小图像的规模。以最大池化（Max Pooling）为例，1000×1000的图像经过10×10的卷积核卷积后，得到的是991×991的特征图，然后使用2×2的池化规模，即每4个点组成的小方块中，取最大的一个作为输出，最终得到的是496×496大小的特征图。 3.5.2 局部连接与权值共享 局部连接 1000 × 1000的输入图像，若下一个隐藏层的神经元数目为10^6个 全连接：1000 × 1000 × 10^6 = 10^12个权值参数 局部连接：隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8 权值共享 在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数。但是，这样仅提取了图像的一种特征，如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像的不同映射下的特征，称之为Feature Map。如果有100个卷积核，最终的权值参数也仅为100 × 100 = 10^4个而已。 3.5.3 卷积 卷积层的作用是提取图像的各种特征 卷积核尺寸: DHW, 卷积核的深度和输入图像是一致的 卷积滑动参数: stride/padding 每个卷积核带有一个bias require(&apos;nn&apos;) img = torch.rand(3,5,5) #输入x: 深度为3, 高和宽均为5 conv = nn.SpatialConvolution(3,2,3,3,2,2,1,1) #参数分别表示输入深度(3),卷积核个数(2),卷积核的尺寸(3*3), h方向的stride(2),w方向的stride(2), h方向的padding大小(1),w方向的padding大小(1)(padding:补0或补重复数) img_out=conv:forward(img) #Forward计算 假设有一个5 5的图像，使用一个3 3的filter进行卷积，想得到一个3 * 3的Feature Map 3.5.4 池化（Pooling） 池化层的作用是对原始特征信号进行抽象，从而大幅度减少训练参数，另外还可以减轻模型过拟合的程度。 改变图像尺寸的操作, 可以逐层的把图像尺寸一点点降下来, 减少维度 max pool / average pool 3.6 Long Short Term 网络（LSTM）几乎所有的令人振奋的关于 RNN 的结果都是通过 LSTM 达到的。LSTM 由 Hochreiter &amp; Schmidhuber (1997) 提出，并在近期被 Alex Graves 进行了改良和推广。 LSTM 可以学习长期依赖信息，避免长期依赖问题。LSTM 的关键就是细胞状态，水平线在图上方贯穿运行。细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传保持不变会很容易。 其中，每一条黑线传输着一整个向量，从一个节点的输出到其他节点的输入。粉色的圈代表 pointwise 的操作，诸如向量的和，而黄色的矩阵就是学习到的神经网络层。合在一起的线表示向量的连接，分开的线表示内容被复制，然后分发到不同的位置。 3.6.1 逐步理解 案例：基于已经看到的词预测下一个词。细胞状态可能包含当前‘主语’的类别，因此正确的‘代词’可以被选择出来。 第一步：确定是否更新。通过’忘记门层’完成。该门会读取h(t-1)和xt，输出一个在 0 到 1 之间的数值给每个在细胞状态C(t-1)中的数字。1 表示“完全保留”，0 表示“完全舍弃”。当我们看到新的‘代词’，我们希望忘记旧的‘代词’。 第二步：确定更新信息。首先，sigmoid层称 “输入门层”决定什么值我们将要更新。其次，tanh层创建一个新的候选值向量，会被加入到状态中。我们希望增加新的代词的类别到细胞状态中，来替代旧的需要忘记的代词。 第三步：更新细胞状态。更新旧细胞状态，把旧状态与ft相乘，丢弃掉我们确定需要丢弃的信息。接着加上新的候选值，根据每个状态的程度进行变化。丢弃旧代词的类别信息并添加新的信息的地方。 第四步：输出信息。首先，运行sigmoid层来确定细胞状态的哪个部分将输出出去。接着，把细胞状态通过tanh进行处理（得到一个在 -1 到 1 之间的值）并将它和sigmoid门的输出相乘，输出确定输出的那部分。代词需要输出与一个动词相关的信息。例如，可能输出是否代词是单数还是负数，这样如果是动词的话，我们也知道动词需要进行的词形变化。 第四章：playground实例 谷歌 打开网页后，总体来说，蓝色代表正值，黄色代表负值。拿分类任务来分析。 数据 在二维平面内，若干点被标记成了两种颜色。黄色，蓝色，表示想要区分的两类。你可以把平面内的任意点标记成任意颜色。网页给你提供了4种规律。神经网络会根据你给的数据训练，再分类相同规律的点。 输入 在二维平面内，你想给网络多少关于“点”的信息。从颜色就可以看出来，x1左边是负，右边是正，x1表示此点的横坐标值。同理，x2表示此点的纵坐标值。x1~2是关于横坐标值的“抛物线”信息。你也可以给更多关于这个点的信息。给的越多，越容易被分开。 连接线 表示权重，蓝色表示用神经元的原始输出，黄色表示用负输出。深浅表示权重的绝对值大小。鼠标放在线上可以看到具体值。也可以更改。 输出 黄色背景颜色都被归为黄点类，蓝色背景颜色都被归为蓝点类。深浅表示可能性的强弱。 第五章：如何选择合适的算法 第一步：问题分类 根据输入数据分类 如果我们的数据有标签，这就是一个监督学习问题 如果数据没有标签而且我们想找出数据的内在结构，那这就是无监督学习 如果我们想通过与环境交互来优化目标函数，这是强化学习 根据输出结果分类 如果模型输出结果是一个数值，这是回归问题 如果输出结果是一个类别，这是分类问题 如果输出结果是一组输入数据，那这是聚类问题 分类（classification）：当使用数据来预测类别时，监督学习也被叫做分类。比如将含有「猫」或「狗」的图片识别出来，分类为「猫」或「狗」，这就是二分类问题（two-class or binomial classification）。当存在更多类别时（例如预测下一届诺贝尔物理学家的获得者是谁），这就是所谓的多分类问题（multi-class classification）。 回归（regression）：当要预测数值时（比如预测股价），监督学习也被称为回归。 聚类（clustering）：聚类或聚类分析（cluster analysis）是无监督学习中最常见的方法之一。聚类是将一组对象以某种方式分组，使得同一组中的数据比不同组的数据有更多的相似性。 异常检测（Anomaly detection）：有时我们需要找出数据点中的异常点。例如，在欺诈检测中，任何极不寻常的信用卡消费都是可疑的；欺诈具有大量不同的形式，而训练样本又非常少，使得我们不可能完全了解欺诈活动应该是什么样。异常检测所采取的方法就是了解正常情况下的表现行为（使用非欺诈交易的历史数据），并识别出显著不同的表现行为。 第二步：寻找算法 分类： 支持向量机（SVM）可用于找到尽可能宽的分类的边界。当两个分类不能被清楚地分开时，该算法会找到其所能找到的最佳边界。其真正的亮点在于处理特征密集的数据，比如文本或者基因组（特征数量&gt; 100）。在这些情况下，除了仅需要适量的记忆外，支持向量机（SVM）能够比其它大多数算法更快且更少过拟合地进行分类。 人工神经网络是涵盖二分类、多分类和回归问题的脑启发式学习算法。它们有无限的种类，包括感知器和深度学习。它们需要很长时间来训练，但已知其在多种应用领域都实现了当前最佳的表现。 logistic 回归：即便名字中有着「回归」，但 logistic 回归实际上是一种可用于二分类和多分类问题的强大工具。它快速且简单。事实上，它使用「S」形曲线而非直线，所以它自然适合用于数据分组。logistic 回归可以给出线性分类边界，所以如果你要使用它，你一定要确保你能接受线性的近似。 决策树和随机森林：决策森林（decision forests）（回归、二分类、多分类），决策丛林（decision jungles）（二分类和多分类）和提升决策树（boosted decision trees）（回归和二分类）都基于决策树。这是一个基本的机器学习概念。决策树有许多不同的变体，但它们都在做同样的事情—将特征空间（feature space）细分为具有大致相同标签的区域。这些区域可以是一致的类别或者恒定值，具体取决于你进行的是分类还是回归。 回归： 线性回归是将一条线（或平面、或超平面）拟合到一个数据集上。这是一种主要的工具，简单且快速，但对于一些问题而言，它可能过于简单。 贝叶斯线性回归有着非常理想的特性：它可以避免过拟合。贝叶斯方法通过事先对答案的可能分布做出一些假设来做到这一点。这种方法的另一个副产品是它们具有非常少的参数。 提升决策树回归（Boosted decision tree regression）：如上所述，提升决策树（回归和二分类）均基于决策树，并通过将特征空间细分为具有大致相同标签的区域发挥效用。提升决策树通过限制其可以细分的次数以及每个区域中所允许的最少数据点来避免过拟合。该算法会构造一个树的序列，其中每棵树都会学习弥补之前的树留下来的误差。这能得到一个会使用大量的内存的非常精确的学习器。 聚类： 层次聚类（Hierarchical Clustering）的目标是构建聚类的层次结构，它有两种形式。聚集聚类（agglomerative clustering）是一种「自下而上」的方法，其中每个观察（observation）在其自己的聚类中开始，随着其在层次中向上移动，成对的聚类会进行融合。分裂聚类（divisive clustering）则是一种「自上而下」的方法，其中所有的观察都从一个聚类开始，并且会随观察向下的层次移动而递归式地分裂。整体而言，这里的融合和分裂是以一种激进的方式确定的。层次聚类的结果通常表示成树状图（dendrogram）的形式。 k-均值聚类（k-means clustering）的目标是将 n 组观测值分为 k 个聚类，其中每个观测值都属于其接近的那个均值的聚类——这些均值被用作这些聚类的原型。这会将数据空间分割成 Voronoi 单元。 异常检测： k 最近邻（k-nearest neighbors / k-NN）是用于分类和回归的非参数方法。在这两种情况下，输入都是由特征空间中与 k 最接近的训练样本组成的。在 k-NN 分类中，输出是一个类成员。对象通过其 k 最近邻的多数投票来分类，其中对象被分配给 k 最近邻中最常见的类（k 为一正整数，通常较小）。在 k-NN 回归中，输出为对象的属性值。该值为其 k 最近邻值的平均值。 单类支持向量机（One-class SVM）：使用了非线性支持向量机的一个巧妙的扩展，单类支持向量机可以描绘一个严格概述整个数据集的边界。远在边界之外的任何新数据点都是非正常的，值得注意。 第三步：实现算法问题通常存在多种候选算法，选择算法应反复试验。 原型开发最好分两步完成。 最小特征工程快速实现。该阶段，主要目标是大概了解哪个算法表现得更好。将列表减少至几个候选算法。 建立机器学习流程，使用一组经过仔细选择的评估标准来比较每个算法在数据集上的表现。该阶段，只处理小部分算法，把注意力放在：特征工程。 如下是深度学习的实现步骤： 数据扩增 水平翻转 随机剪裁 颜色抖动 预处理 去均值与规范化 主成分分析白化（数据先经过去均值，然后计算出（能刻画数据内部相关结果的）协方差矩阵） 参数初始化 全零初始化：若初始权值相同，神经元就不具有非对称性（asymmetry）。 小随机数初始化：在网络的回传过程中，小值权重会减弱“梯度信号” 方差校准：确保了网络中神经元在最初时有着大致相同的输出分布，以及收敛速度的提升。 np.random.randn(n) * sqrt(2.0/n) # 推荐，方差为2.0/n 训练 滤波器与池化 学习率 参数微调 正则化 L2正则化：惩罚目标函数中所有参数的平方。对权重向量的加强惩罚(heavily penalizing peaky weight vectors)和对权重向量的发散(diffuse weight vectors)。 L1正则化：将权重向量中的每个权重参数累加后加入目标函数中。带有L1正则化的神经元最终会将输入的数据中的重要输入元素得到保留，其余会变成或接近00。 最大模限制(max norm constraints)：让每个神经元的权重向量有一个绝对上限(upper bound)的约束，使用投影梯度下降(projected gradient descent)来执行这个约束。 Dropout：对整个神经网络进行抽样，并基于输入数据仅仅更新抽样网络的参数。 第四步：特征工程特征工程却更像是一门艺术。 主要问题在于我们试图分类的数据在特征空间的描述极少。利如，用像素的灰度值来预测图片通常是不佳的选择；相反，我们需要找到能提高信噪比的数据变换。如果没有这些数据转换，我们的任务可能无法解决。利如，在方向梯度直方图（HOG）出现之前，复杂的视觉任务（像行人检测或面部检测）都是很难做到的。 常见的选取数据特征的方法：（大多数特征的有效性需靠实验评估） 主成分分析（PCA）：一种线性降维方法，可以找出包含信息量较高的特征主成分，可以解释数据中的大多数方差。 尺度不变特征变换（SIFT）：计算机视觉领域中的一种有专利的算法，用以检测和描述图片的局部特征。它有一个开源的替代方法 ORB（Oriented FAST and rotated BRIEF）。 加速稳健特征（SURF）：SIFT 的更稳健版本，有专利。方向梯度直方图（HOG）：一种特征描述方法，在计算机视觉中用于计数一张图像中局部部分的梯度方向的 occurrence。 更多算法请参考 或者通过交叉验证误差最大的候选特征，前向或反向搜索获取期望数量的特征。 第五步：优化算法 5.1 调整超参 优化算法超参数。例如，主成分分析中的主成分个数，k 近邻算法的参数 k，或者是神经网络中的层数和学习速率。最好的方法是使用交叉验证来选择。 新数据与当初预训练模型的数据相似时， 若数据少就训练一个线性分类器，作为预训练模型的顶层特征抽取部分。 若数据时就使用一个较小的学习率，对预训练模型的多个顶层进行微调。 如果数据与当初训练模型的数据相差大，但数据多。那么网络的大多数层的参数都应该基于新的数据做微调，同时用一个较小的学习率以提升性能。 如果数据与当初训练模型的数据相差大，且数据少，那就很难。因为数据量的限制，还不如单独训练一个线性模型，因为数据就与原本训练深层模型的不同，如若从顶层开始用自己差异大的数据（预训练模型得到的参数体现的是原始数据的特征）来训练，不见得会有多么好，反倒不如训练一个支持向量机模型替换深层模型中的某些层。 5.2 优化方法 一阶梯度法 手动指定学习速率：SGD, Momentum, Nesterov Momentum 自动调节学习速率AdaGrad, RMSProp, Adam 二阶梯度法","tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://galaxias-sapphi-ren.github.io/tags/深度学习/"},{"name":"神经网络","slug":"神经网络","permalink":"https://galaxias-sapphi-ren.github.io/tags/神经网络/"},{"name":"机器学习","slug":"机器学习","permalink":"https://galaxias-sapphi-ren.github.io/tags/机器学习/"}]},{"title":"Machine Learning | 今日头条又推荐美女图片了，扒扒它的技术架构吧","date":"2017-02-15T01:00:00.000Z","path":"2017/02/15/machine-learning-recommend-sys-tech-framework-of-toutiao/","text":"信了推荐算法的邪，入了深度学习的坑。 2017年02月15日 - 任思飞 @Copyright Smart Home &amp; Roobo 今日头条推荐系统算法技术架构 - 机器学习预研 摘要 “今日头条”是一款基于数据挖掘技术的个性化推荐引擎产品，它为用户推荐有价值的、个性化的信息，提供连接人与信息的新型服务，是国内移动互联网领域成长最快的产品之一。“今日头条”于2012年8月上线，截至2016年9月底，“今日头条”累计激活用户数已达5.8亿，日活跃用户超过6300万。 “今日头条”没有采编人员，不生产内容，没有立场和价值观，运转核心是一套由代码搭建而成的算法。“今日头条”搭建的算法模型会记录用户在今日头条上的每一次行为，基于此计算出用户的喜好，推送他最有可能感兴趣的内容。 本文根据“今日头条”副总裁杨震原的历次演讲及“今日头条“官网http://www.toutiao.com/about/解构“今日头条”推荐系统算法和主要技术环节。 关键字 推荐系统 今日头条 深度学习 杨震原 参考资料 2015年8月29日，“七牛·数据时代峰会”上海国际时尚中心杨震原演讲 《传媒评论》2015年10月刊，“今日头条”的技术逻辑：网络爬虫+矩阵筛选王成军（南京大学新闻传播学院助理研究员，奥美数据科学实验室主任，计算传播学中心研究） 2015年11月19日，CSDN年度技术盛宴 “SDCC 2015中国软件开发者嘉年华”在北京召开，杨震原发表题为《大数据的挑战，开发者如何应对》的演讲及采访。 2016年2月2日，数据挖掘系列篇（9）：今日头条的个性化推荐 2016年4月20日，今日头条核心算法负责人杨震原，MindStore分享 2016年8月8日，今日头条产品总监杨震原解密今日头条算法推荐原理 2017年2月16日，淘宝搜索/推荐系统背后深度强化学习与自适应在线学习的实践之路 第一章：推荐冷启动 cold start 1.1 概念个性化推荐是需要依赖用户的历史行为才能预测用户的兴趣，因此大量的用户行为数据是用户的重要组成部分和先决条件。那么对于在开始阶段就像要一个个性化推荐系统的网站或应用来说，如何在没有用户历史数据的情况下设计个性化推荐并且让用户对推荐结果满意从而使用推荐系统，就是冷启动问题。 1.2 解决方案当新用户加入时，一般需要给用户一个初始兴趣值。比较常见的做法，比如quora，zhihu，pinterest是让人手选感兴趣的话题。另外一个做法是给一些初始歌曲或者电影让人选喜欢或者不喜欢，然后生成一个初始值。无论哪一个做法，用户的行为数据都不足以产生高质量的推荐。而今日头条则选择了另一种解决方案——通过对用户微博账号的分析建立一个“兴趣图谱”。 1.3 技术路径 微博ID接入今日头条后，对兴趣作出分析，建立初始的DNA数据。 抽取一部分用户，让用户可以自主选择新闻tag分类进行订阅，对比自动推荐的人均阅读篇数和留存情况，进行模型效果比较和优化 根据初始的兴趣模型从三个维度呈现内容。 第一个是“推荐”，即会从抓取到的每条信息（包括图片信息）中提取几十个到几百个高维特征，并进行降维、相似计算、聚类、分类等处理，然后根据用户的兴趣模型进行推荐的内容，每天会采用Visual-based抓取技术处理超过100万个网页, 以保证内容来源足够准确。 第二个是“热门”，即互联网和社交网站上出现最多的内容 第三个是好友动态中，可查看好友的评论、转发、收藏动作。 内容评论依照用户的社交关系、评论人的影响力等条件进行排序。 第二章：用户模型 懂算法的人让UGC内容提供者、原创者受益。 5亿用户，月平均增长1000万。 2.1 用户特征阅读姓名，年龄，地域，职业，用户搜索关键词等 2.2 用户行为用户通过“顶”、“踩”、转发、收藏等操作，用户行为数据会实时性地被传送到后台，在用户每次操作后的30秒内，系统就会对用户模型进行更新。 第三章：数据挖掘 数据挖掘是今日头条最核心的技术，本章论述‘今日头条’如何进行推荐内容的挖掘。 3.1 数据网络爬虫今日头条服务器1000台左右，通过代码实现的爬虫功能，在其他传媒的网站和门户上抓取各种信息。如果在网站上抓取到纸媒的内容，优先从纸媒门户上抓取信息。如“网易新闻”、“新浪新闻”、“凤凰新闻”、“浙江新闻”等等。 3.2 分类算法归类抓取信息后，对有价值的信息通过算法进行分析归类。‘今日头条’的核心技术是实体词抽取。对抓取文章进行以下分类分析。 文章实体词抽取，‘词嵌入’方法，做向量化的分析 引入隐含狄利克雷分布简称LDA(Latent Dirichlet allocation)，将文档集中每篇文档的主题按照概率分布的形式给出，进行topic分析。 3.3 分类算法测试现象 定制新闻以泛热点新闻为基础数据来完成的事实，这就出现一个问题，即当一个人关注的新闻不是热点时，系统得不到相关的热点，就会在该新闻当中寻找其他信息进行再匹配，这样匹配出的新闻在现有信息的基础上最大程度吻合了用户的兴趣，但未必会推送当天最热点的新闻。要想达到这种长尾理论所设想的定制服务，关键是对新闻的细分。只有将不同主题细分成各种子主题，再细分下设内容，才能达到真正的私人定制。要做到这一点，实际已经脱离了机械，而在于人对于事物性质的认知与把握。正如法国社会学家福柯在《知识考古学》当中的观点，分类，是一事物区别于其他事物的根本。而分类，归根结底是人的主观能动性的体现；当系统中累计的用户行为越多，这种分类越准确，自动化的私人定制也会越贴近用户需求。 为了测试分类是否准确，今日头条进行以下测试。 3.3.1 A/B测试 A/B测试 是一种把实验对象随机分组，把一个或者多个测试组的表现与对照相比较，进行测试的方式。 唯一变量 随机分布 流量分桶 3.3.2 双盲交叉验证 双盲交叉验证 在评估一项数据时，随机抽取一部分数据进行多人分别评估 3.4 人工运营 原创与转载内容的内容消重 标题和图片消重 相似主题消重 文章审核（标题问题、正文正文问题、推广、广告） 第四章：推荐算法 本章论述‘今日头条’如何通过算法，一边提取内容的特征，一边提取用户兴趣的特征，然后让内容与用户的兴趣匹配。 4.1 基本流程 构建基于内容的推荐的矩阵获得不同候选集 候选集过滤，融合 精细排序 选出用户当前可能最感兴趣的文章进行推荐。 4.2 基于内容的推荐获取的文章内容，是否值得推荐有以下考量： 根据以上信息，‘今日头条’使用以下算法构建算法矩阵： 相似文章主题相似性的推荐：通过获取与用户阅读过文章的相似文章来进行推荐。 基于相同城市的新闻：对于拥有相同地理信息的用户，会推荐与之相匹配的城市的热门文章。 基于文章关键词的推荐：对于每篇文章，提取关键词，作为描述文章内容的一种特征。然后与用户动作历史的文章关键词进行匹配推荐。 基于站内热门文章的普适性推荐：根据站内用户阅读习惯，找出热门文章，对所有没有阅读过该文章的用户进行推荐。 基于社交好友关系的阅读习惯推荐：根据用户的站外好友，获取站外好友转发评论或发表过的文章进行推荐。 基于用户长期兴趣关键词的推荐：通过比较用户短期和长期的阅读兴趣主题和关键词进行推荐。 基于相似用户阅读习惯的列表推荐：计算一定时期内的用户动作相似性，进行阅读内容的交叉性推荐。 基于站点分布来源的内容推荐：通过用户阅读的文章来源分布为用户计算出20个用户喜欢的新闻来源进行推荐。 根据基于内容的以上推荐矩阵获得候选集。 4.2 过滤，融合将以上推荐进行融合、过滤 过滤的目的是为了支持人工介入，比如，要过滤掉： 运营指定不能推的新闻 包含某关键字的新闻 融合 加权型：根据经验对不同的子方案赋予不同的权重，权重越高取的条数越多（按比例） 分级型：优先采用效果好的算法，当产生的候选集大小不足以满足目标值时，再使用效果次好的算法，依次类推（效果好坏的评价可以根据该子方案最终产生的推荐的点击率来算） 4.3 协同过滤基于物品的协同过滤算法（item-based collaborative filtering, ItemCF） 利用某兴趣相投、拥有共同经验之群体的喜好来推荐用户感兴趣的信息，个人通过合作的机制给予信息相当程度的回应（如评分）并记录下来以达到过滤的目的进而帮助别人筛选信息，回应不一定局限于特别感兴趣的，特别不感兴趣信息的纪录也相当重要。 一般是在海量的用户中发掘出一小部分和你品位比较类似的，在协同过滤中，这些用户成为邻居，然后根据他们喜欢的其他东西组织成一个排序的目录作为推荐给你。 今日头条中协同过滤算法是最重要的基于内容推荐的算法。 4.3.1 特征抽取 根据第二、三章论述，从用户、文章具有特征，‘今日头条’也同样参考环境特征。 用户特征分析：阅读姓名，年龄，地域，职业等 文章特征分析：名人，文章发布的时间，文章所属的地区，计算文章的分类、文章的关键词等 环境特征分析：早上看科技新，晚上看搞笑视频。网络环境，要有wifi的话，多推视频。 4.3.2 投票（LR逻辑回归） 算法为：最高分 = W1 候选1的投票率 + W2 候选2的投票率 + W3 * 候选3的投票率 + … 4.5 问题案例 第一讲系统工程和细节的交叉点，我们先说背景，今日内容推荐很重要的一部分就是针对一个你可能感兴趣的候选集进行惊喜的排序，这部分的一个核心就是进行了建模，把永辉的各种组合偏好记录下来。比如说uid—keyword就表达了某个用户的特点。我这里先不讨论各种模型的利弊，我们再往下来看如何解决特征爆炸的问题。机器学习的领域来讲，通常这样的问题解决的思路有很多种，比如说通过sample数据，比如说可以L1正则，稀疏化特征，第三特征过滤，第四hashtrick，第516bit的压缩。这里的方法特别多，我们再白讲一下特征的过滤怎么样来做，这个问题就变得非常明确的问题，我们有3T的uniqkey，我们现在的任务非常的明确我们需要去统计并过滤掉频次在8次以下的Key。采用方案是： 一个hash的结构，一个key要占用40bytes，40bytes会有指针的消耗和对企的问题。开地址的hash，我们是用开地址的hash，而不是冲突了之后放下一个，再冲突了再放下一个，我们最大的填充率按50％记，但key16bit，单机30g内存，冲突率和bloomcounter接近。大家可以想象，就是说这里需要注意一下，就是说sign5bit的数据和其他的不同，我去查一个东西的时候，就是一个表的指，之后我用第二个函数来算出去如果说找到冲突之后，以前是1，1就加到2，2就加到3，我们就用到一个hash用到非常小的一个结果而言，所以我们就要知道，这个hash的函数不同，所以它是一个有损的hash，这个有多大的好处呢？它是bloomcounter性能的6倍，因为它只需要一次访存，所以我们的性能就提升了6倍，这个事情就使得我们对模型训练的时间，提高到了原来的2倍，所以我们在万兆的网络连接上，20个小时都可以传完，是用到fiter的方法，我就希望用到很细节的方法来表达，这些都可以和工程相结合起来，找到结合点的时候就要把规矩和规模进行提升，这些提升所带来的效果是很大的。 理论的研究和实践的结合。对于一个LR model来讲，使用不同的学习率、不同正则项，收敛的效果是不同的。这当中是自带了效果，但是初始的学习率还是会带来很大的影响。除了weiglt的参数之外，我们还有学习率、L1等的超参数。手工调参是非常困难的问题。特征的类型我们是按照特定的规则来分有上百个，每个特征的类型都有正则率和特征的参数，这样我们就几百个参数，这个是没有办法调整的，所有这个事情是是不能够训练的，这是一个很痛苦的问题超参。解决方案是： 寻找过拟合和训练不足之间的最佳的平衡点，我训练是在一个训练集之中去做优化，我上线是在上线的集合之中来做，这两个数据集的分布是不同的，超参数就是去调这个东西，我训练不充分不好，我就是要做到在上线的情况下最优的超参数。我们把数据分为训练集验证集和测试集，我们在训练集之中去优化参数，我们可以做的事情是在验证集之中去优化超参数，目标是降低验证集的loss，这是更加的接近线上的分布，这是一个本质的方法我们可以找到最优点，同时这个方法是服务做好的。后面会稍微的说一下流程，大家可以看到，如此来在验证集上去优化参数，在ftrl下，超参是可以导的，这是最有意思的事情。这个l1正则项梯度，这个是可以求出来的，对l2的正则项也是可以求出来的，所以我们就有自动调参的流程，来算出更新，然后在验证集中去验证，就用到这些相应的方法，如何去把验证集去进行训练，这是有讲究的，如果验证集太近和太远都是不好的，这些都是细节的问题。也有新的问题，学习中的验证怎么样调？做这一块的人，最头痛的事情就是调参，但是我可以把几百个参数变成只有几个——参数可以调了，这个事情我们已经把它实现了并且在头条上全面的上线了，取得了什么效果呢？就是我们的离线评估UAC的面积，有2.2个绝对百分点的收益，在线的CTR有7.5个相对百分点的收益，这是非常重大的改进。 算法和产品、UI的结合。头条不仅仅有文章还有视频，视频的低质内容的控制是很重要的，我们有很多的办法去改进这个问题，有一些账号去评级，通过账号订阅的比例，效果都不好，之后我们用了一个办法，效果会大幅度的提升，说出来大家会觉得很简单，点赞。我们在视频播放的列表页放出了顶踩按钮，这样的使用就会大幅的提升，所以通过简单的加入顶踩的数据的统计，会对低质的打击效果明显提高。这就是一个很简单的，就是和产品结合，大家很多时候会举很多的例子，比如说以前肥皂盒的例子，技术的方案就是要解决问题你有简单的方法去解决问题这才是更有意义的创新。 第五章：分类任务总结 由第三章可以得知，‘今日头条’的分类算法的核心功能在于 数据挖掘，海量内容信息 关键词抽取技术，提取特征并测试 数据挖掘，搭建用户兴趣图谱，正负反馈 人工运营，消重、内容审核 而在任务‘今日头条’分类系统测试中，数据源由今日头条爬虫提供，无需经过步骤3，4。只需进行关键词抽取，提取特征。 本文没有从数据集Train和Test集的划分，过拟合，模型的选择，特征的抽取，正负样本的处理，采样方式（向上采样、向下采样），各种调参，特征的处理，y值处理，融合的方式等具体技术细节分析，只提供了‘今日头条’推荐系统的一般原理。","tags":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://galaxias-sapphi-ren.github.io/tags/推荐系统/"},{"name":"深度学习","slug":"深度学习","permalink":"https://galaxias-sapphi-ren.github.io/tags/深度学习/"}]},{"title":"TodoList in 2017","date":"2017-02-11T01:00:00.000Z","path":"2017/02/11/todo-list-in-2017/","text":"2017年学习计划 read [x] 智能时代 [x] 你的第一本哲学书 [x] 我懂你的知识焦虑 [x] 清教徒的礼物 [] 细节 [] 程序员的数学1,2,3 [] 永远幸福的科学 [] 精进 - 如何成为一个很厉害的人 [] 未来简史 - 从智人到智神 [] 最好的告别 - 关于衰老与死亡，你必须知道的常识 [] 安静的力量 Jan. [x] nodejs npm yeoman 基础 [x] 移动端页面固头固尾fixed布局解决方案（含软键盘弹出），修复不同ios系统的适配问题 [x] dropwizard + bdi API [x] python 2.7 base [x] decision tree id3算法 Feb. [x] python爬虫 [x] 分词工具，结巴分词、讯飞分词 [x] 推荐系统算法研究 [x] 搜狗试验站数据分类 [x] 今日头条推荐系统技术架构 Mar. [x] 神经网络、机器学习、深度学习基础 [x] opencv 基础 [] 电商支付系统基础实现， [] 小象学院深度学习课程 [] 内容推荐 [] 图片识别 Apr.May.Jun.","tags":[]},{"title":"我曾经跨过 npm 和 yeoman，也穿过人山人海","date":"2017-01-07T01:00:00.000Z","path":"2017/01/07/start-npm-and-yeoman/","text":"这个故事发生在我尝试在mac上使用 IntelliJ Idea 和 Sublime Test 3 进行编程时 npm 1 What is npm? 😚 1.1 share and reuse npm makes it easy for JavaScript developers to share and reuse code, and it makes it easy to update the code that you’re sharing. npm makes it easy for Javascript developers to share the code that they’ve created to solve particular problems, and for other developers to reuse that code in their own applications. 1.2 structure package or module files or not “package.json” : metadata 1.3 benefit bring in packages from people who have focused on particular problem areas reuse code across projects no wheels node package manager with registry 1.4 summary 👻 So that’s what npm is. It’s a way to reuse code from other developers, and also a way to share your code with them, and it makes it easy to manage the different versions of code. 1.5 install install Node.js and make sure node -v npm -v maybe you’ll want to make sure it’s the latest version. npm install npm@latest -g or sometime Installing npm manually 1.6 permission fixed 👽 EER when install npm without sudo change the permission to npm’s default directory: npm config get prefix `// /Users/sapphire/.nvm/versions/node/v6.3.0` cd $(npm config get prefix)/ sudo chown -R $(whoami) $(npm config get prefix)/{lib/node_modules,bin,share} or change npm’s default dir ( lazy… 👉) 1.7 registry change npm registry if u have no vpn. 2 How to use npm? 😚 2.1 install packages mkdir and init npm : install and node it : npm install/uninstall &lt;package_name&gt; --save //update packege.json show package.json 🗣 Tips : add a repository during npm init， otherwise we can see two warnings from package.json file and Readme.md 2.2 package.json 2.2.1 requirements{ &quot;name&quot;: &quot;my-awesome-package&quot;, //all lowercase,one word, no spaces &quot;version&quot;: &quot;1.0.0&quot; //follows semver spec } 2.2.2 quickly init npm init –yes name: defaults to author name unless in a git directory, in which case it will be the name of the repository version: always 1.0.0 main: always index.js scripts: by default creates a empty test script keywords: empty author: whatever you provided the CLI license: ISC repository: will pull in info from the current directory, if present bugs: will pull in info from the current directory, if present homepage: will pull in info from the current directory, if present 👉 set several config options for the init command npm set init.author.email &quot;578556078@qq.com&quot; npm set init.author.name &quot;sapphire&quot; npm set init.license &quot;MIT&quot; 🗣 Tips : if there is no description field in the package.json, npm uses the first line of the README.md or README instead. 2.2.3 customize init see init-package-json-code, a node module to get node module started.i have practiced it at “/Users/sapphire/Projects/java/static/js/npm/day2”🗣 Tips : use the prompt function to customize the questions. module.exports = prompt(&quot;what&apos;s your favorite flavor of ice cream buddy?&quot;, &quot;I LIKE THEM ALL&quot;); 2.2.4 specifying packages dependencies //pro –save devDependencies //dev and test –save-div 2.3 update update the package u depend on so u can getany changes form code upstream npm outdated npm update 2.4 global install global or local npm ls npm ls -g npm ls -g --depth=0 2.5 publish You can publish any directory that has a package.json file npm publish then GO here to find it. 2.6 version share with other and release at 1.0.0 3 How npm works? 😚 3.1 definitions of Packages and Modules Packages : readable with package.json a) a folder containing a program described by a package.json file b) a gzipped tarball containing (a) c) a url that resolves to (b) d) a @ that is published on the registry with (c) e) a @ that points to (d) f) a that has a latest tag satisfying (e) g) a git url that, when cloned, results in (a). Modules : requirable and runable A folder with a package.json file containing a main field. A folder with an index.js file in it. A JavaScript file.| dependency resolution 👍 npm can easily load both versions of the module in a way that they do not conflict with each other.👎 maven conflict between two versions dependency npm3 is differently than npm2, just know the command : npm dedupe //redirect module to the top level copy and removes all the nested copies. 4 What is Yeoman? 😚 4.1 kickstart scaffolding 🤓 Yeoman is a generic scaffolding system allowing the creation of any kind of app. It allows for rapidly getting started on new projects and streamlines the maintenance of existing projects. 4.2 forms language agnostic, generate projects in any language generators ecosystem to make decisions workflow with comprising tools and frameworks Here are some common use cases: Rapidly create a new project Create new sections of a project, like a new controller with unit tests Create modules or packages Bootstrapping new services Enforcing standards, best practices and style guides Promote new projects by letting users get started with a sample app 4.3 features 闪电般的初始化 项目开始阶段，可以基于现有的模板框架（例如：HTML5 Bolierplate、Twitter Bootstrap）进行项目初始化的快速构建。 了不起的构建流程 不仅仅包括JS、CSS代码的压缩、合并，还可以对图片和HTML文件进行优化，同时对CoffeScript和Compass的文件进行编译。 自动编译CoffeScript和Compass 通过LiveReload进程可以对源文件发生的改动自动编译，完成后刷新浏览器。 自动Lint代码 对于JS代码会自动进行JSLint测试，确保代码符合最佳编程实践。 内置的预览服务器 不再需要自己配置服务器了，使用内置的就可以快速预览。 惊人的图片优化 通过使用OptiPNG和JPEGTran来优化图片，减少下载损耗。 杀手级包管理 通过bower search jQuery，可以快速安装和更新相关的文件，不再需要打开浏览器自己搜索了。 PhantomJS单元测试 可以非常方便的使用PhantomJS进行单元测试，一切在项目初始的时候都准备好了。 4.4 tools the scaffolding tool (yo) the build tool (Gulp, Grunt etc) the package manager (like npm and Bower) 5 How to use Yeoman? 😚 prepare make sure ur evironment : Node.js、Ruby、Compass sudo gem update --system sudo gem install compass 🗣 Tips : more Compass info. command curl -L get.yeoman.io | bash npm install -g yo grunt-cli bower npm install -g generator-webapp yo webapp yo webapp --help npm home generator-webapp yo angular:controller MyNewController yo doctor 5.1 Installing yo and some generators","tags":[{"name":"npm","slug":"npm","permalink":"https://galaxias-sapphi-ren.github.io/tags/npm/"},{"name":"yeoman","slug":"yeoman","permalink":"https://galaxias-sapphi-ren.github.io/tags/yeoman/"}]},{"title":"学了markdown，丢了word","date":"2017-01-02T01:00:00.000Z","path":"2017/01/02/start-markdown/","text":"markdown学习笔记，练练手 Ch 1 what’s markdown introduction 概念 Markdown是一种轻量级标记语言，创始人为John Gruber。他允许人们 “使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML或HTML文档”。 该语言吸收了很多电子邮件中已有的纯文本标记的特性。 importance 提高效率 改善体验 用途 方便那些需要输入大量文字，不喜欢使用鼠标快速写出文字排版的文档 比如：码农、博客写手、网站小编、出版业人士 Ch 2 markdown grammar common tags \\ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号 table Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 reference 怎样引导新手使用 Markdown Markdown 展示简书 Markdown语法 文章作者：袁晓辉 链接： 为啥要学：酷炫风吸引的技术小白某次听讲座，看到前排的江浩博士拿出电脑记笔记，打开了一个一半是黑色，一般是白色的软件。在左边黑色的区域内打字，打字的过程中加几个简单的符号，所在行的文字立马变成了明快的彩色。更神奇的是，在右侧白色区域中呈现出大小标题十分清晰的结构化文字。当时心想，这也太酷炫了吧。 『啥时候我也要这么酷炫地记笔记！』 之后跟@果说的奇异果打听这是啥软件，他说，那就是之前给你推荐的Markdown语言啊。哦，Markdown，听起来好高端，是不是也像Python、C啥的，也是一种编程语言呢？一定也不太好学吧。 要学习新东西，总觉得需要克服重重困难并且付出巨大的努力才行，于是借口要准备答辩，时间不充裕，就没有马上学起。 今年1月6号，答辩完整理电脑里的文件，想起了记忆中那个图景。现在有时间了，没理由不学了，那就试试看吧。 于是在维基百科上了解了Markdown的理念和语法，装上了一个叫Mou编辑器。打开一看，对！要的就是这种酷炫的感觉！ 研究了一下才发现，Markdown的语法相当简单，一小会儿的功夫，常用的格式处理语法就都试了一遍。神奇的写作体验就此开始。之后的年终总结、演讲稿、生活随笔、论文思路都开始用Markdown来写了，真是爱不释手。 Markdown到底是个啥？Markdown是一种轻量级标记语言，创始人为John Gruber。它允许人们『使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML或HTML文档』 站在技术外行的角度简单理解，就是以最少的输入代价，呈现出结构化且富于表现力的文档。写着舒心，看着顺心。 我根据自己的体验总结了用该语言写作的几个好处： 结构写作：通过格式标记有助于理清思路 语法简单：简单的几个符号，试一次就可以记住 格式优雅：呈现出来的文字排版格式简洁好看 引用方便：插入超链接很方便，再也不担心找不到出处 写作专注：写作时关注内容即可，可开启过瘾的打字机声音 容易分享：可导出HTML和PDF文件，随处都可打开 与Txt和Word相比呢？大多数情况下，我们写东西要么用Word，要么用Txt记事本，跟Markdown相比，这两者的问题在哪呢？ Txt：没有格式，顺序写作，结构化不足，写出来所有格式都一样。 Word：有格式，但鼠标键盘点来点去容易为格式所累，无法专注于写作的内容本身。 而用Markdown来写东西，既有用Txt写作的简洁感，也有用Word刷格式后呈现的排版效果，而且是通过简洁的标记符号就产生了丰富的排版效果。这种感觉只有在上手用过一次以后才能了解奇妙之处。 我们常说，有什么样的思路，就会写出什么样的东西；但我后来发现，写作的呈现结果其实对写作思路的影响也很大： 如果写出的内容是清晰的结构化的，那么思路也会愈发清晰； 如果写出的内容是线性的非结构化的，那么思路很容易陷入某个细节中。 还记得思维导图吗？如果能够把脑海中的很多思绪用思维导图的方式梳理和串联起来，那么我们会发现思路在输出的过程中变清晰。 Markdown语法好记吗？它不是编程语言，很简单，一学就会，一用就灵。 常用的几个语法： 大标题小标题：几个#号几级标题。如一个井号是一级标题，四个井号是四级标题。 加粗和斜体：几对*号斜粗体。一对星号是斜体，两对星号是加粗。 引用别人的话：一个&gt;号变引用。即可呈现出灰色底色引用的效果。 引用链接：方括号里超链接。[需要引用的话][标识码]然后把标识码对应的链接附在文后：[标识码]：http://… 或者[需要引用的话]后面紧跟括号，括号里是对应的链接。 插入表格：|号表示分割线。表格从此想怎么画怎么画。 缩进黑点对齐：一个*号点缩进。呈现黑点引导的对齐效果。 缩进数字对齐：数字圆点数缩进。呈现数字引导的对齐效果。 插入高亮代码：三个`号插代码。插入一段高亮代码。 插入分隔线：三个*号分隔线。分隔线就是这么简单。 以上基本就是常用的语法了，可以在Markdown编辑器里试试看，半小时应该就能熟练掌握。 这些语法记不住咋办？记性不好如我者，时不时打开工具文档再看看呗，重复几次，肯定就没问题了。 用什么软件？Markdown是一种语言，要用Markdown语言写作，一般来说需要一个作为编辑器的软件。 如果上网方便想先试试的话，可以先不安装编辑器，直接试试 作业部落或简书的Web端，网址是Cmd Markdown 编辑阅读器，复制到浏览器中，打开即可上手来写了。 如果已经决定要长期使用，不妨在本地安装Markdown的编辑器， Mac系统推荐一个叫Mou的编辑器，亲测一个月，好使。Windows 系统推荐MarkdownPad或者MarkPad吧，没用过，但可以试试看。 如果决定全面Markdown，那么马克飞象这个软件推荐给印象笔记 的用户，可以直接写完以后同步到笔记中哦。 这些编辑器的首页应该都是详细的介绍和语法说明。心动不如行动啦。 用Markdown搞定微信公众号的排版如果你也有一个微信公众号，只要提前装好一个插件，那么用Markdown写作的文章可以直接粘在正文区，转换一下，即可呈现丰富的格式。从此告别公众号文章的low格式和模板格式时代。 用Markdown写作的作者们直接写好确认好格式，不用再经历小编们的一道修理，就可以以原汁原味的形态，优雅地呈现于读者面前了。小编们也可以从排版的痛苦中解放出来啦。 用Markdown来实现微信公众号的排版包括以下几步： 装chrome浏览器中安装Markdown here插件，需要翻墙； 把用Markdown写作的文章复制过来，粘在微信后台的文本框中； 按住Control+Alt+M，即可转换成最终呈现出来的文字格式； 可以进一步调整文字的颜色，插入图片等。 这样出来的文章，保准比之前看起来上了一个档次哦。 有了好用的工具，会不会爱上写作呢？要爱上写作，关键还是得写起来。 那么如何克服心理障碍开始写作呢？来自问自答几个问题。 想等到想得特别成熟才动笔开始写？放弃吧，不开始写作， 我们永远想不成熟的； 怕露怯，怕不完美？放弃吧，有谁是完美的呢？列一个出来？ 想到啥写啥不会太low吗？没有low，哪有high？大师都说了， 好文章是改出来的，我们首先也得有能改的东西啊。 千头万绪，没想清楚就写，会不会不太好？当脑海中信息太多 的时候，以写作的方式释放出来一些，让那些没有头绪的思想 呈现在纸上，我们才有可能理顺他们，才能给大脑留出足够的 空间关注最核心的问题吧。 好啦，开始带着Markdown的祝福，愉快地写起来吧。 跟我一样，你会爱上她的。","tags":[{"name":"markdown","slug":"markdown","permalink":"https://galaxias-sapphi-ren.github.io/tags/markdown/"}]}]